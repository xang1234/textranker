{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"rapid_textrank","text":"<p>High-performance TextRank keyword extraction in Rust with Python bindings.</p> <p>rapid_textrank extracts keywords and key phrases from text up to 10--100x faster than pure-Python implementations, with support for seven algorithm variants and 18 languages.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Fast -- Rust core with CSR graph format, string interning, and FxHash for 10--100x speedups over pure Python (depending on document size and tokenization).</li> <li>Eight algorithm variants -- BaseTextRank, PositionRank, BiasedTextRank, TopicRank, SingleRank, TopicalPageRank, MultipartiteRank, and SentenceRank.</li> <li>Unicode-aware -- proper handling of CJK and other scripts.</li> <li>18 languages -- built-in stopword lists from English to Japanese.</li> <li>Dual API -- native Python classes for quick use, plus a JSON interface for pre-tokenized / spaCy input.</li> <li>Configurable -- control damping, window size, POS filtering, phrase length, score aggregation, and more via <code>TextRankConfig</code>.</li> </ul>"},{"location":"#install","title":"Install","text":"<pre><code>pip install rapid_textrank\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from rapid_textrank import extract_keywords\n\ntext = \"\"\"\nMachine learning is a subset of artificial intelligence that enables\nsystems to learn and improve from experience. Deep learning, a type of\nmachine learning, uses neural networks with many layers.\n\"\"\"\n\nkeywords = extract_keywords(text, top_n=5, language=\"en\")\nfor phrase in keywords:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <pre><code>machine learning: 0.2341\ndeep learning: 0.1872\nartificial intelligence: 0.1654\nneural networks: 0.1432\nsystems: 0.0891\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"Section What you will find Getting Started Installation, quick start guide, and grab-and-go recipes Algorithms How TextRank works and details on each variant API Reference <code>extract_keywords()</code>, extractor classes, <code>TextRankConfig</code>, JSON interface, spaCy integration Performance Benchmarks, why Rust is fast, comparison with alternatives Architecture Pipeline stages, variant composition, debug introspection, production hardening"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub: https://github.com/xang1234/rapid-textrank</li> <li>PyPI: https://pypi.org/project/rapid-textrank/</li> <li>License: MIT</li> </ul>"},{"location":"algorithms/","title":"Algorithm Variants","text":"<p>rapid_textrank ships with seven algorithm variants, each tailored to a different extraction scenario. All variants share the same core pipeline -- build a word co-occurrence graph, run PageRank (or a personalized variant), and extract scored phrases -- but they differ in how they construct the graph, weight edges, and post-process results.</p> <p>Choose the variant that best matches your document type and extraction goal. If you are unsure where to start, see Choosing a Variant.</p>"},{"location":"algorithms/#variant-comparison","title":"Variant Comparison","text":"Variant Best For Description BaseTextRank General text Standard TextRank implementation PositionRank Academic papers, news Favors words appearing early in the document BiasedTextRank Topic-focused extraction Biases results toward specified focus terms TopicRank Multi-topic documents Clusters similar phrases into topics and ranks the topics SingleRank Longer documents Uses weighted co-occurrence edges and cross-sentence windowing TopicalPageRank Topic-model-guided extraction Biases SingleRank towards topically important words via personalized PageRank MultipartiteRank Multi-topic documents Builds a k-partite graph removing intra-topic edges; boosts first-occurring variants"},{"location":"algorithms/#learn-more","title":"Learn More","text":"<ul> <li>How TextRank Works -- the three-step pipeline shared by all variants.</li> <li>Choosing a Variant -- a decision flowchart and scenario table to help you pick the right one.</li> </ul> <p>Interactive Notebook</p> <p>Compare all variants side-by-side in the Algorithm Variants Notebook.</p>"},{"location":"algorithms/base-textrank/","title":"BaseTextRank","text":"<p>BaseTextRank is the standard TextRank implementation -- a direct adaptation of the algorithm described by Mihalcea and Tarau (2004). It is the default variant used by the convenience function <code>extract_keywords()</code> and a solid general-purpose choice for keyword extraction.</p>"},{"location":"algorithms/base-textrank/#how-it-works","title":"How It Works","text":"<p>BaseTextRank follows the classic three-step pipeline:</p> <ol> <li>Build an unweighted co-occurrence graph from a sliding window over the text.</li> <li>Run PageRank with uniform teleportation to score each word node.</li> <li>Group high-scoring words into phrases using POS-filtered noun chunks.</li> </ol> <p>For a detailed walkthrough of these steps, see How TextRank Works.</p>"},{"location":"algorithms/base-textrank/#usage","title":"Usage","text":""},{"location":"algorithms/base-textrank/#convenience-function","title":"Convenience function","text":"<p>The simplest way to use BaseTextRank is through <code>extract_keywords()</code>, which creates a BaseTextRank extractor under the hood:</p> <pre><code>from rapid_textrank import extract_keywords\n\nkeywords = extract_keywords(text, top_n=10, language=\"en\")\nfor phrase in keywords:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"algorithms/base-textrank/#class-based-api","title":"Class-based API","text":"<p>For more control, instantiate <code>BaseTextRank</code> directly:</p> <pre><code>from rapid_textrank import BaseTextRank\n\nextractor = BaseTextRank(top_n=10, language=\"en\")\nresult = extractor.extract_keywords(text)\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"algorithms/base-textrank/#with-textrankconfig","title":"With TextRankConfig","text":"<p>For full configuration (window size, POS filtering, phrase length, score aggregation, and more):</p> <pre><code>from rapid_textrank import BaseTextRank, TextRankConfig\n\nconfig = TextRankConfig(\n    top_n=10,\n    language=\"en\",\n    window_size=3,\n    min_phrase_length=2,\n    max_phrase_length=4,\n    include_pos=[\"NOUN\", \"ADJ\", \"PROPN\"],\n    score_aggregation=\"sum\",\n)\n\nextractor = BaseTextRank(config=config)\nresult = extractor.extract_keywords(text)\n</code></pre>"},{"location":"algorithms/base-textrank/#when-to-use-basetextrank","title":"When to Use BaseTextRank","text":"<p>BaseTextRank is the right starting point when:</p> <ul> <li>You have no prior knowledge about the document's topics or structure.</li> <li>You want a simple, reliable baseline with no extra configuration.</li> <li>Your documents are of moderate length and cover a single dominant topic.</li> </ul> <p>If you need to steer results toward specific terms, consider BiasedTextRank. For documents where key terms appear early, try PositionRank. For longer or multi-topic documents, see SingleRank, TopicRank, or MultipartiteRank.</p>"},{"location":"algorithms/base-textrank/#reference","title":"Reference","text":"<ul> <li>TextRank: Bringing Order into Texts (Mihalcea &amp; Tarau, 2004)</li> </ul>"},{"location":"algorithms/biased-textrank/","title":"BiasedTextRank","text":"<p>BiasedTextRank (Kazemi et al., 2020) steers keyword extraction toward specific topics by biasing the PageRank random walk toward user-specified focus terms. The <code>bias_weight</code> parameter controls how strongly results favor those terms -- higher values produce results more tightly clustered around the focus vocabulary.</p>"},{"location":"algorithms/biased-textrank/#how-it-works","title":"How It Works","text":"<p>BiasedTextRank modifies the PageRank personalization vector so that focus terms receive a higher teleport probability. Non-focus words still participate in the graph, but the random walk preferentially returns to the focus terms, boosting them and their neighbors in the final ranking.</p> <p>The co-occurrence graph construction and phrase extraction steps are the same as BaseTextRank.</p>"},{"location":"algorithms/biased-textrank/#usage","title":"Usage","text":"<pre><code>from rapid_textrank import BiasedTextRank\n\nextractor = BiasedTextRank(\n    focus_terms=[\"security\", \"privacy\"],\n    bias_weight=5.0,  # Higher = stronger bias\n    top_n=10\n)\n\nresult = extractor.extract_keywords(\"\"\"\nModern web applications must balance user experience with security.\nPrivacy regulations require careful data handling. Performance\noptimizations should not compromise security measures.\n\"\"\")\n\n# Results will favor security/privacy-related phrases\n</code></pre>"},{"location":"algorithms/biased-textrank/#per-call-focus-override","title":"Per-call focus override","text":"<p>You can reuse the same extractor instance with different focus terms for each call:</p> <pre><code>result = extractor.extract_keywords(text, focus_terms=[\"neural\", \"network\"])\n</code></pre> <p>This is useful in pipelines where the extractor configuration (window size, POS filters, etc.) stays the same but the focus topic changes per document or per query.</p>"},{"location":"algorithms/biased-textrank/#choosing-bias_weight","title":"Choosing bias_weight","text":"<ul> <li>Values in the range 3.0 -- 10.0 work well for most use cases.</li> <li>Lower values (1.0 -- 3.0) produce a gentle nudge -- results still include diverse terms.</li> <li>Higher values (10.0+) strongly concentrate results around the focus terms and their immediate neighbors.</li> </ul>"},{"location":"algorithms/biased-textrank/#when-to-use-biasedtextrank","title":"When to Use BiasedTextRank","text":"<p>BiasedTextRank is a good fit when you know the domain or topic you care about and can express it as a short list of terms:</p> <ul> <li>Security audits -- focus on <code>[\"encrypt\", \"tls\", \"mfa\", \"audit\", \"privacy\"]</code>.</li> <li>Query-driven extraction -- set focus terms from user input (e.g., a search query).</li> <li>Domain-specific pipelines -- pre-define focus vocabularies for legal, medical, or financial text.</li> </ul> <p>If you have per-word importance scores (e.g., from a topic model) rather than a flat term list, consider TopicalPageRank instead.</p>"},{"location":"algorithms/biased-textrank/#reference","title":"Reference","text":"<ul> <li>BiasedTextRank: Unsupervised Graph-Based Content Extraction (Kazemi et al., 2020)</li> </ul>"},{"location":"algorithms/choosing-a-variant/","title":"Choosing a Variant","text":"<p>This page provides a decision guide to help you pick the right algorithm variant for your use case.</p>"},{"location":"algorithms/choosing-a-variant/#decision-flowchart","title":"Decision Flowchart","text":"<pre><code>flowchart TD\n    A[Start] --&gt; B{Do you have\\nfocus terms?}\n    B --&gt;|Yes| C{Per-word weights\\nor term list?}\n    C --&gt;|Term list| D[BiasedTextRank]\n    C --&gt;|Per-word weights| E[TopicalPageRank]\n    B --&gt;|No| F{Document type?}\n    F --&gt;|Short / structured\\n title+abstract, news| G[PositionRank]\n    F --&gt;|Long / multi-topic| H{Need diversity\\nacross topics?}\n    F --&gt;|General| I[BaseTextRank]\n    H --&gt;|Yes, coarse topics| J[TopicRank]\n    H --&gt;|Yes, fine-grained| K[MultipartiteRank]\n    H --&gt;|No| L[SingleRank]</code></pre>"},{"location":"algorithms/choosing-a-variant/#scenario-table","title":"Scenario Table","text":"Scenario Recommended Variant Why Blog post keywords BaseTextRank General-purpose, no extra config needed Academic paper abstract PositionRank Key terms appear early Security audit extraction BiasedTextRank Steer toward specific domains LDA-guided extraction TopicalPageRank Data-driven per-word weights Multi-section report TopicRank or MultipartiteRank Ensure coverage across topics Long technical document SingleRank Cross-sentence windowing captures more co-occurrences"},{"location":"algorithms/choosing-a-variant/#when-in-doubt","title":"When in Doubt","text":"<p>Start with BaseTextRank. It requires no extra configuration, works well across a wide range of document types, and serves as a reliable baseline. Once you see how it performs on your data, you can switch to a more specialized variant:</p> <ul> <li>If important keywords are being missed because they appear only in later sections, try SingleRank (weighted edges and cross-sentence windowing help).</li> <li>If results are too generic and you know which domain you care about, try BiasedTextRank with a focus vocabulary.</li> <li>If the keyword list is dominated by a single theme in a multi-topic document, try TopicRank or MultipartiteRank to promote diversity.</li> <li>If you have numeric word-importance scores from a topic model or other source, try TopicalPageRank.</li> <li>If your documents are short and structured (abstracts, news leads), try PositionRank to leverage the early-position signal.</li> </ul>"},{"location":"algorithms/how-textrank-works/","title":"How TextRank Works","text":"<p>TextRank is a graph-based ranking algorithm for keyword extraction, inspired by Google's PageRank.</p>"},{"location":"algorithms/how-textrank-works/#the-algorithm","title":"The Algorithm","text":"<ol> <li> <p>Build a co-occurrence graph -- Words become nodes. An edge connects two words if they appear within a sliding window (default: 4 words).</p> </li> <li> <p>Run PageRank -- The algorithm iteratively distributes \"importance\" through the graph. Words connected to many important words become important themselves.</p> </li> <li> <p>Extract phrases -- High-scoring words are grouped into noun chunks (POS-filtered) to form key phrases. Scores are aggregated (sum, mean, or max).</p> </li> </ol> <pre><code>Text: \"Machine learning enables systems to learn from data\"\n\nCo-occurrence graph (window=2):\n    machine &lt;-&gt; learning &lt;-&gt; enables &lt;-&gt; systems &lt;-&gt; learn &lt;-&gt; data\n                              |\n                            PageRank\n                              |\n    Scores: machine(0.23) learning(0.31) enables(0.12) ...\n                              |\n                        Phrase extraction\n                              |\n    \"machine learning\" (0.54), \"systems\" (0.18), ...\n</code></pre> <p>Each algorithm variant modifies one or more of these steps:</p> <ul> <li>PositionRank biases PageRank teleportation toward words that appear early.</li> <li>BiasedTextRank biases teleportation toward user-specified focus terms.</li> <li>SingleRank weights edges by co-occurrence count and windows across sentence boundaries.</li> <li>TopicalPageRank biases teleportation using per-word topic weights (e.g., from LDA).</li> <li>TopicRank clusters candidates into topics, builds a topic-level graph, then picks representatives.</li> <li>MultipartiteRank keeps individual candidates but removes intra-topic edges and boosts first-occurring variants.</li> </ul>"},{"location":"algorithms/how-textrank-works/#further-reading","title":"Further Reading","text":"<ul> <li>TextRank: Bringing Order into Texts (Mihalcea &amp; Tarau, 2004)</li> <li>PositionRank: An Unsupervised Approach to Keyphrase Extraction (Florescu &amp; Caragea, 2017)</li> <li>BiasedTextRank: Unsupervised Graph-Based Content Extraction (Kazemi et al., 2020)</li> <li>TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction (Bougouin et al., 2013)</li> <li>SingleRank: Single Document Keyphrase Extraction Using Neighborhood Knowledge (Wan &amp; Xiao, 2008)</li> <li>Topical Word Importance for Fast Keyphrase Extraction (Sterckx et al., 2015)</li> <li>MultipartiteRank: Unsupervised Keyphrase Extraction with Multipartite Graphs (Boudin, 2018)</li> </ul> <p>Interactive Notebook</p> <p>See the algorithm explained step-by-step in the Algorithm Explanation Notebook.</p>"},{"location":"algorithms/multipartite-rank/","title":"MultipartiteRank","text":"<p>MultipartiteRank (Boudin, 2018) extends TopicRank by keeping individual candidates as graph nodes instead of collapsing topics into single representatives. It removes intra-topic edges to form a k-partite graph and applies an alpha weight adjustment that boosts the first-occurring variant in each topic cluster, encoding positional preference directly into edge weights.</p>"},{"location":"algorithms/multipartite-rank/#how-it-works","title":"How It Works","text":"<ol> <li>Candidate extraction -- Candidate phrases are identified using POS-filtered noun chunks (same as other variants).</li> <li>Topic clustering -- Candidates are grouped into topics based on Jaccard similarity over word sets, controlled by <code>similarity_threshold</code>.</li> <li>K-partite graph -- A co-occurrence graph is built with all candidates as nodes, but edges between candidates in the same topic cluster are removed. This prevents intra-topic competition.</li> <li>Position boost -- Edge weights are adjusted by an <code>alpha</code> factor that favors the first-occurring candidate in each topic cluster. Set <code>alpha=0</code> to disable this boost.</li> <li>PageRank -- Standard PageRank is run on the k-partite graph.</li> <li>Phrase selection -- Top-scoring candidates are returned directly (no topic-level aggregation step).</li> </ol>"},{"location":"algorithms/multipartite-rank/#usage","title":"Usage","text":""},{"location":"algorithms/multipartite-rank/#native-python-class","title":"Native Python class","text":"<pre><code>from rapid_textrank import MultipartiteRank\n\nextractor = MultipartiteRank(\n    similarity_threshold=0.26,  # Jaccard threshold for topic clustering\n    alpha=1.1,                  # Position boost strength (0 = disabled)\n    top_n=10\n)\n\nresult = extractor.extract_keywords(\"\"\"\nMachine learning is a powerful tool for data analysis. Deep learning\nis a subset of machine learning. Neural networks power deep learning\nsystems. Convolutional neural networks excel at image recognition.\n\"\"\")\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"algorithms/multipartite-rank/#json-interface","title":"JSON interface","text":"<p>MultipartiteRank is also available via the JSON interface with <code>variant=\"multipartite_rank\"</code> (aliases: <code>\"multipartiterank\"</code>, <code>\"multipartite\"</code>, <code>\"mpr\"</code>). Set <code>multipartite_alpha</code> and <code>multipartite_similarity_threshold</code> in the JSON config:</p> <pre><code>import json\nfrom rapid_textrank import extract_from_json\n\npayload = {\n    \"tokens\": tokens,  # Pre-tokenized (e.g., from spaCy)\n    \"variant\": \"multipartite_rank\",\n    \"config\": {\n        \"top_n\": 10,\n        \"multipartite_alpha\": 1.1,\n        \"multipartite_similarity_threshold\": 0.26,\n    },\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\n</code></pre>"},{"location":"algorithms/multipartite-rank/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>similarity_threshold</code> float 0.26 Jaccard similarity threshold for grouping candidates into topic clusters. Higher values produce fewer, larger clusters. <code>alpha</code> float 1.1 Position boost strength. Controls how much first-occurring candidates within a cluster are favored. Set to 0 to disable the position boost entirely."},{"location":"algorithms/multipartite-rank/#multipartiterank-vs-topicrank","title":"MultipartiteRank vs TopicRank","text":"<p>Both variants cluster candidates into topics, but they differ in graph construction and candidate handling:</p> <ul> <li>TopicRank collapses each topic into a single node and ranks topics as a whole, then picks the best representative from each. This gives strong diversity but loses fine-grained candidate distinctions.</li> <li>MultipartiteRank keeps every candidate as its own node but removes edges within the same topic. This preserves fine-grained candidate distinctions while still preventing intra-topic competition.</li> </ul> <p>In practice, MultipartiteRank tends to produce more nuanced results because it can rank individual phrases rather than entire topic clusters. The <code>alpha</code> position boost further helps surface the most salient phrasing of each topic.</p>"},{"location":"algorithms/multipartite-rank/#when-to-use-multipartiterank","title":"When to Use MultipartiteRank","text":"<p>MultipartiteRank is a good choice for:</p> <ul> <li>Long, multi-topic documents where you want diverse keywords but also care about the specific phrasing of each keyword.</li> <li>Documents with near-duplicate phrases (e.g., \"machine learning\" and \"learning machine\") where you want the most natural variant to surface.</li> <li>Scenarios where TopicRank's topic-level collapsing is too aggressive -- MultipartiteRank offers a middle ground between per-candidate ranking (BaseTextRank) and per-topic ranking (TopicRank).</li> </ul>"},{"location":"algorithms/multipartite-rank/#reference","title":"Reference","text":"<ul> <li>Unsupervised Keyphrase Extraction with Multipartite Graphs (Boudin, 2018)</li> </ul>"},{"location":"algorithms/position-rank/","title":"PositionRank","text":"<p>PositionRank (Florescu &amp; Caragea, 2017) extends TextRank by weighting words according to their position in the document -- earlier appearances score higher. This captures the common writing convention of introducing key terms early (in titles, abstracts, or opening paragraphs).</p>"},{"location":"algorithms/position-rank/#how-it-works","title":"How It Works","text":"<p>PositionRank modifies the PageRank teleportation vector so that words appearing earlier receive a larger share of the teleport probability. The co-occurrence graph and phrase extraction steps remain the same as BaseTextRank.</p>"},{"location":"algorithms/position-rank/#usage","title":"Usage","text":"<pre><code>from rapid_textrank import PositionRank\n\nextractor = PositionRank(top_n=10)\nresult = extractor.extract_keywords(\"\"\"\nQuantum Computing Advances in 2024\n\nResearchers have made significant breakthroughs in quantum error correction.\nThe quantum computing field continues to evolve rapidly...\n\"\"\")\n\n# \"quantum computing\" and \"quantum\" will rank higher due to early position\n</code></pre> <p>PositionRank is also available via the JSON interface with <code>variant=\"position_rank\"</code>.</p>"},{"location":"algorithms/position-rank/#when-to-use-positionrank","title":"When to Use PositionRank","text":"<p>PositionRank is most effective on short, structured documents where important terms are introduced early:</p> <ul> <li>Academic abstracts -- key contributions are typically stated in the first few sentences.</li> <li>News articles -- the \"inverted pyramid\" style puts the most important facts first.</li> <li>Executive summaries -- themes are laid out upfront before supporting detail.</li> <li>Title + abstract combinations -- concatenate the title and abstract into one string for best results, since the title carries strong positional signal.</li> </ul> <p>For longer documents where key terms are distributed throughout, SingleRank or BaseTextRank may perform better because PositionRank's early-position bias can underweight terms that appear only in later sections.</p>"},{"location":"algorithms/position-rank/#reference","title":"Reference","text":"<ul> <li>PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents (Florescu &amp; Caragea, 2017)</li> </ul>"},{"location":"algorithms/single-rank/","title":"SingleRank","text":"<p>SingleRank (Wan &amp; Xiao, 2008) extends TextRank in two ways: edges are weighted by co-occurrence count (repeated neighbors get stronger connections), and the sliding window ignores sentence boundaries so that terms at the end of one sentence connect to terms at the start of the next.</p>"},{"location":"algorithms/single-rank/#how-it-works","title":"How It Works","text":"<p>In BaseTextRank, edges are binary (present or absent) and the window resets at sentence boundaries. SingleRank changes both behaviors:</p> <ol> <li>Weighted edges -- If two words co-occur within the window multiple times, the edge weight accumulates. Frequently co-occurring pairs get a stronger signal.</li> <li>Cross-sentence windowing -- The sliding window spans across sentence boundaries, so the last words of one sentence and the first words of the next can form edges. This captures co-occurrences that BaseTextRank misses.</li> </ol> <p>PageRank then operates on this weighted graph, and phrase extraction proceeds as usual.</p>"},{"location":"algorithms/single-rank/#usage","title":"Usage","text":"<pre><code>from rapid_textrank import SingleRank\n\nextractor = SingleRank(top_n=10)\nresult = extractor.extract_keywords(\"\"\"\nMachine learning is a powerful tool. Deep learning is a subset of\nmachine learning. Neural networks power deep learning systems.\n\"\"\")\n\n# Cross-sentence co-occurrences strengthen \"machine learning\" edges\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>SingleRank is also available via the JSON interface with <code>variant=\"single_rank\"</code>.</p>"},{"location":"algorithms/single-rank/#when-to-use-singlerank-over-basetextrank","title":"When to Use SingleRank over BaseTextRank","text":"<p>SingleRank works well on longer documents where important terms co-occur across sentence boundaries. The weighted edges amplify frequently co-occurring pairs, giving a clearer signal than the binary edges used by BaseTextRank.</p> <p>Concrete scenarios where SingleRank tends to outperform BaseTextRank:</p> <ul> <li>Long technical documents -- co-occurrences accumulate over many sentences, and the weighted edges surface the dominant term pairs.</li> <li>Documents with short sentences -- when sentences are terse (e.g., bullet-point summaries), cross-sentence windowing recovers co-occurrence signal that would otherwise be lost.</li> <li>Multi-paragraph prose -- important terms often bridge paragraph and sentence boundaries; SingleRank captures these connections.</li> </ul> <p>For short, structured documents (titles, abstracts), PositionRank is usually a better choice. For multi-topic documents, consider TopicRank or MultipartiteRank.</p>"},{"location":"algorithms/single-rank/#reference","title":"Reference","text":"<ul> <li>Single Document Keyphrase Extraction Using Neighborhood Knowledge (Wan &amp; Xiao, 2008)</li> </ul>"},{"location":"algorithms/topic-rank/","title":"TopicRank","text":"<p>TopicRank (Bougouin et al., 2013) clusters similar candidate phrases into topics, builds a graph over those topics, ranks them with PageRank, and then selects the best representative phrase from each top-ranked topic. This approach promotes diversity -- the final keyword list covers distinct themes rather than repeating near-synonyms.</p> <p>JSON Interface Only</p> <p>TopicRank does not have a native Python class. Use the JSON interface with <code>variant=\"topic_rank\"</code> and pre-tokenized input (e.g., from spaCy).</p>"},{"location":"algorithms/topic-rank/#how-it-works","title":"How It Works","text":"<ol> <li>Candidate extraction -- Candidate phrases are identified using POS-filtered noun chunks (same as other variants).</li> <li>Topic clustering -- Candidates are grouped into topics based on string similarity (Jaccard over word sets). The <code>topic_similarity_threshold</code> parameter controls how aggressively candidates are merged.</li> <li>Topic graph -- A graph is built where each node is a topic (cluster). Edges are weighted by the co-occurrence of candidates across different topics.</li> <li>PageRank on topics -- Standard PageRank ranks the topic nodes.</li> <li>Representative selection -- From each top-ranked topic, the best candidate phrase is selected as the representative.</li> </ol>"},{"location":"algorithms/topic-rank/#usage","title":"Usage","text":"<p>TopicRank requires pre-tokenized input, which makes it a natural fit for spaCy-based pipelines.</p>"},{"location":"algorithms/topic-rank/#install-spacy","title":"Install spaCy","text":"<pre><code>pip install rapid_textrank[spacy]\npython -m spacy download en_core_web_sm\n</code></pre>"},{"location":"algorithms/topic-rank/#full-example","title":"Full example","text":"<pre><code>import json\nimport spacy\nfrom rapid_textrank import extract_from_json\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(text)\n\ntokens = []\nfor sent_idx, sent in enumerate(doc.sents):\n    for token in sent:\n        tokens.append({\n            \"text\": token.text,\n            \"lemma\": token.lemma_,\n            \"pos\": token.pos_,\n            \"start\": token.idx,\n            \"end\": token.idx + len(token.text),\n            \"sentence_idx\": sent_idx,\n            \"token_idx\": token.i,\n            \"is_stopword\": token.is_stop,\n        })\n\npayload = {\n    \"tokens\": tokens,\n    \"variant\": \"topic_rank\",\n    \"config\": {\n        \"top_n\": 10,\n        \"language\": \"en\",\n        \"topic_similarity_threshold\": 0.25,\n        \"topic_edge_weight\": 1.0,\n    },\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\nfor phrase in result[\"phrases\"][:10]:\n    print(phrase[\"text\"], phrase[\"score\"])\n</code></pre>"},{"location":"algorithms/topic-rank/#configuration-fields","title":"Configuration Fields","text":"Field Type Default Description <code>topic_similarity_threshold</code> float 0.25 Jaccard similarity threshold for grouping candidates into topics. Higher values produce fewer, larger topics (more aggressive clustering). <code>topic_edge_weight</code> float 1.0 Base weight for edges between topic nodes in the topic graph. <p>These fields are set inside the <code>config</code> object of the JSON payload, alongside standard fields like <code>top_n</code> and <code>language</code>.</p>"},{"location":"algorithms/topic-rank/#when-to-use-topicrank","title":"When to Use TopicRank","text":"<p>TopicRank is designed for documents that span multiple themes, where vanilla TextRank tends to over-represent the dominant topic:</p> <ul> <li>Quarterly reports covering product, finance, security, and compliance.</li> <li>Long-form articles with multiple sections on different subtopics.</li> <li>Meeting notes spanning several agenda items.</li> </ul> <p>If you want topic-based diversity but also need fine-grained candidate distinctions (rather than collapsing each topic to a single representative), consider MultipartiteRank.</p>"},{"location":"algorithms/topic-rank/#reference","title":"Reference","text":"<ul> <li>TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction (Bougouin et al., 2013)</li> </ul>"},{"location":"algorithms/topical-pagerank/","title":"TopicalPageRank","text":"<p>TopicalPageRank (Sterckx et al., 2015) extends SingleRank by biasing the random walk toward topically important words. Instead of uniform teleportation, PageRank uses a personalization vector derived from per-word topic weights.</p> <p>Users supply pre-computed topic weights as a <code>{lemma: weight}</code> dictionary. These typically come from a topic model (e.g., LDA via gensim or sklearn), but any source of word importance scores works -- TF-IDF weights, embedding similarities, domain relevance scores, or hand-picked values. Words absent from the dictionary receive a configurable minimum weight (<code>min_weight</code>, default 0.0).</p>"},{"location":"algorithms/topical-pagerank/#usage","title":"Usage","text":""},{"location":"algorithms/topical-pagerank/#native-python-class","title":"Native Python class","text":"<pre><code>from rapid_textrank import TopicalPageRank\n\n# Topic weights from an external topic model or manual assignment\ntopic_weights = {\n    \"neural\": 0.9,\n    \"network\": 0.8,\n    \"learning\": 0.7,\n    \"deep\": 0.6,\n}\n\nextractor = TopicalPageRank(\n    topic_weights=topic_weights,\n    min_weight=0.01,  # Floor for out-of-vocabulary words\n    top_n=10\n)\n\nresult = extractor.extract_keywords(\"\"\"\nDeep learning is a subset of machine learning that uses artificial neural\nnetworks. Neural networks with many layers can learn complex patterns.\nConvolutional neural networks excel at image recognition tasks.\n\"\"\")\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n\n# Update topic weights for a different document/topic\nresult = extractor.extract_keywords(\n    \"Machine learning enables data-driven decisions...\",\n    topic_weights={\"machine\": 0.9, \"data\": 0.8}\n)\n</code></pre>"},{"location":"algorithms/topical-pagerank/#json-interface","title":"JSON interface","text":"<p>TopicalPageRank is also available via the JSON interface with <code>variant=\"topical_pagerank\"</code> (aliases: <code>\"tpr\"</code>, <code>\"single_tpr\"</code>). Set <code>topic_weights</code> and optionally <code>topic_min_weight</code> in the JSON config:</p> <pre><code>import json\nfrom rapid_textrank import extract_from_json\n\npayload = {\n    \"tokens\": tokens,  # Pre-tokenized (e.g., from spaCy)\n    \"variant\": \"topical_pagerank\",\n    \"config\": {\n        \"top_n\": 10,\n        \"topic_weights\": {\"neural\": 0.9, \"network\": 0.8, \"learning\": 0.7},\n        \"topic_min_weight\": 0.01,\n    },\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\n</code></pre>"},{"location":"algorithms/topical-pagerank/#topicalpagerank-vs-biasedtextrank","title":"TopicalPageRank vs BiasedTextRank","text":"<p>Both variants bias extraction toward specific terms, but they differ in how the bias is specified:</p> <ul> <li>BiasedTextRank takes a list of focus terms and a single <code>bias_weight</code>. It is manual and direct -- good when you know exactly which terms matter.</li> <li>TopicalPageRank takes per-word weights, typically from a topic model. It is data-driven -- good when you want the topic distribution to guide extraction automatically.</li> </ul> <p>Use BiasedTextRank when you have a short, hand-curated focus vocabulary. Use TopicalPageRank when you have a numeric importance score for each word (e.g., from LDA, TF-IDF, or embedding similarity).</p>"},{"location":"algorithms/topical-pagerank/#topic-modeling-is-optional","title":"Topic Modeling is Optional","text":"<p>Despite the name, TopicalPageRank does not require a topic model. You can supply any word-importance dictionary:</p> <ul> <li>TF-IDF weights from a corpus-level vocabulary.</li> <li>Embedding similarities between candidate words and a target concept.</li> <li>Domain relevance scores from a domain-specific lexicon.</li> <li>Hand-picked values when you know the relative importance of key terms.</li> </ul> <p>For details on computing topic weights from a gensim LDA model using the built-in <code>topic_weights_from_lda</code> helper, see Topic Utilities.</p>"},{"location":"algorithms/topical-pagerank/#reference","title":"Reference","text":"<ul> <li>Topical Word Importance for Fast Keyphrase Extraction (Sterckx et al., 2015)</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>rapid_textrank provides three API layers, each suited to different use cases. Pick the one that matches your workflow.</p>"},{"location":"api/#1-convenience-function","title":"1. Convenience Function","text":"<p>The <code>extract_keywords()</code> function is the simplest way to extract keywords. One import, one call, results as a list of <code>Phrase</code> objects. Ideal for quick scripts and prototyping.</p> <pre><code>from rapid_textrank import extract_keywords\nphrases = extract_keywords(\"Your text here.\", top_n=10, language=\"en\")\n</code></pre>"},{"location":"api/#2-extractor-classes","title":"2. Extractor Classes","text":"<p>The extractor classes give you more control over the algorithm variant and configuration. Create a reusable instance with a <code>TextRankConfig</code>, then call <code>extract_keywords()</code> on any number of documents. Six classes are available as native Python objects: BaseTextRank, PositionRank, BiasedTextRank, SingleRank, TopicalPageRank, and MultipartiteRank.</p> <pre><code>from rapid_textrank import PositionRank\nextractor = PositionRank(top_n=10, language=\"en\")\nresult = extractor.extract_keywords(text)\n</code></pre>"},{"location":"api/#3-json-interface","title":"3. JSON Interface","text":"<p>The JSON interface accepts pre-tokenized input as a JSON string and returns results as JSON. This is the right choice when you are tokenizing with spaCy (or another NLP pipeline) and want to pass tokens directly to the Rust core, or when you need batch processing. It is also the only way to use TopicRank.</p> <pre><code>from rapid_textrank import extract_from_json\nresult_json = extract_from_json(json_string)\n</code></pre>"},{"location":"api/#supporting-pages","title":"Supporting Pages","text":"<ul> <li>TextRankConfig -- full parameter reference for fine-tuning the algorithm.</li> <li>Result Objects -- attributes of <code>TextRankResult</code> and <code>Phrase</code>.</li> <li>spaCy Integration -- drop-in pipeline component for spaCy.</li> <li>Topic Utilities -- computing topic weights from LDA for TopicalPageRank.</li> <li>Supported Languages -- the 18 languages available for stopword filtering.</li> </ul>"},{"location":"api/extract-keywords/","title":"extract_keywords()","text":"<p>The convenience function for one-liner keyword extraction. It uses <code>BaseTextRank</code> internally and returns a flat list of <code>Phrase</code> objects.</p>"},{"location":"api/extract-keywords/#signature","title":"Signature","text":"<pre><code>extract_keywords(text: str, top_n: int = 10, language: str = \"en\") -&gt; list[Phrase]\n</code></pre>"},{"location":"api/extract-keywords/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>text</code> <code>str</code> (required) The input text to extract keywords from. <code>top_n</code> <code>int</code> <code>10</code> Number of top keywords to return. <code>language</code> <code>str</code> <code>\"en\"</code> Language code for stopword filtering (see Supported Languages)."},{"location":"api/extract-keywords/#returns","title":"Returns","text":"<p>A <code>list</code> of <code>Phrase</code> objects, sorted by score in descending order.</p>"},{"location":"api/extract-keywords/#example","title":"Example","text":"<pre><code>from rapid_textrank import extract_keywords\n\ntext = \"\"\"\nMachine learning is a subset of artificial intelligence that enables\nsystems to learn and improve from experience. Deep learning, a type of\nmachine learning, uses neural networks with many layers.\n\"\"\"\n\nkeywords = extract_keywords(text, top_n=5, language=\"en\")\nfor phrase in keywords:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>Output:</p> <pre><code>machine learning: 0.2341\ndeep learning: 0.1872\nartificial intelligence: 0.1654\nneural networks: 0.1432\nsystems: 0.0891\n</code></pre>"},{"location":"api/extract-keywords/#when-to-use","title":"When to Use","text":"<p><code>extract_keywords()</code> is the fastest path to results. Use it when:</p> <ul> <li>You want a one-liner with sensible defaults.</li> <li>You do not need to configure the algorithm beyond <code>top_n</code> and <code>language</code>.</li> <li>You are processing a single document and do not need to reuse an extractor instance.</li> </ul> <p>For more control over the algorithm (damping factor, window size, POS filtering, phrase grouping, etc.), use the extractor classes with a <code>TextRankConfig</code>.</p>"},{"location":"api/extractor-classes/","title":"Extractor Classes","text":"<p>The class-based API gives you reusable extractor instances with full configuration control. Six classes are available as native Python objects. TopicRank is available only through the JSON interface.</p>"},{"location":"api/extractor-classes/#class-summary","title":"Class Summary","text":"Class Extra Constructor Params Extra Methods <code>BaseTextRank</code> -- <code>extract_keywords(text)</code> <code>PositionRank</code> -- <code>extract_keywords(text)</code> <code>BiasedTextRank</code> <code>focus_terms</code>, <code>bias_weight=5.0</code> <code>set_focus(terms)</code>, <code>extract_keywords(text, focus_terms=None)</code> <code>SingleRank</code> -- <code>extract_keywords(text)</code> <code>TopicalPageRank</code> <code>topic_weights</code>, <code>min_weight=0.0</code> <code>set_topic_weights(w)</code>, <code>extract_keywords(text, topic_weights=None)</code> <code>MultipartiteRank</code> <code>similarity_threshold=0.26</code>, <code>alpha=1.1</code> <code>extract_keywords(text)</code> <p>All classes share these constructor parameters:</p> Parameter Type Default Description <code>config</code> <code>TextRankConfig</code> <code>None</code> Full configuration object (see TextRankConfig). Overrides all defaults. <code>top_n</code> <code>int</code> <code>None</code> Number of results. Overrides <code>config.top_n</code> if both are provided. <code>language</code> <code>str</code> <code>None</code> Language for stopword filtering. Overrides <code>config.language</code> if both are provided. <p>All classes return a <code>TextRankResult</code> from <code>extract_keywords()</code>.</p>"},{"location":"api/extractor-classes/#basetextrank","title":"BaseTextRank","text":"<p>The standard TextRank implementation. A good starting point for general-purpose keyword extraction.</p> <pre><code>from rapid_textrank import BaseTextRank\n\nextractor = BaseTextRank(top_n=10, language=\"en\")\nresult = extractor.extract_keywords(text)\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#positionrank","title":"PositionRank","text":"<p>Weights words by their position in the document -- earlier appearances score higher. Useful for academic papers, news articles, and executive summaries where key information appears early.</p> <pre><code>from rapid_textrank import PositionRank\n\nextractor = PositionRank(top_n=10, language=\"en\")\nresult = extractor.extract_keywords(\"\"\"\nQuantum Computing Advances in 2024\n\nResearchers have made significant breakthroughs in quantum error correction.\nThe quantum computing field continues to evolve rapidly...\n\"\"\")\n\n# \"quantum computing\" ranks higher due to early position\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#biasedtextrank","title":"BiasedTextRank","text":"<p>Steers extraction toward specific topics using focus terms. The <code>bias_weight</code> parameter controls how strongly results favor the focus terms.</p>"},{"location":"api/extractor-classes/#constructor","title":"Constructor","text":"<pre><code>BiasedTextRank(\n    focus_terms=None,       # list[str] -- terms to bias toward\n    bias_weight=5.0,        # float -- higher = stronger bias\n    config=None,\n    top_n=None,\n    language=None,\n)\n</code></pre>"},{"location":"api/extractor-classes/#usage","title":"Usage","text":"<pre><code>from rapid_textrank import BiasedTextRank\n\nextractor = BiasedTextRank(\n    focus_terms=[\"security\", \"privacy\"],\n    bias_weight=5.0,\n    top_n=10,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(\"\"\"\nModern web applications must balance user experience with security.\nPrivacy regulations require careful data handling. Performance\noptimizations should not compromise security measures.\n\"\"\")\n\n# Results will favor security/privacy-related phrases\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#updating-focus-terms","title":"Updating focus terms","text":"<p>You can update focus terms on an existing extractor in two ways:</p> <pre><code># Option 1: set_focus() method\nextractor.set_focus([\"encryption\", \"audit\"])\nresult = extractor.extract_keywords(text)\n\n# Option 2: pass focus_terms per call\nresult = extractor.extract_keywords(text, focus_terms=[\"neural\", \"network\"])\n</code></pre>"},{"location":"api/extractor-classes/#singlerank","title":"SingleRank","text":"<p>Extends TextRank with weighted co-occurrence edges and cross-sentence windowing. Edges are weighted by co-occurrence count, and the sliding window ignores sentence boundaries.</p> <pre><code>from rapid_textrank import SingleRank\n\nextractor = SingleRank(top_n=10, language=\"en\")\nresult = extractor.extract_keywords(\"\"\"\nMachine learning is a powerful tool. Deep learning is a subset of\nmachine learning. Neural networks power deep learning systems.\n\"\"\")\n\n# Cross-sentence co-occurrences strengthen \"machine learning\" edges\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#topicalpagerank","title":"TopicalPageRank","text":"<p>Extends SingleRank by biasing the random walk toward topically important words. Supply per-word topic weights as a <code>{lemma: weight}</code> dictionary -- typically from a topic model (LDA, TF-IDF, etc.), but any source of word importance scores works.</p>"},{"location":"api/extractor-classes/#constructor_1","title":"Constructor","text":"<pre><code>TopicalPageRank(\n    topic_weights=None,     # dict[str, float] -- per-lemma importance weights\n    min_weight=0.0,         # float -- floor for out-of-vocabulary words\n    config=None,\n    top_n=None,\n    language=None,\n)\n</code></pre>"},{"location":"api/extractor-classes/#usage_1","title":"Usage","text":"<pre><code>from rapid_textrank import TopicalPageRank\n\ntopic_weights = {\n    \"neural\": 0.9,\n    \"network\": 0.8,\n    \"learning\": 0.7,\n    \"deep\": 0.6,\n}\n\nextractor = TopicalPageRank(\n    topic_weights=topic_weights,\n    min_weight=0.01,\n    top_n=10,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(\"\"\"\nDeep learning is a subset of machine learning that uses artificial neural\nnetworks. Neural networks with many layers can learn complex patterns.\nConvolutional neural networks excel at image recognition tasks.\n\"\"\")\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#updating-topic-weights","title":"Updating topic weights","text":"<pre><code># Option 1: set_topic_weights() method\nextractor.set_topic_weights({\"machine\": 0.9, \"data\": 0.8})\nresult = extractor.extract_keywords(text)\n\n# Option 2: pass topic_weights per call\nresult = extractor.extract_keywords(text, topic_weights={\"machine\": 0.9, \"data\": 0.8})\n</code></pre> <p>See Topic Utilities for computing topic weights from LDA.</p>"},{"location":"api/extractor-classes/#multipartiterank","title":"MultipartiteRank","text":"<p>Builds a k-partite directed graph where candidates from different topic clusters are connected. Intra-topic edges are removed to reduce competition between similar candidates. An <code>alpha</code> weight adjustment boosts the first-occurring variant in each topic cluster, encoding positional preference.</p>"},{"location":"api/extractor-classes/#constructor_2","title":"Constructor","text":"<pre><code>MultipartiteRank(\n    similarity_threshold=0.26,  # float -- Jaccard threshold for topic clustering\n    alpha=1.1,                  # float -- position boost strength (0 = disabled)\n    config=None,\n    top_n=None,\n    language=None,\n)\n</code></pre>"},{"location":"api/extractor-classes/#usage_2","title":"Usage","text":"<pre><code>from rapid_textrank import MultipartiteRank\n\nextractor = MultipartiteRank(\n    similarity_threshold=0.26,\n    alpha=1.1,\n    top_n=10,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(\"\"\"\nMachine learning is a powerful tool for data analysis. Deep learning\nis a subset of machine learning. Neural networks power deep learning\nsystems. Convolutional neural networks excel at image recognition.\n\"\"\")\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/extractor-classes/#topicrank-json-only","title":"TopicRank (JSON only)","text":"<p>TopicRank clusters similar candidate phrases into topics, ranks the topics, then selects representatives. It is available only through the JSON interface with <code>variant=\"topic_rank\"</code>. This is because TopicRank works best with external tokenization (e.g., spaCy), which provides accurate POS tags and lemmatization for the clustering step.</p>"},{"location":"api/extractor-classes/#using-textrankconfig-with-extractor-classes","title":"Using TextRankConfig with Extractor Classes","text":"<p>Any extractor class accepts a <code>TextRankConfig</code> for full control:</p> <pre><code>from rapid_textrank import BaseTextRank, TextRankConfig\n\nconfig = TextRankConfig(\n    damping=0.85,\n    window_size=4,\n    top_n=15,\n    min_phrase_length=2,\n    max_phrase_length=4,\n    include_pos=[\"NOUN\", \"ADJ\", \"PROPN\"],\n    phrase_grouping=\"scrubbed_text\",\n    language=\"en\",\n)\n\nextractor = BaseTextRank(config=config)\nresult = extractor.extract_keywords(text)\n</code></pre> <p>The <code>top_n</code> and <code>language</code> shortcut parameters override the corresponding values in <code>config</code> if both are provided. See TextRankConfig for the full parameter reference.</p>"},{"location":"api/json-interface/","title":"JSON Interface","text":"<p>The JSON interface accepts pre-tokenized input as JSON strings and returns results as JSON strings. This minimizes Python-to-Rust overhead when you already have tokenized data (e.g., from spaCy) and enables batch processing. It is also the only way to use TopicRank.</p>"},{"location":"api/json-interface/#functions","title":"Functions","text":""},{"location":"api/json-interface/#extract_from_json","title":"extract_from_json","text":"<p>Process a single document.</p> <pre><code>from rapid_textrank import extract_from_json\nimport json\n\nresult_json = extract_from_json(json_str)\nresult = json.loads(result_json)\n</code></pre> <p>Signature: <code>extract_from_json(json_input: str) -&gt; str</code></p> <ul> <li>json_input -- a JSON string containing a single <code>JsonDocument</code> object.</li> <li>Returns -- a JSON string containing the extraction result (phrases, converged, iterations).</li> </ul>"},{"location":"api/json-interface/#extract_batch_from_json","title":"extract_batch_from_json","text":"<p>Process multiple documents in a single call. Documents are processed sequentially in the Rust core.</p> <pre><code>from rapid_textrank import extract_batch_from_json\nimport json\n\nresults_json = extract_batch_from_json(json_str)\nresults = json.loads(results_json)  # list of result objects\n</code></pre> <p>Signature: <code>extract_batch_from_json(json_input: str) -&gt; str</code></p> <ul> <li>json_input -- a JSON string containing an array of <code>JsonDocument</code> objects.</li> <li>Returns -- a JSON string containing an array of result objects.</li> </ul>"},{"location":"api/json-interface/#input-schema","title":"Input Schema","text":""},{"location":"api/json-interface/#jsondocument","title":"JsonDocument","text":"<p>The top-level object for a single document:</p> <pre><code>{\n    \"tokens\": [ ... ],\n    \"variant\": \"textrank\",\n    \"config\": { ... }\n}\n</code></pre> Field Type Required Description <code>tokens</code> <code>array[JsonToken]</code> Yes Array of pre-tokenized tokens. <code>variant</code> <code>string</code> No Algorithm variant (default: <code>\"textrank\"</code>). See variant table below. <code>config</code> <code>object</code> No Configuration parameters. Accepts all TextRankConfig fields plus variant-specific fields."},{"location":"api/json-interface/#jsontoken","title":"JsonToken","text":"<p>Each token in the <code>tokens</code> array:</p> <pre><code>{\n    \"text\": \"Machine\",\n    \"lemma\": \"machine\",\n    \"pos\": \"NOUN\",\n    \"start\": 0,\n    \"end\": 7,\n    \"sentence_idx\": 0,\n    \"token_idx\": 0,\n    \"is_stopword\": false\n}\n</code></pre> Field Type Description <code>text</code> <code>string</code> Surface form of the token. <code>lemma</code> <code>string</code> Lemmatized form. <code>pos</code> <code>string</code> Universal POS tag (e.g., <code>\"NOUN\"</code>, <code>\"VERB\"</code>, <code>\"ADJ\"</code>). <code>start</code> <code>int</code> Character start offset in the original text. <code>end</code> <code>int</code> Character end offset in the original text. <code>sentence_idx</code> <code>int</code> 0-based sentence index. <code>token_idx</code> <code>int</code> 0-based token index within the document. <code>is_stopword</code> <code>bool</code> Whether this token is a stopword. Defaults to <code>false</code> if omitted."},{"location":"api/json-interface/#variant-strings","title":"Variant Strings","text":"Variant Accepted String Values BaseTextRank <code>\"textrank\"</code> (default), <code>\"text_rank\"</code>, <code>\"base\"</code> PositionRank <code>\"position_rank\"</code>, <code>\"positionrank\"</code>, <code>\"position\"</code> BiasedTextRank <code>\"biased_textrank\"</code>, <code>\"biased\"</code>, <code>\"biasedtextrank\"</code> TopicRank <code>\"topic_rank\"</code>, <code>\"topicrank\"</code>, <code>\"topic\"</code> SingleRank <code>\"single_rank\"</code>, <code>\"singlerank\"</code>, <code>\"single\"</code> TopicalPageRank <code>\"topical_pagerank\"</code>, <code>\"topicalpagerank\"</code>, <code>\"tpr\"</code>, <code>\"single_tpr\"</code> MultipartiteRank <code>\"multipartite_rank\"</code>, <code>\"multipartiterank\"</code>, <code>\"multipartite\"</code>, <code>\"mpr\"</code>"},{"location":"api/json-interface/#variant-specific-config-fields","title":"Variant-Specific Config Fields","text":"<p>In addition to the standard TextRankConfig fields, each variant accepts additional config parameters:</p>"},{"location":"api/json-interface/#biased_textrank","title":"biased_textrank","text":"Field Type Default Description <code>focus_terms</code> <code>list[str]</code> <code>[]</code> Terms to bias extraction toward. <code>bias_weight</code> <code>float</code> <code>5.0</code> Strength of the bias toward focus terms."},{"location":"api/json-interface/#topic_rank","title":"topic_rank","text":"Field Type Default Description <code>topic_similarity_threshold</code> <code>float</code> <code>0.25</code> Similarity threshold for topic clustering. Higher values produce fewer, larger topics. <code>topic_edge_weight</code> <code>float</code> <code>1.0</code> Weight for edges between topic nodes."},{"location":"api/json-interface/#topical_pagerank","title":"topical_pagerank","text":"Field Type Default Description <code>topic_weights</code> <code>dict[str, float]</code> <code>{}</code> Per-lemma importance weights (e.g., from LDA). <code>topic_min_weight</code> <code>float</code> <code>0.0</code> Floor weight for words not in <code>topic_weights</code>."},{"location":"api/json-interface/#multipartite_rank","title":"multipartite_rank","text":"Field Type Default Description <code>multipartite_alpha</code> <code>float</code> <code>1.1</code> Position boost strength. Set to <code>0</code> to disable. <code>multipartite_similarity_threshold</code> <code>float</code> <code>0.26</code> Jaccard threshold for topic clustering."},{"location":"api/json-interface/#single-document-example","title":"Single Document Example","text":"<pre><code>import json\nfrom rapid_textrank import extract_from_json\n\ndoc = {\n    \"tokens\": [\n        {\n            \"text\": \"Machine\",\n            \"lemma\": \"machine\",\n            \"pos\": \"NOUN\",\n            \"start\": 0,\n            \"end\": 7,\n            \"sentence_idx\": 0,\n            \"token_idx\": 0,\n            \"is_stopword\": False,\n        },\n        {\n            \"text\": \"learning\",\n            \"lemma\": \"learning\",\n            \"pos\": \"NOUN\",\n            \"start\": 8,\n            \"end\": 16,\n            \"sentence_idx\": 0,\n            \"token_idx\": 1,\n            \"is_stopword\": False,\n        },\n        # ... more tokens\n    ],\n    \"variant\": \"textrank\",\n    \"config\": {\n        \"top_n\": 10,\n        \"language\": \"en\",\n        \"stopwords\": [\"nlp\", \"transformers\"],\n    },\n}\n\nresult_json = extract_from_json(json.dumps(doc))\nresult = json.loads(result_json)\n\nfor phrase in result[\"phrases\"]:\n    print(f\"{phrase['text']}: {phrase['score']:.4f}\")\n</code></pre>"},{"location":"api/json-interface/#batch-processing-example","title":"Batch Processing Example","text":"<pre><code>import json\nfrom rapid_textrank import extract_batch_from_json\n\ndocs = [\n    {\n        \"tokens\": tokens_doc1,\n        \"variant\": \"textrank\",\n        \"config\": {\"top_n\": 5},\n    },\n    {\n        \"tokens\": tokens_doc2,\n        \"variant\": \"position_rank\",\n        \"config\": {\"top_n\": 10},\n    },\n    {\n        \"tokens\": tokens_doc3,\n        \"variant\": \"biased_textrank\",\n        \"config\": {\n            \"top_n\": 10,\n            \"focus_terms\": [\"security\", \"privacy\"],\n            \"bias_weight\": 5.0,\n        },\n    },\n]\n\nresults_json = extract_batch_from_json(json.dumps(docs))\nresults = json.loads(results_json)\n\nfor i, result in enumerate(results):\n    print(f\"Document {i}: {len(result['phrases'])} phrases\")\n    for phrase in result[\"phrases\"]:\n        print(f\"  {phrase['text']}: {phrase['score']:.4f}\")\n</code></pre>"},{"location":"api/json-interface/#topicrank-via-json","title":"TopicRank via JSON","text":"<p>TopicRank is only available through the JSON interface. This example uses spaCy for tokenization:</p> <pre><code>import json\nimport spacy\nfrom rapid_textrank import extract_from_json\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Your text here...\")\n\ntokens = []\nfor sent_idx, sent in enumerate(doc.sents):\n    for token in sent:\n        tokens.append({\n            \"text\": token.text,\n            \"lemma\": token.lemma_,\n            \"pos\": token.pos_,\n            \"start\": token.idx,\n            \"end\": token.idx + len(token.text),\n            \"sentence_idx\": sent_idx,\n            \"token_idx\": token.i,\n            \"is_stopword\": token.is_stop,\n        })\n\npayload = {\n    \"tokens\": tokens,\n    \"variant\": \"topic_rank\",\n    \"config\": {\n        \"top_n\": 10,\n        \"language\": \"en\",\n        \"topic_similarity_threshold\": 0.25,\n        \"topic_edge_weight\": 1.0,\n    },\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\nfor phrase in result[\"phrases\"]:\n    print(f\"{phrase['text']}: {phrase['score']:.4f}\")\n</code></pre>"},{"location":"api/json-interface/#stopword-handling","title":"Stopword Handling","text":"<p>The JSON interface supports two complementary mechanisms for stopword filtering:</p> <ol> <li> <p>Per-token <code>is_stopword</code> field -- set this to <code>true</code> on individual tokens (e.g., using <code>token.is_stop</code> from spaCy). This gives you full control over which tokens are treated as stopwords.</p> </li> <li> <p><code>config.language</code> and <code>config.stopwords</code> -- when <code>config.stopwords</code> is a non-empty list, the Rust core loads the built-in stopword list for the configured language, extends it with your custom stopwords, and marks any matching tokens as stopwords (in addition to any tokens already marked via <code>is_stopword</code>).</p> </li> </ol> <p>Both mechanisms can be used together. A token is treated as a stopword if <code>is_stopword</code> is <code>true</code> on the token itself OR if it matches the built-in + custom stopword list.</p>"},{"location":"api/result-objects/","title":"Result Objects","text":"<p>All extractor classes return a <code>TextRankResult</code> containing a list of <code>Phrase</code> objects. This page documents both.</p>"},{"location":"api/result-objects/#textrankresult","title":"TextRankResult","text":"<p>Returned by every <code>extract_keywords()</code> call on an extractor class.</p>"},{"location":"api/result-objects/#attributes","title":"Attributes","text":"Attribute Type Description <code>phrases</code> <code>list[Phrase]</code> List of extracted phrases, sorted by score in descending order. <code>converged</code> <code>bool</code> Whether the PageRank iteration converged within <code>max_iterations</code>. <code>iterations</code> <code>int</code> Number of PageRank iterations actually run."},{"location":"api/result-objects/#methods","title":"Methods","text":"Method Returns Description <code>as_tuples()</code> <code>list[tuple[str, float]]</code> Returns phrases as <code>[(text, score), ...]</code> tuples. Useful for quick inspection or serialization. <code>__len__()</code> <code>int</code> Number of phrases. Supports <code>len(result)</code>. <code>__getitem__(idx)</code> <code>Phrase</code> Index into the phrase list. Supports <code>result[0]</code>."},{"location":"api/result-objects/#example","title":"Example","text":"<pre><code>from rapid_textrank import BaseTextRank\n\nextractor = BaseTextRank(top_n=5, language=\"en\")\nresult = extractor.extract_keywords(\"Machine learning is a subset of artificial intelligence.\")\n\n# Check convergence\nprint(f\"Converged: {result.converged}\")\nprint(f\"Iterations: {result.iterations}\")\n\n# Iterate over phrases\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n\n# Quick tuple output\nprint(result.as_tuples())\n# [('machine learning', 0.2341), ('artificial intelligence', 0.1654), ...]\n\n# Length and indexing\nprint(len(result))     # 5\nprint(result[0].text)  # 'machine learning'\n</code></pre>"},{"location":"api/result-objects/#phrase","title":"Phrase","text":"<p>Each item in <code>TextRankResult.phrases</code> is a <code>Phrase</code> object.</p>"},{"location":"api/result-objects/#attributes_1","title":"Attributes","text":"Attribute Type Description <code>text</code> <code>str</code> The phrase text as it appears in the document (e.g., <code>\"machine learning\"</code>). <code>lemma</code> <code>str</code> Lemmatized form of the phrase (e.g., <code>\"machine learning\"</code>). Useful for deduplication. <code>score</code> <code>float</code> TextRank score. Higher is more important. Scores are not normalized to any fixed range. <code>count</code> <code>int</code> Number of times this phrase (or its variants) appears in the text. <code>rank</code> <code>int</code> 1-indexed rank position. The top-scoring phrase has <code>rank=1</code>."},{"location":"api/result-objects/#example_1","title":"Example","text":"<pre><code>result = extractor.extract_keywords(text)\n\nfor phrase in result.phrases:\n    print(f\"Text:  {phrase.text}\")\n    print(f\"Lemma: {phrase.lemma}\")\n    print(f\"Score: {phrase.score:.4f}\")\n    print(f\"Count: {phrase.count}\")\n    print(f\"Rank:  {phrase.rank}\")\n    print()\n</code></pre>"},{"location":"api/result-objects/#string-representation","title":"String representation","text":"<p><code>Phrase</code> supports both <code>repr()</code> and <code>str()</code>:</p> <pre><code>phrase = result.phrases[0]\n\nrepr(phrase)  # \"Phrase(text='machine learning', score=0.2341, rank=1)\"\nstr(phrase)   # \"machine learning\"\n</code></pre>"},{"location":"api/result-objects/#json-result-format","title":"JSON Result Format","text":"<p>When using the JSON interface, results are returned as a JSON string with the same structure:</p> <pre><code>{\n    \"phrases\": [\n        {\n            \"text\": \"machine learning\",\n            \"lemma\": \"machine learning\",\n            \"score\": 0.2341,\n            \"count\": 2,\n            \"rank\": 1\n        }\n    ],\n    \"converged\": true,\n    \"iterations\": 12\n}\n</code></pre>"},{"location":"api/spacy-integration/","title":"spaCy Integration","text":"<p>rapid_textrank provides a spaCy pipeline component that uses the Rust core for keyword extraction while integrating seamlessly with spaCy's NLP pipeline. It can be used as a drop-in replacement for pytextrank with significantly better performance.</p>"},{"location":"api/spacy-integration/#installation","title":"Installation","text":"<pre><code>pip install rapid_textrank[spacy]\npython -m spacy download en_core_web_sm\n</code></pre>"},{"location":"api/spacy-integration/#basic-usage","title":"Basic Usage","text":"<pre><code>import spacy\nimport rapid_textrank.spacy_component  # registers the pipeline factory\n\nnlp = spacy.load(\"en_core_web_sm\")\nnlp.add_pipe(\"rapid_textrank\")\n\ndoc = nlp(\"Machine learning is a subset of artificial intelligence.\")\nfor phrase in doc._.phrases[:5]:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>Importing <code>rapid_textrank.spacy_component</code> registers a spaCy pipeline factory named <code>\"rapid_textrank\"</code>. After <code>add_pipe</code>, every <code>nlp(text)</code> call will automatically run keyword extraction and store results on the <code>Doc</code>.</p>"},{"location":"api/spacy-integration/#doc-extensions","title":"Doc Extensions","text":"<p>The component registers two custom extensions on <code>spacy.tokens.Doc</code>:</p> Extension Type Description <code>doc._.phrases</code> <code>list[Phrase]</code> Extracted phrases, sorted by score descending. Each <code>Phrase</code> has <code>text</code>, <code>lemma</code>, <code>score</code>, <code>count</code>, and <code>rank</code> attributes. <code>doc._.textrank_result</code> <code>RustTextRankResult</code> Full result object with <code>phrases</code>, <code>converged</code>, and <code>iterations</code> attributes."},{"location":"api/spacy-integration/#configuration","title":"Configuration","text":"<p>The pipeline component accepts all configuration parameters at <code>add_pipe</code> time:</p> <pre><code>nlp.add_pipe(\"rapid_textrank\", config={\n    \"top_n\": 15,\n    \"language\": \"en\",\n    \"include_pos\": [\"NOUN\", \"ADJ\", \"PROPN\"],\n    \"use_pos_in_nodes\": True,\n    \"phrase_grouping\": \"scrubbed_text\",\n    \"window_size\": 4,\n    \"min_phrase_length\": 2,\n    \"max_phrase_length\": 4,\n    \"stopwords\": [\"example\", \"custom\"],\n    \"variant\": \"textrank\",\n})\n</code></pre>"},{"location":"api/spacy-integration/#supported-config-parameters","title":"Supported config parameters","text":"Parameter Type Default Description <code>damping</code> <code>float</code> <code>0.85</code> PageRank damping factor. <code>max_iterations</code> <code>int</code> <code>100</code> Maximum PageRank iterations. <code>convergence_threshold</code> <code>float</code> <code>1e-6</code> Convergence threshold. <code>window_size</code> <code>int</code> <code>3</code> Co-occurrence window size. <code>top_n</code> <code>int</code> <code>10</code> Number of phrases to return. <code>min_phrase_length</code> <code>int</code> <code>1</code> Minimum words in a phrase. <code>max_phrase_length</code> <code>int</code> <code>4</code> Maximum words in a phrase. <code>score_aggregation</code> <code>str</code> <code>\"sum\"</code> Score aggregation method. <code>include_pos</code> <code>list[str]</code> <code>[\"ADJ\",\"NOUN\",\"PROPN\",\"VERB\"]</code> POS tags to include. <code>use_pos_in_nodes</code> <code>bool</code> <code>True</code> Use lemma+POS as graph node keys. <code>phrase_grouping</code> <code>str</code> <code>\"scrubbed_text\"</code> Phrase grouping strategy. <code>language</code> <code>str</code> <code>\"en\"</code> Language for stopwords. <code>stopwords</code> <code>list[str]</code> <code>None</code> Additional stopwords. <code>variant</code> <code>str</code> <code>\"textrank\"</code> Algorithm variant string. <p>The <code>variant</code> parameter accepts the same variant strings as the JSON interface (e.g., <code>\"position_rank\"</code>, <code>\"biased_textrank\"</code>, etc.).</p>"},{"location":"api/spacy-integration/#how-it-works","title":"How It Works","text":"<p>Under the hood, the spaCy component:</p> <ol> <li>Iterates over spaCy tokens and converts them to the JSON token format (using <code>token.text</code>, <code>token.lemma_</code>, <code>token.pos_</code>, <code>token.idx</code>, <code>token.i</code>, <code>token.is_stop</code>).</li> <li>Calls <code>extract_from_json()</code> with the token data and configuration.</li> <li>Parses the JSON result and stores <code>Phrase</code> objects on <code>doc._.phrases</code>.</li> </ol> <p>This means you get the benefit of spaCy's tokenization, lemmatization, and POS tagging combined with rapid_textrank's fast Rust-based ranking.</p>"},{"location":"api/spacy-integration/#serialization","title":"Serialization","text":"<p>The component supports spaCy's <code>to_disk</code> / <code>from_disk</code> methods, so pipelines can be saved and loaded:</p> <pre><code>nlp.to_disk(\"./my_pipeline\")\nnlp2 = spacy.load(\"./my_pipeline\")\n</code></pre>"},{"location":"api/supported-languages/","title":"Supported Languages","text":"<p>rapid_textrank includes built-in stopword lists for 18 languages. These are used for stopword filtering in all APIs: the convenience function, extractor classes, the JSON interface, and the spaCy component.</p>"},{"location":"api/supported-languages/#language-codes","title":"Language Codes","text":"Code Language Code Language Code Language <code>en</code> English <code>de</code> German <code>fr</code> French <code>es</code> Spanish <code>it</code> Italian <code>pt</code> Portuguese <code>nl</code> Dutch <code>ru</code> Russian <code>sv</code> Swedish <code>no</code> Norwegian <code>da</code> Danish <code>fi</code> Finnish <code>hu</code> Hungarian <code>tr</code> Turkish <code>pl</code> Polish <code>ar</code> Arabic <code>zh</code> Chinese <code>ja</code> Japanese"},{"location":"api/supported-languages/#usage","title":"Usage","text":"<p>Pass the language code to the <code>language</code> parameter in any API:</p> <pre><code>from rapid_textrank import extract_keywords\n\n# English (default)\nphrases = extract_keywords(text, language=\"en\")\n\n# German\nphrases = extract_keywords(german_text, language=\"de\")\n\n# Chinese\nphrases = extract_keywords(chinese_text, language=\"zh\")\n</code></pre> <p>With extractor classes:</p> <pre><code>from rapid_textrank import BaseTextRank\n\nextractor = BaseTextRank(top_n=10, language=\"fr\")\nresult = extractor.extract_keywords(french_text)\n</code></pre> <p>With <code>TextRankConfig</code>:</p> <pre><code>from rapid_textrank import TextRankConfig, BaseTextRank\n\nconfig = TextRankConfig(language=\"ja\")\nextractor = BaseTextRank(config=config)\n</code></pre> <p>In the JSON interface:</p> <pre><code>{\n    \"tokens\": [ ... ],\n    \"config\": {\n        \"language\": \"es\"\n    }\n}\n</code></pre>"},{"location":"api/supported-languages/#inspecting-stopwords","title":"Inspecting Stopwords","text":"<p>You can retrieve the built-in stopword list for any supported language:</p> <pre><code>import rapid_textrank as rt\n\nstopwords = rt.get_stopwords(\"en\")\nprint(f\"English stopwords: {len(stopwords)} words\")\nprint(stopwords[:10])\n\nstopwords_de = rt.get_stopwords(\"de\")\nprint(f\"German stopwords: {len(stopwords_de)} words\")\n</code></pre>"},{"location":"api/supported-languages/#extending-stopwords","title":"Extending Stopwords","text":"<p>The built-in lists can be extended with domain-specific terms using the <code>stopwords</code> parameter. These additional words are merged with the built-in list, not used as a replacement.</p> <pre><code>from rapid_textrank import TextRankConfig, BaseTextRank\n\nconfig = TextRankConfig(\n    language=\"en\",\n    stopwords=[\"data\", \"system\", \"model\"],  # added to built-in English stopwords\n)\n\nextractor = BaseTextRank(config=config)\n</code></pre> <p>In the JSON interface, the same applies via <code>config.stopwords</code>:</p> <pre><code>{\n    \"tokens\": [ ... ],\n    \"config\": {\n        \"language\": \"en\",\n        \"stopwords\": [\"data\", \"system\", \"model\"]\n    }\n}\n</code></pre>"},{"location":"api/textrank-config/","title":"TextRankConfig","text":"<p><code>TextRankConfig</code> controls every tunable aspect of the TextRank algorithm. Pass it to any extractor class via the <code>config</code> parameter.</p>"},{"location":"api/textrank-config/#parameter-reference","title":"Parameter Reference","text":"Parameter Type Default Description <code>damping</code> <code>float</code> <code>0.85</code> PageRank damping factor (0-1). Higher values give more weight to graph structure vs. uniform distribution. <code>max_iterations</code> <code>int</code> <code>100</code> Maximum number of PageRank iterations. <code>convergence_threshold</code> <code>float</code> <code>1e-6</code> PageRank convergence threshold. Iteration stops when the score change between iterations falls below this value. <code>window_size</code> <code>int</code> <code>3</code> Co-occurrence window size. Two words are connected in the graph if they appear within this many words of each other. <code>top_n</code> <code>int</code> <code>10</code> Number of top-scoring phrases to return. <code>min_phrase_length</code> <code>int</code> <code>1</code> Minimum number of words in a phrase. Set to <code>2</code> to exclude single-word results. <code>max_phrase_length</code> <code>int</code> <code>4</code> Maximum number of words in a phrase. <code>score_aggregation</code> <code>str</code> <code>\"sum\"</code> How to combine individual word scores into a phrase score. Options: <code>\"sum\"</code>, <code>\"mean\"</code>, <code>\"max\"</code>, <code>\"rms\"</code> (root mean square). <code>language</code> <code>str</code> <code>\"en\"</code> Language code for built-in stopword filtering. See Supported Languages. <code>use_edge_weights</code> <code>bool</code> <code>True</code> Whether to use weighted edges in the co-occurrence graph. When <code>False</code>, all edges have weight 1. <code>include_pos</code> <code>list[str]</code> <code>[\"NOUN\",\"ADJ\",\"PROPN\",\"VERB\"]</code> POS tags to include in the graph. Only words with these POS tags become graph nodes. <code>stopwords</code> <code>list[str]</code> <code>[]</code> Additional stopwords that extend the built-in list for the selected language. <code>use_pos_in_nodes</code> <code>bool</code> <code>True</code> If <code>True</code>, graph nodes are keyed by <code>\"lemma|POS\"</code> (e.g., <code>\"learning|NOUN\"</code>). If <code>False</code>, nodes are keyed by lemma only. <code>phrase_grouping</code> <code>str</code> <code>\"scrubbed_text\"</code> How to group phrase variants. <code>\"scrubbed_text\"</code> groups by lowercased surface form. <code>\"lemma\"</code> groups by lemmatized form."},{"location":"api/textrank-config/#full-example","title":"Full Example","text":"<pre><code>from rapid_textrank import TextRankConfig, BaseTextRank\n\nconfig = TextRankConfig(\n    damping=0.85,\n    max_iterations=100,\n    convergence_threshold=1e-6,\n    window_size=3,\n    top_n=10,\n    min_phrase_length=1,\n    max_phrase_length=4,\n    score_aggregation=\"sum\",\n    language=\"en\",\n    use_edge_weights=True,\n    include_pos=[\"NOUN\", \"ADJ\", \"PROPN\", \"VERB\"],\n    use_pos_in_nodes=True,\n    phrase_grouping=\"scrubbed_text\",\n    stopwords=[\"custom\", \"terms\"],\n)\n\nextractor = BaseTextRank(config=config)\nresult = extractor.extract_keywords(text)\n</code></pre>"},{"location":"api/textrank-config/#common-tuning-patterns","title":"Common Tuning Patterns","text":""},{"location":"api/textrank-config/#seo-style-multi-word-phrases","title":"SEO-style multi-word phrases","text":"<p>Force 2-4 word phrases, noun-heavy, with scrubbed-text grouping:</p> <pre><code>config = TextRankConfig(\n    min_phrase_length=2,\n    max_phrase_length=4,\n    include_pos=[\"NOUN\", \"ADJ\", \"PROPN\"],\n    phrase_grouping=\"scrubbed_text\",\n)\n</code></pre>"},{"location":"api/textrank-config/#larger-co-occurrence-window","title":"Larger co-occurrence window","text":"<p>A wider window captures longer-range relationships:</p> <pre><code>config = TextRankConfig(window_size=6)\n</code></pre>"},{"location":"api/textrank-config/#stricter-convergence","title":"Stricter convergence","text":"<p>More iterations with a tighter threshold can improve score stability on long documents:</p> <pre><code>config = TextRankConfig(\n    max_iterations=200,\n    convergence_threshold=1e-8,\n)\n</code></pre>"},{"location":"api/textrank-config/#adding-domain-specific-stopwords","title":"Adding domain-specific stopwords","text":"<p>Extend the built-in stopword list with terms that are too common in your domain:</p> <pre><code>config = TextRankConfig(\n    language=\"en\",\n    stopwords=[\"data\", \"system\", \"model\", \"2024\"],\n)\n</code></pre>"},{"location":"api/textrank-config/#notes","title":"Notes","text":"<ul> <li>The <code>include_pos</code> parameter expects Universal POS tags as strings (the same tags spaCy uses): <code>\"NOUN\"</code>, <code>\"VERB\"</code>, <code>\"ADJ\"</code>, <code>\"ADV\"</code>, <code>\"PROPN\"</code>, etc.</li> <li>The <code>stopwords</code> parameter extends the built-in list -- it does not replace it. To use only your custom stopwords without built-in ones, you would need to use the JSON interface with <code>is_stopword</code> flags on individual tokens.</li> <li><code>TextRankConfig</code> is validated on construction. Invalid combinations (e.g., negative damping) raise a <code>ValueError</code>.</li> </ul>"},{"location":"api/topic-utilities/","title":"Topic Utilities","text":"<p>rapid_textrank includes a helper function for computing per-lemma topic weights from a trained gensim LDA model. These weights can be passed directly to <code>TopicalPageRank</code> for topic-model-guided keyword extraction.</p>"},{"location":"api/topic-utilities/#installation","title":"Installation","text":"<p>The topic utilities require gensim:</p> <pre><code>pip install rapid_textrank[topic]\n</code></pre>"},{"location":"api/topic-utilities/#topic_weights_from_lda","title":"topic_weights_from_lda","text":"<p>Computes per-lemma importance weights from a trained LDA model and a single document's bag-of-words representation.</p>"},{"location":"api/topic-utilities/#signature","title":"Signature","text":"<pre><code>topic_weights_from_lda(\n    lda_model,\n    corpus_entry: list[tuple[int, int | float]],\n    dictionary,\n    top_n_words: int = 50,\n    aggregation: str = \"max\",\n) -&gt; dict[str, float]\n</code></pre>"},{"location":"api/topic-utilities/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>lda_model</code> <code>gensim.models.LdaModel</code> (required) A trained gensim LDA model (or <code>LdaMulticore</code>). <code>corpus_entry</code> <code>list[tuple[int, int]]</code> (required) Bag-of-words for a single document, as returned by <code>dictionary.doc2bow(tokens)</code>. <code>dictionary</code> <code>gensim.corpora.Dictionary</code> (required) The gensim <code>Dictionary</code> mapping token IDs to words. <code>top_n_words</code> <code>int</code> <code>50</code> Number of top words to retrieve per topic. <code>aggregation</code> <code>str</code> <code>\"max\"</code> How to aggregate a word's weight across multiple topics. <code>\"max\"</code> keeps the highest weight; <code>\"mean\"</code> averages."},{"location":"api/topic-utilities/#returns","title":"Returns","text":"<p>A <code>dict[str, float]</code> mapping lemma strings to importance weights, suitable for passing to <code>TopicalPageRank(topic_weights=...)</code>.</p>"},{"location":"api/topic-utilities/#how-it-works","title":"How It Works","text":"<p>For each topic that the document belongs to, the function retrieves the top words and computes <code>P(topic|doc) * P(word|topic)</code> for every word. Scores are then aggregated across topics using the specified method.</p>"},{"location":"api/topic-utilities/#full-example","title":"Full Example","text":"<pre><code>from gensim.corpora import Dictionary\nfrom gensim.models import LdaModel\nfrom rapid_textrank import TopicalPageRank, topic_weights_from_lda\n\n# 1. Train (or load) an LDA model\ncorpus = [\n    \"transformers attention neural networks deep learning\",\n    \"access control authentication encryption audit logging\",\n    \"renewable energy solar wind grid storage batteries\",\n    \"customer retention cohort analysis activation funnel\",\n    \"privacy gdpr consent tracking cookies analytics\",\n]\n\ntexts = [doc.split() for doc in corpus]\ndictionary = Dictionary(texts)\nbow_corpus = [dictionary.doc2bow(t) for t in texts]\nlda = LdaModel(bow_corpus, num_topics=3, id2word=dictionary, random_state=0)\n\n# 2. Compute topic weights for a single document\ndoc_id = 4\nraw_text = corpus[doc_id]\nweights = topic_weights_from_lda(lda, bow_corpus[doc_id], dictionary)\n\n# 3. Extract keywords using those weights\nextractor = TopicalPageRank(\n    topic_weights=weights,\n    min_weight=0.01,\n    top_n=12,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(raw_text)\nfor phrase in result.phrases[:10]:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre>"},{"location":"api/topic-utilities/#batch-pipeline-pattern","title":"Batch Pipeline Pattern","text":"<p>For processing many documents, keep a single <code>TopicalPageRank</code> instance and pass new weights per call:</p> <pre><code>extractor = TopicalPageRank(top_n=10, language=\"en\")\n\nfor doc_id in range(len(bow_corpus)):\n    weights = topic_weights_from_lda(lda, bow_corpus[doc_id], dictionary)\n    result = extractor.extract_keywords(\n        corpus[doc_id],\n        topic_weights=weights,\n    )\n    print(f\"Doc {doc_id}: {[p.text for p in result.phrases[:5]]}\")\n</code></pre>"},{"location":"api/topic-utilities/#aggregation-modes","title":"Aggregation Modes","text":"Mode Behavior <code>\"max\"</code> (default) For each word, keep the highest <code>P(topic|doc) * P(word|topic)</code> across all topics. Good when a word's importance is best captured by its strongest topic association. <code>\"mean\"</code> Average the weight across all topics the word appears in. Smooths out weights for words that appear across many topics."},{"location":"api/topic-utilities/#notes","title":"Notes","text":"<ul> <li>Topic modeling is optional. <code>TopicalPageRank</code> accepts any <code>dict[str, float]</code> as topic weights. You can supply TF-IDF weights, embedding similarities, domain relevance scores, or hand-picked values instead of LDA-derived weights.</li> <li>Gensim is only imported on demand. The <code>topic_weights_from_lda</code> function is lazily loaded to avoid pulling in gensim unless you actually call it.</li> </ul>"},{"location":"architecture/composition-matrix/","title":"Variant Composition Matrix","text":"<p>Every algorithm variant in rapid_textrank is a parameter choice, not a separate code path. The <code>Pipeline</code> struct is generic over eight stage slots:</p> <pre><code>pub struct Pipeline&lt;Pre, Sel, GB, GT, TB, Rnk, PB, Fmt&gt; { .. }\n</code></pre> <p>Each variant is a type alias that fills these slots with concrete implementations. Stages that differ from the baseline are bolded in the tables below.</p>"},{"location":"architecture/composition-matrix/#complete-matrix","title":"Complete Matrix","text":"Stage Trait BaseTextRank PositionRank BiasedTextRank SingleRank TopicalPageRank TopicRank MultipartiteRank SentenceRank <code>Pre</code> <code>Preprocessor</code> Noop Noop Noop Noop Noop Noop Noop Noop <code>Sel</code> <code>CandidateSelector</code> WordNode WordNode WordNode WordNode WordNode Phrase Phrase Sentence <code>GB</code> <code>GraphBuilder</code> Window Window Window Window Window TopicGraph CandidateGraph SentenceGraph <code>GT</code> <code>GraphTransform</code> Noop Noop Noop Noop Noop Noop Multipartite Noop <code>TB</code> <code>TeleportBuilder</code> Uniform Position FocusTerms Uniform TopicWeights Uniform Uniform Uniform <code>Rnk</code> <code>Ranker</code> PageRank PageRank PageRank PageRank PageRank PageRank PageRank PageRank <code>PB</code> <code>PhraseBuilder</code> Chunk Chunk Chunk Chunk Chunk TopicRep MultipartitePhrase SentencePhrase <code>Fmt</code> <code>ResultFormatter</code> Standard Standard Standard Standard Standard Standard Standard Sentence <p>Reading the table column-by-column shows exactly what makes each variant unique. Reading row-by-row shows which stages are shared.</p>"},{"location":"architecture/composition-matrix/#rust-type-aliases","title":"Rust Type Aliases","text":"<p>Each variant maps to a concrete type alias in <code>src/pipeline/runner.rs</code>:</p> <pre><code>// Word-graph family\ntype BaseTextRankPipeline     = Pipeline&lt;Noop, WordNode, Window, Noop, Uniform,    PR, Chunk, Std&gt;;\ntype PositionRankPipeline     = Pipeline&lt;Noop, WordNode, Window, Noop, Position,   PR, Chunk, Std&gt;;\ntype BiasedTextRankPipeline   = Pipeline&lt;Noop, WordNode, Window, Noop, FocusTerms, PR, Chunk, Std&gt;;\ntype SingleRankPipeline       = Pipeline&lt;Noop, WordNode, Window, Noop, Uniform,    PR, Chunk, Std&gt;;\ntype TopicalPageRankPipeline  = Pipeline&lt;Noop, WordNode, Window, Noop, TopicWts,   PR, Chunk, Std&gt;;\n\n// Topic family\ntype TopicRankPipeline        = Pipeline&lt;Noop, Phrase, TopicGB&lt;HAC&gt;, Noop, Uniform, PR, TopicRep, Std&gt;;\ntype MultipartiteRankPipeline = Pipeline&lt;Noop, Phrase, CandGB&lt;HAC&gt;,  MPT, Uniform, PR, MPPhrase, Std&gt;;\n\n// Extractive summarization (feature-gated: `sentence-rank`)\ntype SentenceRankPipeline     = Pipeline&lt;Noop, SentSel, SentGB, Noop, Uniform, PR, SentPB, SentFmt&gt;;\n</code></pre> <p>Note: type names above are abbreviated for readability. See <code>runner.rs</code> for exact definitions.</p> <p>Notice that <code>BaseTextRankPipeline</code> and <code>SingleRankPipeline</code> have identical type signatures \u2014 they differ only in the runtime configuration of <code>WindowGraphBuilder</code> (sentence-bounded vs. cross-sentence).</p>"},{"location":"architecture/composition-matrix/#stage-implementation-details","title":"Stage Implementation Details","text":""},{"location":"architecture/composition-matrix/#candidate-selectors","title":"Candidate Selectors","text":"Implementation Candidates Produced Used By <code>WordNodeSelector</code> <code>CandidateKind::Words</code> \u2014 one entry per unique (lemma, POS) pair that passes POS and stopword filters BaseTextRank, PositionRank, BiasedTextRank, SingleRank, TopicalPageRank <code>PhraseCandidateSelector</code> <code>CandidateKind::Phrases</code> \u2014 multi-word candidates from pre-supplied <code>ChunkSpan</code>s TopicRank, MultipartiteRank <code>SentenceCandidateSelector</code> <code>CandidateKind::Sentences</code> \u2014 one candidate per sentence in the document SentenceRank"},{"location":"architecture/composition-matrix/#graph-builders","title":"Graph Builders","text":"Implementation Graph Topology Configuration Axes Used By <code>WindowGraphBuilder</code> Co-occurrence within sliding window <code>WindowStrategy</code> \u00d7 <code>EdgeWeightPolicy</code> All word-graph variants <code>TopicGraphBuilder&lt;C&gt;</code> Complete graph over cluster centroids Embeds a <code>Clusterer</code> (e.g., <code>JaccardHacClusterer</code>) TopicRank <code>CandidateGraphBuilder&lt;C&gt;</code> Complete graph over individual candidates Embeds a <code>Clusterer</code> MultipartiteRank <code>SentenceGraphBuilder</code> Jaccard similarity between token sets <code>min_similarity</code> threshold (default: 0.0) SentenceRank"},{"location":"architecture/composition-matrix/#windowgraphbuilder-configurations","title":"WindowGraphBuilder Configurations","text":"<p>The <code>WindowGraphBuilder</code> covers two configuration axes:</p> Parameter BaseTextRank / PositionRank / BiasedTextRank SingleRank / TopicalPageRank <code>WindowStrategy</code> <code>SentenceBounded { window_size: 3 }</code> <code>CrossSentence { window_size: 3 }</code> <code>EdgeWeightPolicy</code> <code>CountAccumulating</code> <code>CountAccumulating</code> <p>Both groups use count-accumulating edges by default. The paper-standard binary-edge variant can be constructed manually with <code>EdgeWeightPolicy::Binary</code>.</p> <ul> <li>SentenceBounded: Window resets at sentence boundaries. Co-occurrences never cross sentence breaks.</li> <li>CrossSentence: Window slides continuously over the entire candidate sequence, ignoring sentence boundaries.</li> </ul>"},{"location":"architecture/composition-matrix/#graph-transforms","title":"Graph Transforms","text":"Implementation Effect Used By <code>NoopGraphTransform</code> Nothing (zero-sized, compiled away) All except MultipartiteRank <code>MultipartiteTransform</code> 1. Zeros intra-cluster edges (k-partite structure) 2. Boosts edges toward first-occurring variants (alpha=1.1) MultipartiteRank <p>The <code>MultipartiteTransform</code> combines two sub-operations (<code>IntraTopicEdgeRemover</code> + <code>AlphaBoostWeighter</code>) into a single pass for efficiency.</p>"},{"location":"architecture/composition-matrix/#teleport-builders","title":"Teleport Builders","text":"Implementation Teleport Vector Parameters Used By <code>UniformTeleportBuilder</code> <code>None</code> (standard PageRank, uniform jump) \u2014 BaseTextRank, SingleRank, TopicRank, MultipartiteRank, SentenceRank <code>PositionTeleportBuilder</code> <code>weight[i] = 1 / (position + 1)</code> \u2014 PositionRank <code>FocusTermsTeleportBuilder</code> Focus terms get <code>bias_weight</code>; others get <code>1.0</code> <code>focus_terms: Vec&lt;String&gt;</code>, <code>bias_weight: f64</code> BiasedTextRank <code>TopicWeightsTeleportBuilder</code> Per-word weights from external topic model <code>topic_weights: HashMap&lt;String, f64&gt;</code>, <code>min_weight: f64</code> TopicalPageRank <p>All non-uniform teleport vectors are normalized to sum to 1.0 before being passed to PageRank.</p>"},{"location":"architecture/composition-matrix/#phrase-builders","title":"Phrase Builders","text":"Implementation Strategy Used By <code>ChunkPhraseBuilder</code> Noun-phrase chunking: <code>(DET)? (ADJ)* (NOUN\\|PROPN)+</code>. Scores via PageRank aggregation. Groups by lemma. All word-graph variants <code>TopicRepresentativeBuilder</code> Selects first-occurring phrase from each top-scoring cluster TopicRank <code>MultipartitePhraseBuilder</code> Selects highest-scoring phrase per lemma group MultipartiteRank <code>SentencePhraseBuilder</code> Materializes full sentence text directly SentenceRank"},{"location":"architecture/composition-matrix/#result-formatters","title":"Result Formatters","text":"Implementation Sort Order Used By <code>StandardResultFormatter</code> Score descending (deterministic mode: <code>stable_cmp</code> with tie-breaking) All except SentenceRank <code>SentenceFormatter</code> Score descending (default) or document position ascending (<code>sort_by_position = true</code>) SentenceRank"},{"location":"architecture/composition-matrix/#clustering-topic-family-only","title":"Clustering (Topic Family Only)","text":"<p>TopicRank and MultipartiteRank share a clustering sub-stage embedded in the graph builder:</p> Parameter TopicRank MultipartiteRank Clusterer <code>JaccardHacClusterer</code> <code>JaccardHacClusterer</code> Distance metric Jaccard Jaccard Linkage Average Average Similarity threshold 0.25 0.26 <p>The clustering result (<code>ClusterAssignments</code>) is attached to the <code>Graph</code> artifact and consumed by the phrase builder and (for MultipartiteRank) the graph transform.</p>"},{"location":"architecture/composition-matrix/#what-this-means","title":"What This Means","text":"<ol> <li> <p>No variant-specific orchestration code. The pipeline runner (<code>Pipeline::run_inner</code>) is a single generic function that executes the same eight stages for every variant. The variant is encoded entirely in which concrete types fill the generic slots.</p> </li> <li> <p>Adding a variant = choosing stages. To create a new variant, pick an implementation for each stage and define a type alias. No new control flow is needed.</p> </li> <li> <p>Runtime vs. compile-time variation. Some variants differ at the type level (e.g., <code>PositionTeleportBuilder</code> vs. <code>UniformTeleportBuilder</code>), while others differ only at runtime (e.g., <code>BaseTextRankPipeline</code> vs. <code>SingleRankPipeline</code> share the same types but configure <code>WindowGraphBuilder</code> differently). Both approaches are valid \u2014 type-level differences enable zero-cost abstraction, while runtime differences keep the type zoo small.</p> </li> <li> <p>Zero-cost defaults. Stages like <code>NoopPreprocessor</code>, <code>NoopGraphTransform</code>, and <code>UniformTeleportBuilder</code> are zero-sized types. They add zero bytes to the pipeline struct and compile to no instructions.</p> </li> </ol>"},{"location":"architecture/debug-introspection/","title":"Debug and Introspection Outputs","text":"<p>rapid_textrank provides a tiered debug system that lets you see inside the pipeline \u2014 from graph statistics to per-iteration convergence residuals. This is useful when you want to understand why certain keywords were ranked higher than others.</p>"},{"location":"architecture/debug-introspection/#quick-start","title":"Quick Start","text":""},{"location":"architecture/debug-introspection/#via-textrankconfig","title":"Via <code>TextRankConfig</code>","text":"<p>Set <code>debug_level</code> to control what debug data is attached to results:</p> <pre><code>from rapid_textrank import TextRankConfig, PositionRank\n\nconfig = TextRankConfig(debug_level=\"top_nodes\")\nresult = PositionRank().extract_with_info(tokens, config)\nprint(result.debug)  # contains graph_stats, convergence_summary, node_scores\n</code></pre>"},{"location":"architecture/debug-introspection/#via-pipelinespec-json-interface","title":"Via <code>PipelineSpec</code> (JSON interface)","text":"<p>Add an <code>expose</code> section to your pipeline spec for fine-grained control:</p> <pre><code>{\n  \"v\": 1,\n  \"preset\": \"textrank\",\n  \"expose\": {\n    \"node_scores\": { \"top_k\": 20 },\n    \"graph_stats\": true,\n    \"stage_timings\": true\n  }\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#debug-levels","title":"Debug Levels","text":"<p>Debug output is organized into four cumulative levels. Each level is a strict superset of the previous:</p> <pre><code>None \u2282 Stats \u2282 TopNodes \u2282 Full\n</code></pre> Level Serialized What's Included Overhead <code>None</code> <code>\"none\"</code> Nothing (default) Zero \u2014 compiled away <code>Stats</code> <code>\"stats\"</code> Graph statistics, convergence summary, stage timings Negligible <code>TopNodes</code> <code>\"top_nodes\"</code> Everything in Stats + top-K node scores Allocates + sorts score vector <code>Full</code> <code>\"full\"</code> Everything in TopNodes + per-iteration residuals + cluster memberships Can be substantial on large graphs <p>The level ordering is enforced at the type level via <code>PartialOrd</code>:</p> <pre><code>assert!(DebugLevel::Stats &lt; DebugLevel::TopNodes);\nassert!(DebugLevel::TopNodes &lt; DebugLevel::Full);\n</code></pre>"},{"location":"architecture/debug-introspection/#debug-payload-fields","title":"Debug Payload Fields","text":"<p>The <code>DebugPayload</code> struct contains all introspection data. Fields are individually optional \u2014 you only pay for what you ask for.</p>"},{"location":"architecture/debug-introspection/#graph_stats-available-at-stats-and-above","title":"<code>graph_stats</code> (available at <code>Stats</code> and above)","text":"<p>Summary statistics for the co-occurrence graph.</p> Field Type Description <code>num_nodes</code> <code>usize</code> Number of nodes (unique candidates) in the graph <code>num_edges</code> <code>usize</code> Number of edges (co-occurrence links) <code>is_transformed</code> <code>bool</code> Whether a <code>GraphTransform</code> stage modified the graph <p>Interpretation: For word-graph variants, <code>num_nodes</code> is the number of unique (lemma, POS) pairs that survived filtering. For topic variants, it's the number of clusters or candidates depending on the variant. A high edge-to-node ratio indicates a dense graph where many candidates co-occur.</p> <pre><code>{\n  \"graph_stats\": {\n    \"num_nodes\": 42,\n    \"num_edges\": 156,\n    \"is_transformed\": false\n  }\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#convergence_summary-available-at-stats-and-above","title":"<code>convergence_summary</code> (available at <code>Stats</code> and above)","text":"<p>PageRank convergence metadata.</p> Field Type Description <code>iterations</code> <code>u32</code> Number of power-iteration steps performed <code>converged</code> <code>bool</code> Whether the L1-norm delta dropped below <code>convergence_threshold</code> <code>final_delta</code> <code>f64</code> L1-norm delta between the last two iteration vectors <p>Interpretation: If <code>converged</code> is <code>false</code>, results may be approximate. Check <code>final_delta</code> to gauge how close to convergence the algorithm got. Increasing <code>max_iterations</code> in <code>TextRankConfig</code> may help. A very small graph (&lt; 5 nodes) often converges in 2\u20133 iterations.</p> <pre><code>{\n  \"convergence_summary\": {\n    \"iterations\": 28,\n    \"converged\": true,\n    \"final_delta\": 3.7e-8\n  }\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#stage_timings-available-at-stats-and-above","title":"<code>stage_timings</code> (available at <code>Stats</code> and above)","text":"<p>Wall-clock duration of each pipeline stage in milliseconds.</p> <pre><code>{\n  \"stage_timings\": [\n    [\"preprocess\", 0.012],\n    [\"candidates\", 0.089],\n    [\"graph\", 0.234],\n    [\"graph_transform\", 0.001],\n    [\"teleport\", 0.003],\n    [\"rank\", 0.156],\n    [\"phrases\", 0.045],\n    [\"format\", 0.018]\n  ]\n}\n</code></pre> <p>Interpretation: Use this to identify bottlenecks. For most documents, <code>graph</code> and <code>rank</code> dominate. If <code>candidates</code> is slow, you may have a very large document \u2014 consider truncating input. The <code>graph_transform</code> stage is <code>0.0</code> for non-MultipartiteRank variants (the NoopGraphTransform is compiled away).</p>"},{"location":"architecture/debug-introspection/#node_scores-available-at-topnodes-and-above","title":"<code>node_scores</code> (available at <code>TopNodes</code> and above)","text":"<p>Top-K graph nodes sorted by PageRank score descending. Ties are broken by lemma ascending for stability.</p> <pre><code>{\n  \"node_scores\": [\n    [\"machine|NOUN\", 0.0523],\n    [\"learning|NOUN\", 0.0487],\n    [\"neural|ADJ\", 0.0312],\n    [\"network|NOUN\", 0.0298]\n  ]\n}\n</code></pre> <p>Interpretation: These are the raw PageRank scores before phrase assembly. Comparing node scores helps you understand:</p> <ul> <li>Why a phrase ranks high: Its constituent words all have high individual scores.</li> <li>Why a phrase ranks low: One of its words has very low score, dragging down the aggregate.</li> <li>How teleport biasing works: In PositionRank, early words get inflated scores. In BiasedTextRank, focus terms dominate.</li> </ul> <p>Node labels follow the <code>\"lemma|POS\"</code> format when <code>use_pos_in_nodes</code> is enabled (the default). With it disabled, labels are just the lemma.</p> <p>The number of nodes returned is bounded by <code>top_k</code>:</p> Source Priority Default <code>expose.node_scores.top_k</code> 1 (highest) \u2014 <code>runtime.max_debug_top_k</code> 2 \u2014 <code>DebugLevel::DEFAULT_TOP_K</code> 3 (fallback) 50"},{"location":"architecture/debug-introspection/#residuals-available-at-full-only","title":"<code>residuals</code> (available at <code>Full</code> only)","text":"<p>Per-iteration L1-norm convergence residuals from PageRank.</p> <pre><code>{\n  \"residuals\": [0.8234, 0.3912, 0.1856, 0.0423, 0.0089, 0.0012, 0.00003]\n}\n</code></pre> <p>Interpretation: This shows how fast PageRank is converging. A healthy convergence curve drops roughly exponentially. If the curve plateaus early, the graph may have a structural issue (e.g., disconnected components, very low damping). Only populated when PageRank diagnostics are enabled internally \u2014 if absent even at <code>Full</code> level, diagnostics were not captured for this run.</p>"},{"location":"architecture/debug-introspection/#cluster_memberships-available-at-full-only-topic-family-variants","title":"<code>cluster_memberships</code> (available at <code>Full</code> only, topic-family variants)","text":"<p>Cluster membership arrays for TopicRank and MultipartiteRank. <code>cluster_memberships[i]</code> lists the candidate indices belonging to cluster <code>i</code>.</p> <pre><code>{\n  \"cluster_memberships\": [\n    [0, 1, 4],\n    [2, 3],\n    [5]\n  ]\n}\n</code></pre> <p>Interpretation: This shows how phrase candidates were grouped by the HAC clusterer. Candidates in the same cluster share overlapping words (Jaccard similarity above the threshold). For TopicRank, each cluster becomes a single graph node. For MultipartiteRank, intra-cluster edges are removed to create a k-partite structure.</p> <p>This field is <code>null</code> for word-graph variants (BaseTextRank, PositionRank, etc.) and SentenceRank since they don't use clustering.</p>"},{"location":"architecture/debug-introspection/#the-expose-spec-json-interface","title":"The <code>expose</code> Spec (JSON Interface)","text":"<p>The <code>expose</code> field in a <code>PipelineSpec</code> provides fine-grained control over which debug fields to populate. It maps declaratively to <code>DebugLevel</code>:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 expose field            \u2502 Minimum DebugLevel   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 graph_stats: true       \u2502 Stats                \u2502\n\u2502 stage_timings: true     \u2502 Stats                \u2502\n\u2502 pagerank: {}            \u2502 Stats                \u2502\n\u2502 node_scores: {}         \u2502 TopNodes             \u2502\n\u2502 node_scores: {top_k: N} \u2502 TopNodes             \u2502\n\u2502 pagerank: {residuals: T}\u2502 Full                 \u2502\n\u2502 clusters: true          \u2502 Full                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>When multiple fields are requested, the highest required level wins. For example, <code>{ \"graph_stats\": true, \"clusters\": true }</code> resolves to <code>Full</code>.</p>"},{"location":"architecture/debug-introspection/#full-expose-example","title":"Full Expose Example","text":"<pre><code>{\n  \"v\": 1,\n  \"preset\": \"multipartite_rank\",\n  \"expose\": {\n    \"node_scores\": { \"top_k\": 50 },\n    \"graph_stats\": true,\n    \"pagerank\": { \"residuals\": true },\n    \"clusters\": true,\n    \"stage_timings\": true\n  },\n  \"runtime\": {\n    \"max_debug_top_k\": 100\n  }\n}\n</code></pre> <p>This requests everything at <code>Full</code> level: graph stats, convergence summary, stage timings, top-50 node scores, per-iteration residuals, and cluster memberships.</p>"},{"location":"architecture/debug-introspection/#minimal-expose-stats-only","title":"Minimal Expose (Stats Only)","text":"<pre><code>{\n  \"v\": 1,\n  \"preset\": \"textrank\",\n  \"expose\": {\n    \"graph_stats\": true,\n    \"stage_timings\": true\n  }\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#empty-expose-disabled","title":"Empty Expose (Disabled)","text":"<p>An empty <code>expose: {}</code> enables nothing \u2014 each sub-field must be explicitly set:</p> <pre><code>{\n  \"v\": 1,\n  \"expose\": {}\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#pipeline-observer-rust-api","title":"Pipeline Observer (Rust API)","text":"<p>For Rust users, the <code>PipelineObserver</code> trait provides real-time callbacks at every stage boundary \u2014 more powerful than the static <code>DebugPayload</code>.</p>"},{"location":"architecture/debug-introspection/#available-callbacks","title":"Available Callbacks","text":"Method Called After Receives <code>on_stage_start(stage)</code> \u2014 Stage name (before execution) <code>on_stage_end(stage, report)</code> Every stage <code>StageReport</code> with duration + optional metrics <code>on_tokens(tokens)</code> Preprocess Full <code>TokenStream</code> <code>on_candidates(candidates)</code> Candidate selection <code>CandidateSet</code> <code>on_graph(graph)</code> Graph build + transform <code>Graph</code> (CSR, with cluster assignments if topic-family) <code>on_rank(rank)</code> Ranking <code>RankOutput</code> (scores + convergence) <code>on_phrases(phrases)</code> Phrase building <code>PhraseSet</code>"},{"location":"architecture/debug-introspection/#stage-names","title":"Stage Names","text":"<p>Stage names are <code>&amp;'static str</code> constants:</p> Constant Value <code>STAGE_PREPROCESS</code> <code>\"preprocess\"</code> <code>STAGE_CANDIDATES</code> <code>\"candidates\"</code> <code>STAGE_GRAPH</code> <code>\"graph\"</code> <code>STAGE_GRAPH_TRANSFORM</code> <code>\"graph_transform\"</code> <code>STAGE_TELEPORT</code> <code>\"teleport\"</code> <code>STAGE_RANK</code> <code>\"rank\"</code> <code>STAGE_PHRASES</code> <code>\"phrases\"</code> <code>STAGE_FORMAT</code> <code>\"format\"</code>"},{"location":"architecture/debug-introspection/#built-in-observers","title":"Built-in Observers","text":"Observer Purpose <code>NoopObserver</code> Default. Zero-sized, compiled away entirely. <code>StageTimingObserver</code> Collects <code>(stage_name, StageReport)</code> pairs. Call <code>.reports()</code> after the run to inspect timings. Call <code>.total_duration_ms()</code> for aggregate wall time."},{"location":"architecture/debug-introspection/#custom-observer-example","title":"Custom Observer Example","text":"<pre><code>use rapid_textrank::pipeline::observer::*;\n\nstruct MyObserver;\n\nimpl PipelineObserver for MyObserver {\n    fn on_stage_end(&amp;mut self, stage: &amp;'static str, report: &amp;StageReport) {\n        println!(\"{stage}: {:.3}ms\", report.duration_ms());\n        if let Some(nodes) = report.nodes() {\n            println!(\"  graph: {nodes} nodes, {} edges\", report.edges().unwrap_or(0));\n        }\n        if let Some(iters) = report.iterations() {\n            println!(\"  PageRank: {iters} iterations, converged={}\",\n                     report.converged().unwrap_or(false));\n        }\n    }\n}\n</code></pre>"},{"location":"architecture/debug-introspection/#stagereport-fields","title":"StageReport Fields","text":"<p>Each <code>StageReport</code> always has <code>duration_us</code>. Other fields depend on which stage produced it:</p> Field Type Populated By <code>duration_us()</code> <code>u64</code> All stages <code>duration_ms()</code> <code>f64</code> All stages <code>nodes()</code> <code>Option&lt;usize&gt;</code> GraphBuilder <code>edges()</code> <code>Option&lt;usize&gt;</code> GraphBuilder <code>iterations()</code> <code>Option&lt;u32&gt;</code> Ranker <code>converged()</code> <code>Option&lt;bool&gt;</code> Ranker <code>residual()</code> <code>Option&lt;f64&gt;</code> Ranker"},{"location":"architecture/debug-introspection/#troubleshooting-with-debug-output","title":"Troubleshooting with Debug Output","text":""},{"location":"architecture/debug-introspection/#why-is-keyword-x-missing","title":"\"Why is keyword X missing?\"","text":"<ol> <li>Set <code>debug_level: \"top_nodes\"</code> and check <code>node_scores</code>. If the word appears with a low score, it was considered but ranked below the <code>top_n</code> cutoff.</li> <li>If the word doesn't appear in <code>node_scores</code> at all, it was likely filtered out during candidate selection (wrong POS tag, or in the stopword list).</li> </ol>"},{"location":"architecture/debug-introspection/#why-did-pagerank-not-converge","title":"\"Why did PageRank not converge?\"","text":"<ol> <li>Check <code>convergence_summary.iterations</code> \u2014 did it hit <code>max_iterations</code>?</li> <li>Check <code>convergence_summary.final_delta</code> \u2014 how far from the threshold is it?</li> <li>At <code>Full</code> level, inspect <code>residuals</code> to see the convergence curve. If it plateaus, try increasing <code>damping</code> (default: 0.85).</li> </ol>"},{"location":"architecture/debug-introspection/#why-are-two-similar-phrases-both-in-the-output","title":"\"Why are two similar phrases both in the output?\"","text":"<ol> <li>Check <code>cluster_memberships</code> (TopicRank/MultipartiteRank) \u2014 if they're in different clusters, the similarity threshold wasn't met.</li> <li>For word-graph variants, similar phrases with different lemmas won't be grouped. Consider TopicRank if you need deduplication.</li> </ol>"},{"location":"architecture/debug-introspection/#which-stage-is-slow","title":"\"Which stage is slow?\"","text":"<ol> <li>Set <code>expose.stage_timings: true</code> (or use <code>StageTimingObserver</code> in Rust).</li> <li>Look for the dominant stage. Common patterns:</li> <li><code>graph</code> dominates: Large document, many candidates, dense co-occurrence.</li> <li><code>rank</code> dominates: Large graph, slow convergence. Try reducing <code>max_iterations</code> or increasing <code>convergence_threshold</code>.</li> <li><code>candidates</code> dominates: Very long document. Consider truncating input.</li> </ol>"},{"location":"architecture/pipeline/","title":"Pipeline Architecture","text":"<p>This document describes the internal pipeline that powers every TextRank variant in rapid_textrank.</p>"},{"location":"architecture/pipeline/#stage-diagram","title":"Stage Diagram","text":"<p>Every extraction request flows through eight stages. Stages are statically composed \u2014 the compiler monomorphizes each variant into a unique concrete type with zero virtual-call overhead.</p> <pre><code>  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502                        Input: TokenStream                          \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 0 \u00b7 PREPROCESS                                              \u2502\n  \u2502  Trait: Preprocessor                                               \u2502\n  \u2502  Default: NoopPreprocessor (zero-sized, compiled away)             \u2502\n  \u2502  Mutates TokenStream in place                                      \u2502\n  \u2502  Ownership: &amp;mut TokenStream (borrowed, mutated)                   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 1 \u00b7 CANDIDATES                                              \u2502\n  \u2502  Trait: CandidateSelector                                          \u2502\n  \u2502  Impls: WordNodeSelector \u2502 PhraseCandidateSelector                 \u2502\n  \u2502         \u2502 SentenceCandidateSelector                                \u2502\n  \u2502  Input:  TokenStreamRef&lt;'_&gt; (borrowed)                             \u2502\n  \u2502  Output: CandidateSet (owned)                                      \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 2 \u00b7 GRAPH                                                   \u2502\n  \u2502  Trait: GraphBuilder                                               \u2502\n  \u2502  Impls: WindowGraphBuilder \u2502 TopicGraphBuilder&lt;C&gt;                  \u2502\n  \u2502         \u2502 CandidateGraphBuilder&lt;C&gt; \u2502 SentenceGraphBuilder          \u2502\n  \u2502  Input:  TokenStreamRef&lt;'_&gt;, CandidateSetRef&lt;'_&gt; (borrowed)       \u2502\n  \u2502  Output: Graph (owned, CSR format)                                 \u2502\n  \u2502  Note: TopicGraphBuilder embeds a Clusterer (e.g. JaccardHAC)     \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 2a \u00b7 GRAPH TRANSFORM (optional)                             \u2502\n  \u2502  Trait: GraphTransform                                             \u2502\n  \u2502  Default: NoopGraphTransform (zero-sized, compiled away)           \u2502\n  \u2502  Impls: IntraTopicEdgeRemover \u2502 AlphaBoostWeighter                 \u2502\n  \u2502         \u2502 MultipartiteTransform (combined)                         \u2502\n  \u2502  Ownership: &amp;mut Graph (borrowed, mutated in place)                \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 3a \u00b7 TELEPORT                                               \u2502\n  \u2502  Trait: TeleportBuilder                                            \u2502\n  \u2502  Default: UniformTeleportBuilder \u2192 returns None (standard PR)      \u2502\n  \u2502  Impls: PositionTeleportBuilder \u2502 FocusTermsTeleportBuilder        \u2502\n  \u2502         \u2502 TopicWeightsTeleportBuilder                              \u2502\n  \u2502  Input:  TokenStreamRef&lt;'_&gt;, CandidateSetRef&lt;'_&gt; (borrowed)       \u2502\n  \u2502  Output: Option&lt;TeleportVector&gt; (owned)                            \u2502\n  \u2502  Contract: returned vector MUST sum to 1.0                         \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 3 \u00b7 RANK                                                    \u2502\n  \u2502  Trait: Ranker                                                     \u2502\n  \u2502  Impl: PageRankRanker                                              \u2502\n  \u2502  Delegates to: StandardPageRank (if teleport = None)               \u2502\n  \u2502                PersonalizedPageRank (if teleport = Some)           \u2502\n  \u2502  Input:  &amp;Graph, Option&lt;&amp;TeleportVector&gt; (borrowed)                \u2502\n  \u2502  Output: RankOutput (owned \u2014 scores + convergence metadata)        \u2502\n  \u2502  Algorithm: Power iteration with damping, dangling-node handling   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 4 \u00b7 PHRASES                                                 \u2502\n  \u2502  Trait: PhraseBuilder                                              \u2502\n  \u2502  Impls: ChunkPhraseBuilder \u2502 TopicRepresentativeBuilder            \u2502\n  \u2502         \u2502 MultipartitePhraseBuilder \u2502 SentencePhraseBuilder        \u2502\n  \u2502  Input:  all prior artifacts (borrowed)                            \u2502\n  \u2502  Output: PhraseSet (owned)                                         \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  Stage 5 \u00b7 FORMAT                                                  \u2502\n  \u2502  Trait: ResultFormatter                                            \u2502\n  \u2502  Impls: StandardResultFormatter \u2502 SentenceFormatter                \u2502\n  \u2502  Input:  &amp;PhraseSet, &amp;RankOutput, optional DebugPayload (borrowed) \u2502\n  \u2502  Output: FormattedResult (owned \u2014 final public result)             \u2502\n  \u2502  Responsibilities: sort, assign ranks, apply top_n, attach meta    \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                         FormattedResult\n</code></pre>"},{"location":"architecture/pipeline/#artifact-definitions","title":"Artifact Definitions","text":"<p>Each stage boundary has a well-defined artifact type. The ownership discipline keeps the hot path allocation-light: stages borrow whenever possible and only produce owned output when the data is new.</p> Artifact Defined in Ownership Description <code>TokenStream</code> <code>pipeline/artifacts.rs</code> Owned by pipeline runner Interned token array with <code>StringPool</code>, CSR-style <code>sentence_offsets</code>. ~28\u201332 bytes per token. Passed by <code>&amp;mut</code> to preprocess, then by <code>TokenStreamRef&lt;'_&gt;</code> to all later stages. <code>TokenStreamRef&lt;'_&gt;</code> <code>pipeline/artifacts.rs</code> Borrowed view Read-only reference into <code>TokenStream</code>. Zero-cost wrapper providing safe slice access. <code>CandidateSet</code> <code>pipeline/artifacts.rs</code> Owned by runner Contains <code>CandidateKind</code> enum: <code>Words(Vec&lt;WordCandidate&gt;)</code>, <code>Phrases(Vec&lt;PhraseCandidate&gt;)</code>, or <code>Sentences(Vec&lt;SentenceCandidate&gt;)</code>. <code>CandidateSetRef&lt;'_&gt;</code> <code>pipeline/artifacts.rs</code> Borrowed view Read-only reference into <code>CandidateSet</code>. Passed to graph, transform, teleport, and phrase stages. <code>Graph</code> <code>pipeline/artifacts.rs</code> Owned by runner Wraps a <code>CsrGraph</code> (compressed sparse row). Optional <code>ClusterAssignments</code> for topic variants. A <code>transformed</code> flag tracks whether transform has run. <code>TeleportVector</code> <code>pipeline/artifacts.rs</code> Owned (optional) <code>Vec&lt;f64&gt;</code> personalization vector. <code>None</code> means uniform teleport (standard PageRank). When present, must be normalized to sum to 1.0. <code>RankOutput</code> <code>pipeline/artifacts.rs</code> Owned by runner Per-node scores (<code>Vec&lt;f64&gt;</code>) plus convergence metadata (<code>converged: bool</code>, <code>iterations: usize</code>, <code>delta: f64</code>). <code>PhraseSet</code> <code>pipeline/artifacts.rs</code> Owned by runner Collection of <code>PhraseEntry</code> records (still using interned IDs \u2014 not yet materialized to strings). <code>FormattedResult</code> <code>pipeline/artifacts.rs</code> Owned \u2014 returned to caller Public result: materialized <code>Vec&lt;Phrase&gt;</code>, convergence info, optional debug payload. Strings are only materialized at this final stage."},{"location":"architecture/pipeline/#ownership-pattern-summary","title":"Ownership Pattern Summary","text":"<pre><code>Preprocess:  &amp;mut TokenStream          (borrow + mutate)\nCandidates:  TokenStreamRef \u2192 owned CandidateSet\nGraph:       TokenStreamRef + CandidateSetRef \u2192 owned Graph\nTransform:   &amp;mut Graph                (borrow + mutate)\nTeleport:    TokenStreamRef + CandidateSetRef \u2192 owned Option&lt;TeleportVector&gt;\nRank:        &amp;Graph + Option&lt;&amp;TeleportVector&gt; \u2192 owned RankOutput\nPhrases:     all refs \u2192 owned PhraseSet\nFormat:      all refs \u2192 owned FormattedResult\n</code></pre> <p>String data remains interned (<code>StringPool</code> + <code>u32</code> IDs) through stages 0\u20134. Materialization to <code>String</code> only happens in the Format stage, keeping the hot path cache-friendly and allocation-light.</p>"},{"location":"architecture/pipeline/#variant-composition-matrix","title":"Variant Composition Matrix","text":"<p>Each algorithm variant is a concrete composition of stages. The <code>Pipeline</code> struct is generic over all eight stage types and each variant is a type alias (e.g., <code>BaseTextRankPipeline</code>, <code>TopicRankPipeline</code>).</p>"},{"location":"architecture/pipeline/#word-graph-family","title":"Word-Graph Family","text":"<p>These variants use word-level candidates, co-occurrence graphs, and chunk-based phrase extraction. They differ only in graph configuration and teleport strategy.</p> Stage BaseTextRank PositionRank BiasedTextRank SingleRank TopicalPageRank Preprocess Noop Noop Noop Noop Noop Candidates WordNode WordNode WordNode WordNode WordNode Graph Window (sentence-bounded, count-accum) Window (sentence-bounded, count-accum) Window (sentence-bounded, count-accum) Window (cross-sentence, count-accum) Window (cross-sentence, count-accum) Transform Noop Noop Noop Noop Noop Teleport Uniform Position FocusTerms Uniform TopicWeights Rank PageRank PageRank PageRank PageRank PageRank Phrases Chunk Chunk Chunk Chunk Chunk Format Standard Standard Standard Standard Standard <p>All five word-graph variants use count-accumulating edge weights by default (co-occurrence frequency is captured). The paper-standard binary-edge variant can be constructed manually with <code>EdgeWeightPolicy::Binary</code>.</p> <p>Key differences:</p> <ul> <li>BaseTextRank: Baseline. Sentence-bounded window, uniform teleport.</li> <li>PositionRank: Teleport biased by position \u2014 earlier words get higher teleport probability (<code>weight = 1/(position+1)</code>).</li> <li>BiasedTextRank: Teleport biased toward user-specified focus terms with configurable <code>bias_weight</code>.</li> <li>SingleRank: Window crosses sentence boundaries (ignores sentence boundaries entirely).</li> <li>TopicalPageRank: SingleRank's cross-sentence graph + per-word topic weights (e.g., from LDA) as teleport bias.</li> </ul>"},{"location":"architecture/pipeline/#topic-family","title":"Topic Family","text":"<p>These variants use phrase-level candidates, hierarchical agglomerative clustering (HAC), and cluster-aware graphs.</p> Stage TopicRank MultipartiteRank Preprocess Noop Noop Candidates PhraseCandidate PhraseCandidate Clustering JaccardHAC (threshold=0.25) JaccardHAC (threshold=0.26) Graph TopicGraph (clusters as nodes) CandidateGraph (candidates as nodes) Transform Noop Multipartite (remove intra-cluster + alpha boost) Teleport Uniform Uniform Rank PageRank PageRank Phrases TopicRepresentative (first-occurring per cluster) Multipartite (highest-score per lemma group) Format Standard Standard <p>Key differences:</p> <ul> <li>TopicRank: Clusters candidates into topics (HAC with Jaccard distance). Builds a graph where clusters are nodes. Picks the first-occurring phrase as cluster representative.</li> <li>MultipartiteRank: Same clustering, but keeps individual candidates as graph nodes. Removes intra-cluster edges (k-partite structure) and boosts edges toward first-occurring variants (<code>alpha=1.1</code> by default).</li> </ul>"},{"location":"architecture/pipeline/#extractive-summarization","title":"Extractive Summarization","text":"Stage SentenceRank Preprocess Noop Candidates SentenceCandidate Graph SentenceGraph (Jaccard similarity between sentences) Transform Noop Teleport Uniform Rank PageRank Phrases SentencePhrase (materializes full sentence text) Format SentenceFormatter (optional position-based sort) <p>Feature-gated behind <code>sentence-rank</code> (enabled by default). The <code>SentenceFormatter</code> supports two ordering modes: by score (default) or by document position (for readable summaries).</p>"},{"location":"architecture/pipeline/#determinism-modes","title":"Determinism Modes","text":"<p>The pipeline supports two execution modes via <code>TextRankConfig::determinism</code>:</p> Mode Behavior Use Case <code>Default</code> Fastest. HashMap iteration order is non-deterministic. Parallel reductions permitted. Production latency-sensitive workloads <code>Deterministic</code> Reproducible. Sorts keys at graph construction, phrase grouping, and result formatting. Research, testing, golden-test CI"},{"location":"architecture/pipeline/#enforcement-points","title":"Enforcement Points","text":"<ol> <li>Graph construction (<code>WindowGraphBuilder</code>): Deterministic mode sorts candidate keys before iterating.</li> <li>Phrase grouping (<code>phrase/extraction.rs</code>): Deterministic mode sorts group keys lexicographically.</li> <li>Result sorting (<code>StandardResultFormatter</code>): Deterministic mode uses <code>Phrase::stable_cmp()</code> with multi-key tie-breaking: score \u2192 position \u2192 length \u2192 lemma (float epsilon: <code>1e-10</code>).</li> </ol> <p>Golden tests in <code>src/lib.rs</code> run each variant 3 times with identical input and assert bit-exact output, catching determinism regressions in CI.</p>"},{"location":"architecture/pipeline/#validation-rules","title":"Validation Rules","text":""},{"location":"architecture/pipeline/#build-time-validation-validationengine","title":"Build-Time Validation (<code>ValidationEngine</code>)","text":"<p>The <code>ValidationEngine</code> runs declarative rules against a <code>PipelineSpec</code> before construction. It never short-circuits \u2014 all errors are collected before reporting.</p> Rule Code Description <code>RankTeleportRule</code> <code>invalid_combo</code> Ensures ranking stage has compatible teleport configuration <code>TopicGraphDepsRule</code> <code>missing_stage</code> Validates topic-family dependency chain: candidates \u2192 clustering \u2192 graph <code>GraphTransformDepsRule</code> <code>incompatible_modules</code> Ensures graph transforms have the required graph structure <code>RuntimeLimitsRule</code> <code>limit_exceeded</code> Validates numeric limits (max tokens, etc.) are within range <code>UnknownFieldsRule</code> <code>unknown_field</code> Warns or errors on unrecognized fields (strict mode) <p>Each finding is a <code>ValidationDiagnostic</code> with severity (error vs. warning), JSON-pointer path, and optional hint.</p>"},{"location":"architecture/pipeline/#runtime-config-validation-textrankconfigvalidate","title":"Runtime Config Validation (<code>TextRankConfig::validate()</code>)","text":"<p>Called before pipeline execution. Validates:</p> Field Rule <code>damping</code> Must be in <code>[0.0, 1.0]</code> <code>max_iterations</code> Must be <code>&gt; 0</code> <code>convergence_threshold</code> Must be <code>&gt; 0.0</code> <code>window_size</code> Must be <code>\u2265 2</code> <code>min_phrase_length</code> Must be <code>&gt; 0</code> <code>max_phrase_length</code> Must be <code>\u2265 min_phrase_length</code>"},{"location":"architecture/pipeline/#error-codes","title":"Error Codes","text":"<p>All pipeline errors carry an <code>ErrorCode</code> for programmatic handling. Codes are <code>#[non_exhaustive]</code> for forward compatibility and serialize to <code>snake_case</code> strings.</p> Code Serialized When <code>MissingStage</code> <code>missing_stage</code> Required pipeline stage absent from spec <code>InvalidCombo</code> <code>invalid_combo</code> Conflicting configuration options <code>ModuleUnavailable</code> <code>module_unavailable</code> Referenced module not available (e.g., feature-gated) <code>LimitExceeded</code> <code>limit_exceeded</code> Numeric value out of allowed range <code>UnknownField</code> <code>unknown_field</code> Unrecognized field in spec <code>InvalidValue</code> <code>invalid_value</code> Field value invalid for type or context <code>IncompatibleModules</code> <code>incompatible_modules</code> Selected modules cannot work together <code>ValidationFailed</code> <code>validation_failed</code> General validation failure <code>StageFailed</code> <code>stage_failed</code> Pipeline stage crashed during execution <code>ConvergenceFailed</code> <code>convergence_failed</code> PageRank did not converge within allowed iterations"},{"location":"architecture/pipeline/#error-types","title":"Error Types","text":"Type Phase Fields <code>PipelineSpecError</code> Build-time <code>code</code>, <code>path</code> (JSON pointer), <code>message</code>, <code>hint</code> <code>PipelineRuntimeError</code> Execution <code>code</code>, <code>path</code>, <code>stage</code>, <code>message</code>, <code>hint</code> <code>TextRankError</code> Legacy API Enum variants: <code>EmptyInput</code>, <code>NoCandidates</code>, <code>ConvergenceFailure</code>, <code>InvalidConfig</code>, <code>Serialization</code>, <code>Internal</code> <p>Note: PageRank convergence failure is non-fatal by design. Results are still returned with <code>RankOutput::converged = false</code>. Callers can check this flag and decide whether partial results are acceptable.</p>"},{"location":"architecture/pipeline/#key-implementation-files","title":"Key Implementation Files","text":"File Role <code>src/pipeline/runner.rs</code> Pipeline struct, type aliases, factory methods, stage orchestration <code>src/pipeline/traits.rs</code> All stage trait definitions and implementations (~2300 lines) <code>src/pipeline/artifacts.rs</code> Artifact types: <code>TokenStream</code>, <code>CandidateSet</code>, <code>Graph</code>, <code>RankOutput</code>, etc. <code>src/pipeline/error_code.rs</code> <code>ErrorCode</code> enum <code>src/pipeline/errors.rs</code> <code>PipelineSpecError</code>, <code>PipelineRuntimeError</code> <code>src/pipeline/validation.rs</code> <code>ValidationEngine</code> and rule implementations <code>src/pipeline/spec.rs</code> Declarative <code>PipelineSpec</code>, preset resolution <code>src/pipeline/observer.rs</code> <code>PipelineObserver</code> trait for debug/profiling hooks <code>src/pagerank/standard.rs</code> Standard PageRank (power iteration) <code>src/pagerank/personalized.rs</code> Personalized PageRank <code>src/graph/csr.rs</code> CSR graph representation <code>src/phrase/extraction.rs</code> Chunk-based phrase extraction, scoring, grouping <code>src/types.rs</code> Core public types: <code>Token</code>, <code>Phrase</code>, <code>TextRankConfig</code>, <code>DeterminismMode</code> <code>src/variants/</code> Per-variant structs and <code>extract_with_info()</code> entry points"},{"location":"architecture/pipeline/#design-principles","title":"Design Principles","text":"<ol> <li> <p>Static dispatch everywhere: All stage traits are resolved at compile time. Zero-sized defaults (<code>NoopPreprocessor</code>, <code>NoopGraphTransform</code>, <code>UniformTeleportBuilder</code>) add zero bytes and zero cost.</p> </li> <li> <p>Borrow then own: Stages receive borrowed views (<code>TokenStreamRef&lt;'_&gt;</code>, <code>CandidateSetRef&lt;'_&gt;</code>) and return owned artifacts. No unnecessary cloning on the hot path.</p> </li> <li> <p>Deferred materialization: String data stays interned (<code>StringPool</code> + <code>u32</code> IDs) through the entire pipeline. Human-readable <code>String</code> values are only produced in the final Format stage.</p> </li> <li> <p>CSR for graphs: Compressed Sparse Row format avoids per-edge allocations. Edge weights can be modified in place by transforms but new edges cannot be added (by design \u2014 the structure is frozen after construction).</p> </li> <li> <p>Workspace reuse: <code>PipelineWorkspace</code> lets batch callers amortize PageRank buffer allocations across documents. <code>run_batch()</code> automates this pattern.</p> </li> </ol>"},{"location":"architecture/production-hardening/","title":"Production Hardening","text":"<p>rapid_textrank ships five features designed for operators running keyword extraction at scale. Together they form a layered defense: catch typos before they silently change behavior, preflight specs before committing compute, declare resource budgets, guarantee reproducible output, and negotiate feature support at runtime.</p>"},{"location":"architecture/production-hardening/#quick-reference","title":"Quick Reference","text":"Feature Config Field Default Purpose Strict Mode <code>strict: bool</code> <code>false</code> Reject unknown fields Validate-Only <code>validate_only: bool</code> <code>false</code> Preflight check without extraction Runtime Limits <code>runtime.max_*</code> <code>None</code> Declare resource budgets Deterministic Mode <code>determinism: \"deterministic\"</code> <code>\"default\"</code> Reproducible output Capability Discovery <code>capabilities: bool</code> <code>false</code> Query supported features"},{"location":"architecture/production-hardening/#strict-mode","title":"Strict Mode","text":"<p>Strict mode controls whether unrecognized fields in a pipeline spec are errors or warnings.</p>"},{"location":"architecture/production-hardening/#the-problem","title":"The Problem","text":"<p>By default, serde silently ignores unknown JSON fields. A typo like <code>\"preest\": \"textrank\"</code> (instead of <code>\"preset\"</code>) would be silently dropped \u2014 the spec parses successfully but behaves differently than intended.</p>"},{"location":"architecture/production-hardening/#how-it-works","title":"How It Works","text":"<p>Rather than using serde's <code>#[serde(deny_unknown_fields)]</code> (which hard-fails at deserialization), rapid_textrank uses <code>#[serde(flatten)]</code> with a <code>HashMap&lt;String, Value&gt;</code> to capture unknown fields. The <code>UnknownFieldsRule</code> validation rule then inspects these maps and emits diagnostics whose severity depends on the <code>strict</code> flag:</p> <ul> <li><code>strict: false</code> (default) \u2014 unknown fields produce warnings. Validation succeeds.</li> <li><code>strict: true</code> \u2014 unknown fields produce errors. Validation fails.</li> </ul> <p>Unknown field detection covers three locations:</p> Location JSON Pointer Prefix Top-level spec <code>/</code> Module set <code>/modules/</code> Runtime spec <code>/runtime/</code>"},{"location":"architecture/production-hardening/#configuration","title":"Configuration","text":"<pre><code>{\n  \"v\": 1,\n  \"strict\": true,\n  \"preset\": \"textrank\"\n}\n</code></pre>"},{"location":"architecture/production-hardening/#example-catching-a-typo","title":"Example: Catching a Typo","text":"<pre><code>{\n  \"v\": 1,\n  \"strict\": true,\n  \"preest\": \"textrank\"\n}\n</code></pre> <p>Validation response:</p> <pre><code>{\n  \"valid\": false,\n  \"diagnostics\": [\n    {\n      \"severity\": \"error\",\n      \"code\": \"unknown_field\",\n      \"path\": \"/preest\",\n      \"message\": \"unrecognized field \\\"preest\\\"\",\n      \"hint\": \"Check spelling or remove this field\"\n    }\n  ]\n}\n</code></pre> <p>Without <code>strict: true</code>, the same spec would produce a warning and <code>\"valid\": true</code> \u2014 the spec executes but <code>preest</code> is ignored.</p>"},{"location":"architecture/production-hardening/#recommendation","title":"Recommendation","text":"<p>Always set <code>strict: true</code> in production. The default is <code>false</code> only for backward compatibility.</p>"},{"location":"architecture/production-hardening/#validate-only-mode","title":"Validate-Only Mode","text":"<p>Validate-only mode runs spec validation and returns a report without performing extraction. Use it as a preflight check in CI pipelines, deployment gates, or config editors.</p>"},{"location":"architecture/production-hardening/#how-it-works_1","title":"How It Works","text":"<p>Set <code>validate_only: true</code> on the input document. The system:</p> <ol> <li>Resolves the preset (if any) and merges module overrides.</li> <li>Runs all validation rules.</li> <li>Returns a <code>ValidationResponse</code> immediately \u2014 no tokens are processed.</li> </ol> <p>The <code>tokens</code> field is not required when <code>validate_only</code> is true.</p>"},{"location":"architecture/production-hardening/#configuration_1","title":"Configuration","text":"<pre><code>{\n  \"validate_only\": true,\n  \"pipeline\": {\n    \"v\": 1,\n    \"strict\": true,\n    \"preset\": \"position_rank\",\n    \"runtime\": { \"max_threads\": 4 }\n  }\n}\n</code></pre>"},{"location":"architecture/production-hardening/#response","title":"Response","text":"<pre><code>{\n  \"valid\": true,\n  \"diagnostics\": []\n}\n</code></pre> <p>Or, when validation fails:</p> <pre><code>{\n  \"valid\": false,\n  \"diagnostics\": [\n    {\n      \"severity\": \"error\",\n      \"code\": \"missing_stage\",\n      \"path\": \"/modules/teleport\",\n      \"message\": \"personalized_pagerank requires a teleport module\",\n      \"hint\": \"Add a teleport module: position, focus_terms, topic_weights, or uniform\"\n    }\n  ]\n}\n</code></pre>"},{"location":"architecture/production-hardening/#requirements","title":"Requirements","text":"<p>A <code>pipeline</code> field must be present. If missing:</p> <pre><code>\"validate_only requires a 'pipeline' field\"\n</code></pre>"},{"location":"architecture/production-hardening/#processing-priority","title":"Processing Priority","text":"<p>When multiple flags are set on a document, the system resolves them in this order:</p> <pre><code>capabilities (1st) \u2192 validate_only (2nd) \u2192 extraction (3rd)\n</code></pre> <p>If <code>capabilities: true</code> and <code>validate_only: true</code> are both set, the capabilities response wins.</p>"},{"location":"architecture/production-hardening/#validation-rules","title":"Validation Rules","text":"<p>The default <code>ValidationEngine</code> runs five rules. All rules run \u2014 the engine never short-circuits on the first error, so users see every problem at once.</p> Rule Checks Error Code <code>rank_teleport</code> <code>personalized_pagerank</code> requires a teleport module <code>missing_stage</code> <code>topic_graph_deps</code> <code>topic_graph</code> / <code>candidate_graph</code> require clustering + phrase_candidates <code>missing_stage</code>, <code>invalid_combo</code> <code>graph_transform_deps</code> <code>remove_intra_cluster_edges</code> requires clustering <code>missing_stage</code> <code>runtime_limits</code> Numeric limits must be &gt; 0 when set <code>limit_exceeded</code> <code>unknown_fields</code> Unrecognized fields (strict \u2192 error, non-strict \u2192 warning) <code>unknown_field</code>"},{"location":"architecture/production-hardening/#custom-rules-rust-api","title":"Custom Rules (Rust API)","text":"<p>Implement the <code>ValidationRule</code> trait to add project-specific checks:</p> <pre><code>use rapid_textrank::pipeline::validation::*;\nuse rapid_textrank::pipeline::errors::PipelineSpecError;\nuse rapid_textrank::pipeline::error_code::ErrorCode;\n\nstruct MaxDampingRule;\n\nimpl ValidationRule for MaxDampingRule {\n    fn name(&amp;self) -&gt; &amp;str { \"max_damping\" }\n\n    fn validate(&amp;self, spec: &amp;PipelineSpecV1) -&gt; Vec&lt;ValidationDiagnostic&gt; {\n        // Your custom check here\n        vec![]\n    }\n}\n\nlet mut engine = ValidationEngine::with_defaults();\nengine.add_rule(Box::new(MaxDampingRule));\nlet report = engine.validate(&amp;spec);\n</code></pre>"},{"location":"architecture/production-hardening/#runtime-limits","title":"Runtime Limits","text":"<p>The <code>RuntimeSpec</code> declares resource budgets for pipeline execution.</p>"},{"location":"architecture/production-hardening/#available-limits","title":"Available Limits","text":"Field Type Default Description <code>max_tokens</code> <code>Option&lt;usize&gt;</code> <code>None</code> Maximum input token count <code>max_nodes</code> <code>Option&lt;usize&gt;</code> <code>None</code> Maximum graph node count <code>max_edges</code> <code>Option&lt;usize&gt;</code> <code>None</code> Maximum graph edge count <code>max_threads</code> <code>Option&lt;usize&gt;</code> <code>None</code> Maximum Rayon thread pool size <code>single_thread</code> <code>bool</code> <code>false</code> Force single-threaded execution <code>max_debug_top_k</code> <code>Option&lt;usize&gt;</code> <code>None</code> Limit debug node_scores output size <code>deterministic</code> <code>Option&lt;bool&gt;</code> <code>None</code> Request deterministic execution"},{"location":"architecture/production-hardening/#configuration_2","title":"Configuration","text":"<pre><code>{\n  \"v\": 1,\n  \"preset\": \"textrank\",\n  \"runtime\": {\n    \"max_tokens\": 200000,\n    \"max_nodes\": 50000,\n    \"max_edges\": 1000000,\n    \"max_threads\": 4,\n    \"max_debug_top_k\": 100\n  }\n}\n</code></pre>"},{"location":"architecture/production-hardening/#validation","title":"Validation","text":"<p>Setting any numeric limit to <code>0</code> produces a validation error:</p> <pre><code>{\n  \"code\": \"limit_exceeded\",\n  \"path\": \"/runtime/max_tokens\",\n  \"message\": \"max_tokens must be greater than 0\",\n  \"hint\": \"Remove max_tokens to disable the limit, or set it to a positive value\"\n}\n</code></pre> <p>Omitting a limit (<code>None</code>) disables it \u2014 no validation error.</p>"},{"location":"architecture/production-hardening/#threading-controls","title":"Threading Controls","text":"<p>Threading limits are enforced at runtime:</p> <ul> <li><code>single_thread: true</code> \u2014 overrides <code>max_threads</code>, forces <code>num_threads(1)</code>.</li> <li><code>max_threads: N</code> \u2014 creates a scoped Rayon thread pool with N threads.</li> <li>Both absent \u2014 uses the global Rayon pool (all logical cores).</li> </ul> <p>Resolution order:</p> <pre><code>single_thread: true  \u2192  effective_threads() = Some(1)\nmax_threads: N       \u2192  effective_threads() = Some(N)\nneither              \u2192  effective_threads() = None (global pool)\n</code></pre> <p>The scoped pool is constructed via <code>RuntimeSpec::build_thread_pool()</code> and applied via <code>RuntimeSpec::scoped(|| { ... })</code>, ensuring all <code>par_iter()</code> calls within the closure use the constrained pool.</p>"},{"location":"architecture/production-hardening/#current-status-resource-limits","title":"Current Status: Resource Limits","text":"<p>Important: <code>max_tokens</code>, <code>max_nodes</code>, and <code>max_edges</code> are validated (must be &gt; 0 when set) but not yet enforced during pipeline execution. They serve as declarative annotations today \u2014 a pipeline with <code>max_tokens: 10000</code> will still process 100,000 tokens without error.</p> <p>Threading controls (<code>max_threads</code>, <code>single_thread</code>) are enforced.</p>"},{"location":"architecture/production-hardening/#deterministic-mode","title":"Deterministic Mode","text":"<p>Deterministic mode forces every pipeline stage to produce identical output across runs, at a potential throughput cost.</p>"},{"location":"architecture/production-hardening/#the-problem_1","title":"The Problem","text":"<p>By default, the library uses the fastest available code path:</p> <ul> <li>Hash map iteration order varies across runs (Rust's random hash seed).</li> <li>Parallel reductions may accumulate floating-point values in different orders.</li> <li>Tie-breaking in ranking may not be stable.</li> </ul> <p>This is fine for most use cases, but problematic when you need bit-exact reproducibility \u2014 for regression testing, audit trails, or reproducible research.</p>"},{"location":"architecture/production-hardening/#how-it-works_2","title":"How It Works","text":"<p><code>DeterminismMode</code> is a two-variant enum:</p> <pre><code>#[derive(Default)]\npub enum DeterminismMode {\n    #[default]\n    Default,        // Fastest \u2014 non-deterministic iteration and reductions\n    Deterministic,  // Stable \u2014 reproducible across runs and machines\n}\n</code></pre> <p>When <code>Deterministic</code> is active, stages must:</p> <ul> <li>Use sorted keys instead of hash-map iteration order.</li> <li>Build CSR graphs in a stable node order.</li> <li>Apply deterministic reductions (no parallel non-deterministic sums).</li> <li>Use a stable tie-breaker comparator for final ranking (lexicographic by lemma).</li> </ul>"},{"location":"architecture/production-hardening/#configuration_3","title":"Configuration","text":"<p>Via <code>TextRankConfig</code> (Rust / native Python):</p> <pre><code>from rapid_textrank import TextRankConfig\n\nconfig = TextRankConfig(determinism=\"deterministic\")\n</code></pre> <p>Via <code>PipelineSpec</code> (JSON interface):</p> <pre><code>{\n  \"v\": 1,\n  \"preset\": \"textrank\",\n  \"runtime\": {\n    \"deterministic\": true\n  }\n}\n</code></pre> <p>Via Rust API:</p> <pre><code>use rapid_textrank::DeterminismMode;\n\nlet cfg = TextRankConfig::default();\n// cfg.determinism = DeterminismMode::Deterministic;\n</code></pre>"},{"location":"architecture/production-hardening/#affected-stages","title":"Affected Stages","text":"Stage Default Behavior Deterministic Behavior Graph build <code>FxHashMap</code> iteration order Sorted (lemma, POS) node order Phrase grouping Hash-map key order Deterministic key ordering Result formatting Score descending, unstable ties Score descending, ties broken by lemma ascending"},{"location":"architecture/production-hardening/#performance-impact","title":"Performance Impact","text":"<p>Deterministic mode adds sorting overhead proportional to the number of graph nodes and phrase groups. For typical documents (&lt; 1000 unique candidates), the overhead is negligible. For very large documents (10K+ candidates), expect 5\u201315% throughput reduction.</p>"},{"location":"architecture/production-hardening/#serialization","title":"Serialization","text":"Mode JSON Serde Default <code>\"default\"</code> <code>DeterminismMode::Default</code> Deterministic <code>\"deterministic\"</code> <code>DeterminismMode::Deterministic</code>"},{"location":"architecture/production-hardening/#capability-discovery","title":"Capability Discovery","text":"<p>Capability discovery returns a static response describing what this build of rapid_textrank supports \u2014 versions, presets, and available modules per stage. Use it to negotiate feature support at runtime without attempting extraction.</p>"},{"location":"architecture/production-hardening/#how-it-works_3","title":"How It Works","text":"<p>Set <code>capabilities: true</code> on the input document. No <code>tokens</code>, <code>config</code>, or <code>pipeline</code> fields are needed.</p>"},{"location":"architecture/production-hardening/#configuration_4","title":"Configuration","text":"<pre><code>{\n  \"capabilities\": true\n}\n</code></pre>"},{"location":"architecture/production-hardening/#response_1","title":"Response","text":"<pre><code>{\n  \"version\": \"0.7.0\",\n  \"pipeline_spec_versions\": [1],\n  \"presets\": [\n    \"textrank\",\n    \"position_rank\",\n    \"biased_textrank\",\n    \"single_rank\",\n    \"topical_pagerank\",\n    \"topic_rank\",\n    \"multipartite_rank\",\n    \"sentence_rank\"\n  ],\n  \"modules\": {\n    \"preprocess\": [\"default\"],\n    \"candidates\": [\"word_nodes\", \"phrase_candidates\", \"sentence_candidates\"],\n    \"graph\": [\"cooccurrence_window\", \"topic_graph\", \"candidate_graph\", \"sentence_graph\"],\n    \"graph_transforms\": [\"remove_intra_cluster_edges\", \"alpha_boost\"],\n    \"teleport\": [\"uniform\", \"position\", \"focus_terms\", \"topic_weights\"],\n    \"clustering\": [\"hac\"],\n    \"rank\": [\"standard_pagerank\", \"personalized_pagerank\"],\n    \"phrases\": [\"chunk_phrases\", \"sentence_phrases\"],\n    \"format\": [\"standard_json\", \"sentence_json\"]\n  }\n}\n</code></pre>"},{"location":"architecture/production-hardening/#feature-gating","title":"Feature Gating","text":"<p>Some modules are conditionally compiled behind Cargo feature flags:</p> Module Feature Flag Present When <code>sentence_candidates</code> <code>sentence-rank</code> Feature enabled (default) <code>sentence_graph</code> <code>sentence-rank</code> Feature enabled (default) <code>sentence_phrases</code> <code>sentence-rank</code> Feature enabled (default) <code>sentence_json</code> <code>sentence-rank</code> Feature enabled (default) <code>sentence_rank</code> (preset) <code>sentence-rank</code> Feature enabled (default) <p>When <code>sentence-rank</code> is not compiled in, these entries are absent from the response.</p>"},{"location":"architecture/production-hardening/#use-cases","title":"Use Cases","text":"<ul> <li>Client negotiation: Check whether the server supports <code>sentence_rank</code> before sending a document with that preset.</li> <li>Config UI generation: Build a dropdown of available presets and module types from the response.</li> <li>Version checking: Compare the <code>version</code> field against known-good versions for deployment.</li> </ul>"},{"location":"architecture/production-hardening/#error-types","title":"Error Types","text":"<p>All production hardening features share two error types with a common structure.</p>"},{"location":"architecture/production-hardening/#pipelinespecerror-build-time","title":"<code>PipelineSpecError</code> (Build-Time)","text":"<p>Found during spec validation, before execution begins.</p> <pre><code>{\n  \"code\": \"missing_stage\",\n  \"path\": \"/modules/teleport\",\n  \"message\": \"personalized_pagerank requires a teleport module\",\n  \"hint\": \"Add a teleport module: position, focus_terms, topic_weights, or uniform\"\n}\n</code></pre> <p>Display format: <code>[missing_stage] /modules/teleport: personalized_pagerank requires a teleport module</code></p>"},{"location":"architecture/production-hardening/#pipelineruntimeerror-execution-time","title":"<code>PipelineRuntimeError</code> (Execution-Time)","text":"<p>Failures during pipeline execution.</p> <pre><code>{\n  \"code\": \"convergence_failed\",\n  \"path\": \"/modules/rank\",\n  \"stage\": \"rank\",\n  \"message\": \"PageRank did not converge after 100 iterations\",\n  \"hint\": \"Increase max_iterations or relax the convergence threshold\"\n}\n</code></pre> <p>Display format: <code>[convergence_failed] /modules/rank (stage: rank): PageRank did not converge after 100 iterations</code></p>"},{"location":"architecture/production-hardening/#error-codes","title":"Error Codes","text":"<p>All error codes are <code>#[non_exhaustive]</code> \u2014 new codes may be added in future versions. Always include a wildcard arm when matching.</p> Code Serialized Meaning <code>MissingStage</code> <code>\"missing_stage\"</code> A required pipeline stage is absent <code>InvalidCombo</code> <code>\"invalid_combo\"</code> Configuration options conflict <code>ModuleUnavailable</code> <code>\"module_unavailable\"</code> Requested module not available in this build <code>LimitExceeded</code> <code>\"limit_exceeded\"</code> Numeric value out of allowed range <code>UnknownField</code> <code>\"unknown_field\"</code> Unrecognized field name in spec <code>InvalidValue</code> <code>\"invalid_value\"</code> Field value invalid for its context <code>IncompatibleModules</code> <code>\"incompatible_modules\"</code> Selected modules cannot work together <code>ValidationFailed</code> <code>\"validation_failed\"</code> General validation failure <code>StageFailed</code> <code>\"stage_failed\"</code> Pipeline stage crashed during execution <code>ConvergenceFailed</code> <code>\"convergence_failed\"</code> PageRank did not converge"},{"location":"architecture/production-hardening/#build-validate-run-lifecycle","title":"Build-Validate-Run Lifecycle","text":"<p>The <code>SpecPipelineBuilder</code> integrates validation into a three-phase lifecycle:</p> <pre><code>Resolve \u2192 Validate \u2192 Build\n</code></pre> <ol> <li>Resolve \u2014 <code>resolve_spec(&amp;spec)</code> merges the preset with module overrides to produce a fully-specified <code>PipelineSpecV1</code>.</li> <li>Validate \u2014 <code>ValidationEngine::with_defaults().validate(&amp;effective)</code> runs all rules. If any error is found, <code>build_from_spec</code> returns early with the first error.</li> <li>Build \u2014 Each module spec is mapped to a concrete stage implementation, producing a <code>DynPipeline</code> ready to execute.</li> </ol> <pre><code>let pipeline = SpecPipelineBuilder::new()\n    .with_chunks(chunks)\n    .build_from_spec(&amp;spec, &amp;cfg)?;  // resolve + validate + build\n\nlet result = pipeline.run(stream, &amp;cfg, &amp;mut obs);\n</code></pre> <p>The validate-only JSON path (<code>validate_only: true</code>) performs steps 1\u20132 and returns the report, skipping step 3 entirely.</p>"},{"location":"architecture/production-hardening/#putting-it-all-together","title":"Putting It All Together","text":"<p>A production-grade pipeline spec combining all hardening features:</p> <pre><code>{\n  \"validate_only\": false,\n  \"pipeline\": {\n    \"v\": 1,\n    \"strict\": true,\n    \"preset\": \"position_rank\",\n    \"runtime\": {\n      \"max_tokens\": 200000,\n      \"max_nodes\": 50000,\n      \"max_edges\": 1000000,\n      \"max_threads\": 4,\n      \"deterministic\": true,\n      \"max_debug_top_k\": 50\n    },\n    \"expose\": {\n      \"graph_stats\": true,\n      \"stage_timings\": true\n    }\n  },\n  \"tokens\": [...]\n}\n</code></pre> <p>This spec:</p> <ol> <li>Strict mode catches any typos in field names.</li> <li>Runtime limits declare resource expectations (validated, not yet enforced).</li> <li>Threading is constrained to 4 threads.</li> <li>Deterministic output is guaranteed.</li> <li>Debug output includes graph stats and stage timings for observability.</li> </ol> <p>To preflight this spec before deploying:</p> <pre><code>{\n  \"validate_only\": true,\n  \"pipeline\": {\n    \"v\": 1,\n    \"strict\": true,\n    \"preset\": \"position_rank\",\n    \"runtime\": {\n      \"max_tokens\": 200000,\n      \"max_threads\": 4,\n      \"deterministic\": true\n    }\n  }\n}\n</code></pre> <p>To check what the server supports:</p> <pre><code>{\n  \"capabilities\": true\n}\n</code></pre>"},{"location":"development/contributing/","title":"Contributing","text":"<p>This page covers how to set up a development environment for rapid_textrank and, for maintainers, how to publish releases.</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Rust 1.70+ -- install from rustup.rs</li> <li>Python 3.9+ -- install from python.org</li> <li>maturin -- the Rust/Python build tool (<code>pip install maturin</code>)</li> </ul>"},{"location":"development/contributing/#building-from-source","title":"Building from Source","text":"<pre><code>git clone https://github.com/xang1234/rapid-textrank\ncd rapid_textrank\npip install maturin\nmaturin develop --release\n</code></pre>"},{"location":"development/contributing/#installing-dev-dependencies","title":"Installing Dev Dependencies","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This installs the package in editable mode along with development dependencies (pytest, etc.).</p>"},{"location":"development/contributing/#running-python-tests","title":"Running Python Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"development/contributing/#running-rust-tests","title":"Running Rust Tests","text":"<pre><code>cargo test\n</code></pre> <p>This runs the full Rust test suite, including unit tests and integration tests.</p>"},{"location":"development/contributing/#for-maintainers","title":"For Maintainers","text":""},{"location":"development/contributing/#publishing","title":"Publishing","text":"<p>Publishing is automated with GitHub Actions using Trusted Publishing (OIDC), so no API tokens need to be stored as secrets.</p>"},{"location":"development/contributing/#testpypi-release","title":"TestPyPI Release","text":"<p>Push a tag matching the <code>test-*</code> pattern:</p> <pre><code>git tag -a test-0.1.0 -m \"TestPyPI 0.1.0\"\ngit push origin test-0.1.0\n</code></pre> <p>This triggers the <code>.github/workflows/publish-testpypi.yml</code> workflow.</p>"},{"location":"development/contributing/#pypi-release","title":"PyPI Release","text":"<p>Push a tag matching the <code>v*</code> pattern:</p> <pre><code>git tag -a v0.1.0 -m \"Release 0.1.0\"\ngit push origin v0.1.0\n</code></pre> <p>This triggers the <code>.github/workflows/publish-pypi.yml</code> workflow.</p>"},{"location":"development/contributing/#wheel-builds","title":"Wheel Builds","text":"<p>GitHub Actions builds wheels for:</p> <ul> <li>Python versions: 3.9, 3.10, 3.11, 3.12</li> <li>Platforms: Linux (manylinux), macOS (x86_64, arm64), Windows (x86_64)</li> </ul>"},{"location":"development/contributing/#trusted-publisher-setup","title":"Trusted Publisher Setup","text":"<p>Before the first publish, add Trusted Publishers on both TestPyPI and PyPI:</p> <ul> <li>Repository: <code>xang1234/textranker</code></li> <li>Workflows:<ul> <li><code>.github/workflows/publish-testpypi.yml</code></li> <li><code>.github/workflows/publish-pypi.yml</code></li> </ul> </li> <li>Environments:<ul> <li><code>testpypi</code></li> <li><code>pypi</code></li> </ul> </li> </ul> <p>You can also trigger either workflow manually via the GitHub Actions UI if needed.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This section covers everything you need to go from zero to extracting keywords with rapid_textrank. Whether you want a one-liner or a fully tuned pipeline, start here.</p> <ul> <li>Installation -- install from PyPI (with optional spaCy and topic-model extras) or build from source.</li> <li>Quick Start -- a minimal working example, plus pointers to the class-based and JSON APIs.</li> <li>Recipes -- five grab-and-go examples covering SEO keywording, academic extraction, security-focused analysis, LDA-guided keywords, and multi-topic documents.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#from-pypi","title":"From PyPI","text":"<p>The simplest way to install rapid_textrank:</p> <pre><code>pip install rapid_textrank\n</code></pre> <p>The import name is <code>rapid_textrank</code>.</p>"},{"location":"getting-started/installation/#optional-extras","title":"Optional Extras","text":""},{"location":"getting-started/installation/#spacy-support","title":"spaCy support","text":"<p>If you want to use the JSON interface with spaCy-tokenized input, or the spaCy pipeline component:</p> <pre><code>pip install rapid_textrank[spacy]\n</code></pre> <p>You will also need a spaCy model:</p> <pre><code>python -m spacy download en_core_web_sm\n</code></pre>"},{"location":"getting-started/installation/#topic-model-support","title":"Topic model support","text":"<p>If you plan to use <code>TopicalPageRank</code> with <code>topic_weights_from_lda</code> (gensim LDA integration):</p> <pre><code>pip install rapid_textrank[topic]\n</code></pre> <p>This installs gensim as an extra dependency.</p>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<p>Requirements: Rust 1.70+, Python 3.9+</p> <pre><code>git clone https://github.com/xang1234/rapid-textrank\ncd rapid_textrank\npip install maturin\nmaturin develop --release\n</code></pre> <p>This compiles the Rust core and installs the package into your current Python environment.</p>"},{"location":"getting-started/installation/#verifying-the-installation","title":"Verifying the Installation","text":"<pre><code>import rapid_textrank\nprint(rapid_textrank.extract_keywords(\"Hello world\", top_n=1))\n</code></pre> <p>If the import succeeds and returns a result list, the installation is working correctly.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":""},{"location":"getting-started/quickstart/#extract-keywords-in-five-lines","title":"Extract Keywords in Five Lines","text":"<p>The fastest way to pull keywords from text is the <code>extract_keywords</code> convenience function:</p> <pre><code>from rapid_textrank import extract_keywords\n\ntext = \"\"\"\nMachine learning is a subset of artificial intelligence that enables\nsystems to learn and improve from experience. Deep learning, a type of\nmachine learning, uses neural networks with many layers.\n\"\"\"\n\nkeywords = extract_keywords(text, top_n=5, language=\"en\")\nfor phrase in keywords:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>Output:</p> <pre><code>machine learning: 0.2341\ndeep learning: 0.1872\nartificial intelligence: 0.1654\nneural networks: 0.1432\nsystems: 0.0891\n</code></pre> <p>Each returned <code>Phrase</code> object carries several attributes:</p> Attribute Description <code>text</code> Surface form of the phrase (e.g., <code>\"machine learning\"</code>) <code>lemma</code> Lemmatized form <code>score</code> TextRank score <code>count</code> Number of occurrences in the text <code>rank</code> 1-indexed rank"},{"location":"getting-started/quickstart/#class-based-api","title":"Class-Based API","text":"<p>For more control -- choosing an algorithm variant, tuning configuration, or reusing an extractor across multiple documents -- use the class-based API:</p> <pre><code>from rapid_textrank import BaseTextRank, TextRankConfig\n\nconfig = TextRankConfig(\n    top_n=10,\n    language=\"en\",\n    min_phrase_length=2,\n    max_phrase_length=4,\n)\n\nextractor = BaseTextRank(config=config)\nresult = extractor.extract_keywords(text)\n\nfor phrase in result.phrases:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>All seven algorithm variants (<code>BaseTextRank</code>, <code>PositionRank</code>, <code>BiasedTextRank</code>, <code>TopicRank</code>, <code>SingleRank</code>, <code>TopicalPageRank</code>, <code>MultipartiteRank</code>) follow the same pattern. See the Extractor Classes reference for the full list of constructors and parameters.</p>"},{"location":"getting-started/quickstart/#json-interface","title":"JSON Interface","text":"<p>If you already tokenize with spaCy (or another NLP pipeline), you can pass pre-tokenized data directly via the JSON interface to avoid re-tokenizing in Rust:</p> <pre><code>import json\nfrom rapid_textrank import extract_from_json\n\npayload = {\n    \"tokens\": [\n        {\n            \"text\": \"Machine\",\n            \"lemma\": \"machine\",\n            \"pos\": \"NOUN\",\n            \"start\": 0,\n            \"end\": 7,\n            \"sentence_idx\": 0,\n            \"token_idx\": 0,\n            \"is_stopword\": False,\n        },\n        # ... more tokens\n    ],\n    \"variant\": \"textrank\",\n    \"config\": {\"top_n\": 10, \"language\": \"en\"},\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\n</code></pre> <p>See the JSON Interface reference for full details on the payload schema and supported variants.</p> <p>Interactive Notebook</p> <p>Explore this topic in the Quick Start Notebook.</p>"},{"location":"getting-started/recipes/","title":"Recipes","text":"<p>These recipes are grab-and-go starting points for common real-world tasks. Each one is a self-contained example you can copy, paste, and adapt.</p> <p>Notes:</p> <ul> <li>Outputs will vary by input text (and by tokenization if you use spaCy vs the built-in tokenizer).</li> <li>If you want to tune phrase shapes (2--4 word phrases, noun-only phrases, grouping behavior, etc.), see the TextRankConfig reference.</li> </ul>"},{"location":"getting-started/recipes/#1-seo-blog-keywording-basetextrank-phrase-grouping","title":"1. SEO / Blog Keywording (BaseTextRank + Phrase Grouping)","text":"<p>Goal: extract \"SEO-ready\" keyphrases (usually 2--4 words) from a blog post draft or landing page copy.</p> <p>This recipe emphasizes:</p> <ul> <li>Multi-word phrases (to avoid a list of generic single tokens).</li> <li>Noun/adjective/proper-noun phrases (to filter out noisy verbs).</li> <li>Scrubbed-text grouping (so phrases look like what you would actually put in a CMS or brief).</li> <li>Optional lemma-deduping (to avoid near-duplicates in your final list).</li> </ul> <pre><code>from rapid_textrank import BaseTextRank, TextRankConfig\n\ntext = \"\"\"\nPrivacy-first analytics is becoming the default choice for SaaS teams who\nwant accurate conversion tracking without relying on third-party cookies.\nIn this guide, we'll compare cookieless tracking, first-party event capture,\nself-hosted deployment, and GDPR-friendly consent flows.\n\nYou'll learn how to:\n- pick a privacy-first analytics tool for product and marketing,\n- define an event taxonomy (signup, activation, retention),\n- build dashboards for funnel conversion and cohort retention,\n- ship tracking with minimal performance impact.\n\"\"\"\n\nconfig = TextRankConfig(\n    top_n=25,\n    language=\"en\",\n\n    # SEO keyword lists generally benefit from longer phrases.\n    min_phrase_length=2,\n    max_phrase_length=4,\n\n    # Most SEO phrases are noun-y. Dropping VERB helps reduce \"learn how\" style noise.\n    include_pos=[\"NOUN\", \"ADJ\", \"PROPN\"],\n\n    # Group phrases by scrubbed surface form so outputs look \"human\" (vs pure lemmas).\n    phrase_grouping=\"scrubbed_text\",\n\n    # Add your own \"boilerplate\" stopwords (brand name, CTA words, years, etc.).\n    stopwords=[\n        \"guide\", \"tutorial\", \"tips\", \"step\", \"steps\",\n        \"learn\", \"using\", \"use\", \"how\",\n        \"2026\",  # years often sneak into keyword lists\n    ],\n)\n\nextractor = BaseTextRank(config=config)\nresult = extractor.extract_keywords(text)\n\n# Optional: dedupe by lemma so you don't end up with near-duplicates.\nseen = set()\nkeywords = []\nfor phrase in result.phrases:\n    key = phrase.lemma\n    if key not in seen:\n        seen.add(key)\n        keywords.append(phrase.text)\n\nprint(keywords[:15])\n</code></pre> <p>Example output (will vary by input text):</p> <pre><code>[\n  'privacy-first analytics',\n  'cookieless tracking',\n  'first-party event capture',\n  'self-hosted deployment',\n  'gdpr-friendly consent flows',\n  'event taxonomy',\n  'funnel conversion',\n  'cohort retention',\n  'conversion tracking',\n  'performance impact'\n]\n</code></pre> <p>Practical tweaks for SEO workflows:</p> <ul> <li>Run on: H1 + first 2--3 paragraphs + headings. Full posts can dilute intent.</li> <li>Add stopwords for your brand/product name if it dominates results.</li> <li>If you need canonical forms for spreadsheets: use <code>phrase.lemma</code> instead of <code>phrase.text</code>.</li> </ul>"},{"location":"getting-started/recipes/#2-academic-abstract-extraction-positionrank","title":"2. Academic Abstract Extraction (PositionRank)","text":"<p>Goal: extract keyphrases from paper abstracts (or news articles) where important terms are typically introduced early. PositionRank biases the random walk toward early-occurring candidates, which often matches academic writing style.</p> <p>Tip: include the paper title and abstract together in one string -- titles are short but highly informative.</p> <pre><code>from rapid_textrank import PositionRank\n\ntext = \"\"\"\nTitle: Efficient Graph-Based Keyphrase Extraction with Sparse Updates\n\nAbstract: Keyphrase extraction is commonly used to index scientific documents,\nsupport literature discovery, and improve retrieval. We propose a sparse-update\ngraph ranking method that reduces computational cost while preserving phrase quality.\nExperiments on benchmark datasets show improved F1 under strict matching.\n\"\"\"\n\nextractor = PositionRank(top_n=12, language=\"en\")\nresult = extractor.extract_keywords(text)\n\n# Print the top phrases (scores shown for debugging; sort order is by score).\nfor phrase in result.phrases[:10]:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>When PositionRank usually helps:</p> <ul> <li>Short, structured documents (title + abstract).</li> <li>News leads (topic stated upfront).</li> <li>Executive summaries (key themes early).</li> </ul> <p>If you want fewer generic results:</p> <p>Increase <code>top_n</code> and then keep only 2--4 word phrases in post-processing:</p> <pre><code>filtered = [p.text for p in result.phrases if 2 &lt;= len(p.text.split()) &lt;= 4]\n</code></pre>"},{"location":"getting-started/recipes/#3-security-privacy-focused-extraction-biasedtextrank","title":"3. Security / Privacy-Focused Extraction (BiasedTextRank)","text":"<p>Goal: pull out security- or privacy-relevant phrases from a mixed document (policies, architecture docs, incident reports, DPIAs, vendor questionnaires). BiasedTextRank lets you \"steer\" extraction toward your focus terms while still discovering related phrases.</p> <pre><code>from rapid_textrank import BiasedTextRank\n\ntext = \"\"\"\nWe encrypt data at rest using AES-256 and enforce TLS 1.2+ for data in transit.\nAccess to production is gated by MFA and short-lived credentials. Audit logs are\nretained for 180 days and monitored for anomalous access patterns. Personal data\nprocessing is limited to the declared purpose, and retention follows a documented\nschedule. We support DSAR workflows and apply data minimization by default.\n\"\"\"\n\nextractor = BiasedTextRank(\n    # Keep focus terms simple (single tokens). Think: what you'd search for in the doc.\n    focus_terms=[\n        \"privacy\", \"personal\", \"pii\", \"encrypt\", \"encryption\",\n        \"tls\", \"mfa\", \"audit\", \"retention\", \"dsar\", \"minimization\"\n    ],\n    bias_weight=8.0,   # 5-10 is a reasonable starting band\n    top_n=15,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(text)\nfor phrase in result.phrases[:10]:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>Two useful patterns:</p> <ul> <li>Query-driven extraction: set <code>focus_terms</code> from user input (e.g., \"SOC2 audit logging\").</li> <li>Per-call focus override (same extractor, different focus sets):</li> </ul> <pre><code>result = extractor.extract_keywords(text, focus_terms=[\"privacy\", \"retention\", \"dsar\"])\n</code></pre>"},{"location":"getting-started/recipes/#4-topic-model-guided-keywords-from-lda-topicalpagerank","title":"4. Topic-Model Guided Keywords from LDA (TopicalPageRank)","text":"<p>Goal: if you already run LDA (or any topic model) on a corpus, use the topic distribution to bias keyword extraction automatically. TopicalPageRank uses a personalization vector where words with higher topic weights get more teleport probability.</p> <p>This recipe uses the built-in <code>topic_weights_from_lda</code> helper for gensim LDA.</p> <pre><code>pip install rapid_textrank[topic]   # installs gensim\n</code></pre> <pre><code>from gensim.corpora import Dictionary\nfrom gensim.models import LdaModel\nfrom rapid_textrank import TopicalPageRank, topic_weights_from_lda\n\n# Tiny example corpus (replace with your real corpus)\ncorpus = [\n    \"transformers attention neural networks deep learning\",\n    \"access control authentication encryption audit logging\",\n    \"renewable energy solar wind grid storage batteries\",\n    \"customer retention cohort analysis activation funnel\",\n    \"privacy gdpr consent tracking cookies analytics\",\n]\n\ntexts = [doc.lower().split() for doc in corpus]\ndictionary = Dictionary(texts)\nbow_corpus = [dictionary.doc2bow(t) for t in texts]\n\nlda = LdaModel(bow_corpus, num_topics=3, id2word=dictionary, random_state=0)\n\n# Pick a document and compute topic weights for it\ndoc_id = 4\nraw_text = corpus[doc_id]\nweights = topic_weights_from_lda(lda, bow_corpus[doc_id], dictionary)\n\nextractor = TopicalPageRank(\n    topic_weights=weights,\n    min_weight=0.01,   # floor for words missing from the topic weights\n    top_n=12,\n    language=\"en\",\n)\n\nresult = extractor.extract_keywords(raw_text)\nfor phrase in result.phrases[:10]:\n    print(f\"{phrase.text}: {phrase.score:.4f}\")\n</code></pre> <p>Operational tips:</p> <ul> <li>For batch pipelines, keep one <code>TopicalPageRank</code> instance and pass new weights per call:</li> </ul> <pre><code>result = extractor.extract_keywords(other_text, topic_weights=other_weights)\n</code></pre> <ul> <li><code>topic_weights_from_lda</code> supports <code>aggregation</code> (<code>\"max\"</code> or <code>\"mean\"</code>) and <code>top_n_words</code> to tune how per-topic weights get combined.</li> </ul>"},{"location":"getting-started/recipes/#5-multi-topic-documents-topicrank-multipartiterank","title":"5. Multi-Topic Documents (TopicRank / MultipartiteRank)","text":"<p>Goal: extract diverse phrases from long documents that cover multiple themes (e.g., quarterly reports, RFCs, incident postmortems). Vanilla TextRank can over-focus on the dominant cluster.</p> <p>Two strong options:</p> <ul> <li>TopicRank clusters candidates into topics, ranks topics, then selects representatives (diversity-first).</li> <li>MultipartiteRank keeps candidates but removes intra-topic edges and can boost early variants (more nuanced).</li> </ul>"},{"location":"getting-started/recipes/#topicrank-via-json-interface-great-if-you-already-tokenize-with-spacy","title":"TopicRank (via JSON interface -- great if you already tokenize with spaCy)","text":"<pre><code>pip install rapid_textrank[spacy]\npython -m spacy download en_core_web_sm\n</code></pre> <pre><code>import json\nimport spacy\nfrom rapid_textrank import extract_from_json\n\ntext = \"\"\"\nProduct: We shipped a new recommendation system and improved onboarding conversion.\nSecurity: We rolled out MFA for all admins and expanded audit logging for production access.\nFinance: Revenue grew 18% QoQ and churn decreased after pricing changes.\nCompliance: We updated our retention policy and improved DSAR response automation.\n\"\"\"\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(text)\n\ntokens = []\nfor sent_idx, sent in enumerate(doc.sents):\n    for token in sent:\n        tokens.append({\n            \"text\": token.text,\n            \"lemma\": token.lemma_,\n            \"pos\": token.pos_,\n            \"start\": token.idx,\n            \"end\": token.idx + len(token.text),\n            \"sentence_idx\": sent_idx,\n            \"token_idx\": token.i,\n            \"is_stopword\": token.is_stop,\n        })\n\npayload = {\n    \"tokens\": tokens,\n    \"variant\": \"topic_rank\",\n    \"config\": {\n        \"top_n\": 15,\n        \"language\": \"en\",\n\n        # Higher threshold =&gt; fewer, larger topics (more aggressive clustering).\n        \"topic_similarity_threshold\": 0.25,\n        \"topic_edge_weight\": 1.0,\n    },\n}\n\nresult = json.loads(extract_from_json(json.dumps(payload)))\nprint([p[\"text\"] for p in result[\"phrases\"][:12]])\n</code></pre>"},{"location":"getting-started/recipes/#multipartiterank-native-class-no-spacy-needed","title":"MultipartiteRank (native class -- no spaCy needed)","text":"<pre><code>from rapid_textrank import MultipartiteRank\n\nextractor = MultipartiteRank(\n    similarity_threshold=0.26,\n    alpha=1.1,      # 0 disables the position boost\n    top_n=15,\n    language=\"en\",\n)\nresult = extractor.extract_keywords(text)\nprint([p.text for p in result.phrases[:12]])\n</code></pre> <p>If you want even more diversity:</p> <ul> <li>Split the document by headings or sections and run extraction per section, then merge and deduplicate.</li> </ul>"},{"location":"performance/","title":"Performance","text":"<p>rapid_textrank is designed for speed. The Rust core delivers 10-100x faster keyword extraction compared to pure Python implementations, depending on document size and tokenization method.</p>"},{"location":"performance/#key-performance-features","title":"Key Performance Features","text":"<ul> <li>Rust core with zero-copy data paths -- most computation happens in compiled Rust code, minimizing Python overhead</li> <li>CSR graph format -- Compressed Sparse Row storage for cache-friendly PageRank iteration</li> <li>String interning -- <code>StringPool</code> reduces memory allocations 10-100x for typical documents</li> <li>Parallel processing -- Rayon provides data parallelism for internal graph construction</li> <li>Link-Time Optimization -- full LTO with single codegen unit for maximum inlining</li> <li>FxHash -- fast non-cryptographic hashing for internal hash maps</li> </ul>"},{"location":"performance/#approximate-speedups","title":"Approximate Speedups","text":"Document Size rapid_textrank pytextrank + spaCy Speedup Small (~20 words) ~0.1 ms ~5 ms ~50x Medium (~100 words) ~0.3 ms ~15 ms ~50x Large (~1000 words) ~2 ms ~80 ms ~40x <p>Results are approximate and vary by hardware. See the Benchmarks page for a runnable benchmark script.</p>"},{"location":"performance/#learn-more","title":"Learn More","text":"<ul> <li>Benchmarks -- detailed benchmark results and a script to measure performance on your system</li> <li>Why Rust is Fast -- deep dive into the performance optimizations used in rapid_textrank</li> <li>Comparison -- how rapid_textrank compares to alternative keyword extraction libraries</li> </ul>"},{"location":"performance/benchmarks/","title":"Benchmarks","text":"<p>rapid_textrank achieves significant speedups over pure Python TextRank implementations through Rust's performance characteristics and careful algorithm implementation.</p>"},{"location":"performance/benchmarks/#pre-computed-results","title":"Pre-computed Results","text":"<p>The table below shows approximate timings measured on a modern laptop. Your results will vary depending on hardware, Python version, and system load.</p> Document Size rapid_textrank pytextrank + spaCy Speedup Small (~20 words) ~0.1 ms ~5 ms ~50x Medium (~100 words) ~0.3 ms ~15 ms ~50x Large (~1000 words) ~2 ms ~80 ms ~40x <p>About these numbers</p> <p>Results are approximate and depend on hardware. Run the benchmark script below to measure on your system.</p>"},{"location":"performance/benchmarks/#benchmark-script","title":"Benchmark Script","text":"<p>Use the script below to compare rapid_textrank and pytextrank performance on your own hardware.</p> Benchmark Script <pre><code>\"\"\"\nBenchmark: rapid_textrank vs pytextrank\n\nPrerequisites:\n    pip install rapid_textrank pytextrank spacy\n    python -m spacy download en_core_web_sm\n\"\"\"\n\nimport time\nimport statistics\n\n# Sample texts of varying sizes\nTEXTS = {\n    \"small\": \"\"\"\n        Machine learning is a subset of artificial intelligence.\n        Deep learning uses neural networks with many layers.\n    \"\"\",\n\n    \"medium\": \"\"\"\n        Natural language processing (NLP) is a field of artificial intelligence\n        that focuses on the interaction between computers and humans through\n        natural language. The ultimate goal of NLP is to enable computers to\n        understand, interpret, and generate human language in a valuable way.\n\n        Machine learning approaches have transformed NLP in recent years.\n        Deep learning models, particularly transformers, have achieved\n        state-of-the-art results on many NLP tasks including translation,\n        summarization, and question answering.\n\n        Key applications include sentiment analysis, named entity recognition,\n        machine translation, and text classification. These technologies\n        power virtual assistants, search engines, and content recommendation\n        systems used by millions of people daily.\n    \"\"\",\n\n    \"large\": \"\"\"\n        Artificial intelligence has evolved dramatically since its inception in\n        the mid-20th century. Early AI systems relied on symbolic reasoning and\n        expert systems, where human knowledge was manually encoded into rules.\n\n        The machine learning revolution changed everything. Instead of explicit\n        programming, systems learn patterns from data. Supervised learning uses\n        labeled examples, unsupervised learning finds hidden structures, and\n        reinforcement learning optimizes through trial and error.\n\n        Deep learning, powered by neural networks with multiple layers, has\n        achieved remarkable success. Convolutional neural networks excel at\n        image recognition. Recurrent neural networks and transformers handle\n        sequential data like text and speech. Generative adversarial networks\n        create realistic synthetic content.\n\n        Natural language processing has been transformed by these advances.\n        Word embeddings capture semantic relationships. Attention mechanisms\n        allow models to focus on relevant context. Large language models\n        demonstrate emergent capabilities in reasoning and generation.\n\n        Computer vision applications include object detection, facial recognition,\n        medical image analysis, and autonomous vehicle perception. These systems\n        process visual information with superhuman accuracy in many domains.\n\n        The ethical implications of AI are significant. Bias in training data\n        can lead to unfair outcomes. Privacy concerns arise from data collection.\n        Job displacement affects workers across industries. Regulation and\n        governance frameworks are being developed worldwide.\n\n        Future directions include neuromorphic computing, quantum machine learning,\n        and artificial general intelligence. Researchers continue to push\n        boundaries while addressing safety and alignment challenges.\n    \"\"\" * 3  # ~1000 words\n}\n\n\ndef benchmark_rapid_textrank(text: str, runs: int = 10) -&gt; dict:\n    \"\"\"Benchmark rapid_textrank.\"\"\"\n    from rapid_textrank import BaseTextRank\n\n    extractor = BaseTextRank(top_n=10, language=\"en\")\n\n    # Warmup\n    extractor.extract_keywords(text)\n\n    times = []\n    for _ in range(runs):\n        start = time.perf_counter()\n        result = extractor.extract_keywords(text)\n        elapsed = time.perf_counter() - start\n        times.append(elapsed * 1000)  # Convert to ms\n\n    return {\n        \"min\": min(times),\n        \"mean\": statistics.mean(times),\n        \"median\": statistics.median(times),\n        \"std\": statistics.stdev(times) if len(times) &gt; 1 else 0,\n        \"phrases\": len(result.phrases)\n    }\n\n\ndef benchmark_pytextrank(text: str, runs: int = 10) -&gt; dict:\n    \"\"\"Benchmark pytextrank with spaCy.\"\"\"\n    import spacy\n    import pytextrank\n\n    nlp = spacy.load(\"en_core_web_sm\")\n    nlp.add_pipe(\"textrank\")\n\n    # Warmup\n    doc = nlp(text)\n\n    times = []\n    for _ in range(runs):\n        start = time.perf_counter()\n        doc = nlp(text)\n        phrases = list(doc._.phrases[:10])\n        elapsed = time.perf_counter() - start\n        times.append(elapsed * 1000)\n\n    return {\n        \"min\": min(times),\n        \"mean\": statistics.mean(times),\n        \"median\": statistics.median(times),\n        \"std\": statistics.stdev(times) if len(times) &gt; 1 else 0,\n        \"phrases\": len(phrases)\n    }\n\n\ndef main():\n    print(\"=\" * 70)\n    print(\"TextRank Performance Benchmark\")\n    print(\"=\" * 70)\n\n    for size, text in TEXTS.items():\n        word_count = len(text.split())\n        print(f\"\\n{size.upper()} TEXT (~{word_count} words)\")\n        print(\"-\" * 50)\n\n        # Benchmark rapid_textrank\n        rust_results = benchmark_rapid_textrank(text)\n        print(f\"rapid_textrank:  {rust_results['mean']:&gt;8.2f} ms (\u00b1{rust_results['std']:.2f})\")\n\n        # Benchmark pytextrank\n        try:\n            py_results = benchmark_pytextrank(text)\n            print(f\"pytextrank:     {py_results['mean']:&gt;8.2f} ms (\u00b1{py_results['std']:.2f})\")\n\n            speedup = py_results['mean'] / rust_results['mean']\n            print(f\"Speedup:        {speedup:&gt;8.1f}x faster\")\n        except Exception as e:\n            print(f\"pytextrank:     (not available: {e})\")\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Note: pytextrank times include spaCy tokenization.\")\n    print(\"For fair comparison with pre-tokenized input, use rapid_textrank's JSON API.\")\n    print(\"=\" * 70)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"performance/benchmarks/#notes-on-fair-comparison","title":"Notes on Fair Comparison","text":"<p>pytextrank times include spaCy tokenization (loading the pipeline, running the tokenizer, POS tagger, lemmatizer, etc.). For a fair comparison with pre-tokenized input, use rapid_textrank's JSON API, which accepts tokens that have already been processed by spaCy or another NLP pipeline.</p> <p>When comparing end-to-end latency (raw text in, keywords out), the rapid_textrank native classes include a built-in tokenizer that is much lighter than spaCy's full pipeline. This accounts for a significant portion of the observed speedup.</p> <p>Interactive Notebook</p> <p>Run benchmarks interactively in the Benchmarks Notebook.</p>"},{"location":"performance/comparison/","title":"Comparison with Alternatives","text":"<p>This page compares rapid_textrank with other popular keyword and keyphrase extraction libraries to help you choose the right tool for your use case.</p>"},{"location":"performance/comparison/#feature-comparison","title":"Feature Comparison","text":"Feature rapid_textrank pytextrank YAKE KeyBERT pke Rake-NLTK Speed Very fast (Rust) Moderate (Python) Fast (Python) Slow (transformer) Moderate Fast Algorithm variants 7 3 (TextRank, BiasedTR, TopicRank) 1 (YAKE) 1 (BERT-based) 5+ (TextRank, TFIDF, etc.) 1 (RAKE) Language support 18 languages Via spaCy 25+ Any (via embeddings) Via spaCy English-focused spaCy dependency Optional Required None None Required None Pre-tokenized input Yes (JSON API) Via spaCy No No Via spaCy No API style Classes + JSON spaCy pipeline Function Class Classes Class"},{"location":"performance/comparison/#when-to-use-each-tool","title":"When to Use Each Tool","text":""},{"location":"performance/comparison/#rapid_textrank","title":"rapid_textrank","text":"<p>Best for speed-critical pipelines, batch processing, and multi-variant exploration.</p> <p>Choose rapid_textrank when latency matters -- real-time APIs, high-throughput batch jobs, or interactive applications where users expect instant results. The seven algorithm variants (BaseTextRank, PositionRank, BiasedTextRank, TopicRank, SingleRank, TopicalPageRank, MultipartiteRank) let you experiment with different ranking strategies without switching libraries. The JSON API is ideal for pipelines that already tokenize with spaCy or another NLP tool.</p>"},{"location":"performance/comparison/#pytextrank","title":"pytextrank","text":"<p>Best when you are already in a spaCy pipeline and need spaCy's NER/dependency parsing.</p> <p>If your application already loads a spaCy model for named entity recognition, dependency parsing, or other linguistic features, pytextrank integrates as a native pipeline component. It leverages spaCy's tokenization and POS tagging directly. The tradeoff is speed -- pytextrank is pure Python and includes the full spaCy pipeline overhead.</p>"},{"location":"performance/comparison/#yake","title":"YAKE","text":"<p>Best for lightweight extraction without graph computation.</p> <p>YAKE (Yet Another Keyword Extractor) uses statistical features (word frequency, position, co-occurrence) without building a graph. It is fast, unsupervised, and language-independent. Choose YAKE when you need a simple, dependency-free solution and do not need graph-based ranking or multiple algorithm variants.</p>"},{"location":"performance/comparison/#keybert","title":"KeyBERT","text":"<p>Best when semantic understanding matters more than speed.</p> <p>KeyBERT uses transformer embeddings (BERT, RoBERTa, etc.) to find keywords that are semantically similar to the document. It captures meaning beyond surface-level co-occurrence, making it strong for documents where important concepts are expressed with varied vocabulary. The tradeoff is speed -- transformer inference is orders of magnitude slower than graph-based methods.</p>"},{"location":"performance/comparison/#pke","title":"pke","text":"<p>Best for academic research and access to many classical keyphrase methods.</p> <p>pke (Python Keyphrase Extraction) implements a wide range of keyphrase extraction algorithms (TextRank, SingleRank, TopicRank, TFIDF, KP-Miner, and more) in a unified framework. It is designed for reproducible research and benchmarking across methods. Choose pke when you need to compare many algorithms or need methods not available elsewhere.</p>"},{"location":"performance/comparison/#rake-nltk","title":"Rake-NLTK","text":"<p>Best for a quick RAKE implementation with minimal dependencies.</p> <p>Rake-NLTK implements the Rapid Automatic Keyword Extraction (RAKE) algorithm, which uses word co-occurrence within phrases delimited by stopwords and punctuation. It is simple, fast, and easy to understand. Choose it for quick prototyping or when you specifically want the RAKE algorithm.</p>"},{"location":"performance/comparison/#summary","title":"Summary","text":"<p>If speed is your primary concern and you want flexibility across algorithm variants, rapid_textrank is the strongest choice. If you need semantic understanding, look at KeyBERT. If you need minimal dependencies and a simple statistical approach, consider YAKE or Rake-NLTK. If you are building on spaCy, pytextrank or pke integrate naturally into that ecosystem.</p>"},{"location":"performance/why-rust-is-fast/","title":"Why Rust is Fast","text":"<p>The performance advantage of rapid_textrank comes from several factors working together. Each optimization targets a specific bottleneck in the TextRank pipeline.</p>"},{"location":"performance/why-rust-is-fast/#1-csr-graph-format","title":"1. CSR Graph Format","text":"<p>The co-occurrence graph uses Compressed Sparse Row (CSR) format, which stores all edge data in contiguous arrays rather than pointer-chasing through linked structures.</p> <p>Why it matters: PageRank iterates over every node's neighbors many times (typically 20-100 iterations until convergence). CSR format keeps each node's neighbors in adjacent memory locations, which means the CPU cache can prefetch the next edge while processing the current one. This cache-friendly access pattern avoids the random memory access penalties that adjacency-list or dictionary-of-dictionaries representations suffer from, especially as graph size grows.</p>"},{"location":"performance/why-rust-is-fast/#2-string-interning","title":"2. String Interning","text":"<p>Repeated words share a single allocation via <code>StringPool</code>, reducing memory usage 10-100x for typical documents.</p> <p>Why it matters: Natural language text is highly repetitive. A 1,000-word document might contain only 200-300 unique words, but a naive implementation allocates a new string for every occurrence. String interning maps each unique word to a small integer ID, so the graph, co-occurrence counts, and PageRank vectors all operate on compact integer keys rather than heap-allocated strings. This reduces both memory pressure and the cost of hash lookups and equality comparisons throughout the pipeline.</p>"},{"location":"performance/why-rust-is-fast/#3-parallel-processing","title":"3. Parallel Processing","text":"<p>Rayon provides data parallelism for internal graph construction without explicit thread management.</p> <p>Why it matters: Building the co-occurrence graph involves scanning every sliding window in the document and updating edge weights. Rayon's work-stealing scheduler automatically distributes this work across available CPU cores. For large documents or batch processing, this parallelism translates directly into wall-clock speedups proportional to core count. The programmer writes sequential-looking iterators, and Rayon handles the threading, synchronization, and load balancing.</p>"},{"location":"performance/why-rust-is-fast/#4-link-time-optimization-lto","title":"4. Link-Time Optimization (LTO)","text":"<p>Release builds use full LTO with a single codegen unit for maximum inlining.</p> <p>Why it matters: By default, the Rust compiler splits code into multiple codegen units for faster compilation, but this prevents cross-unit inlining. Full LTO merges all code into a single compilation unit, allowing the optimizer to inline small functions across module boundaries, eliminate dead code, and perform whole-program optimizations. For rapid_textrank, this means hot loops in PageRank iteration, graph construction, and string interning can be fully inlined and optimized as a single block of machine code.</p>"},{"location":"performance/why-rust-is-fast/#5-rust-core","title":"5. Rust Core","text":"<p>Most computation happens in compiled Rust code, minimizing Python-level overhead.</p> <p>Why it matters: Python's interpreter adds overhead for every operation -- attribute lookups, dynamic dispatch, reference counting, and the Global Interpreter Lock (GIL). By implementing the core algorithm in Rust and exposing only the entry/exit points to Python via PyO3, rapid_textrank avoids this overhead for the performance-critical inner loops. The Python layer handles configuration and result formatting, while the Rust layer handles graph construction, PageRank iteration, and phrase extraction -- the three most compute-intensive steps.</p>"},{"location":"performance/why-rust-is-fast/#6-fxhash","title":"6. FxHash","text":"<p>Fast non-cryptographic hashing for internal hash maps.</p> <p>Why it matters: The standard library's <code>HashMap</code> uses SipHash, which is designed to resist hash-flooding attacks. This security property is unnecessary for internal data structures where keys are controlled (word IDs, node indices). FxHash is a much simpler hash function that processes 4-8 bytes per cycle, making hash map lookups and insertions significantly faster. Since rapid_textrank's inner loops involve frequent hash map operations (co-occurrence counting, node lookups, score aggregation), switching to FxHash provides a measurable speedup.</p>"},{"location":"performance/why-rust-is-fast/#combined-effect","title":"Combined Effect","text":"<p>These optimizations are not independent -- they compound. CSR format makes PageRank iteration cache-friendly, string interning makes the CSR arrays compact, FxHash makes the interning lookups fast, LTO lets the compiler optimize across all these layers, Rayon parallelizes the graph construction, and the Rust core avoids Python overhead for all of it. The result is an implementation that is typically 10-100x faster than equivalent pure Python code.</p>"},{"location":"reference/citation/","title":"Citation","text":"<p>If you use rapid_textrank in research, please cite the relevant papers for the algorithm variants you use.</p>"},{"location":"reference/citation/#textrank","title":"TextRank","text":"<p>TextRank: Bringing Order into Texts (Mihalcea &amp; Tarau, 2004)</p> <p>The foundational graph-based ranking algorithm for keyword extraction, inspired by PageRank. Used by <code>BaseTextRank</code>.</p> <pre><code>@inproceedings{mihalcea-tarau-2004-textrank,\n    title = \"{T}ext{R}ank: Bringing Order into Text\",\n    author = \"Mihalcea, Rada and Tarau, Paul\",\n    booktitle = \"Proceedings of EMNLP 2004\",\n    year = \"2004\",\n    publisher = \"Association for Computational Linguistics\",\n}\n</code></pre>"},{"location":"reference/citation/#positionrank","title":"PositionRank","text":"<p>PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents (Florescu &amp; Caragea, 2017)</p> <p>Extends TextRank by biasing the random walk toward words that appear earlier in the document. Used by <code>PositionRank</code>.</p> <pre><code>@inproceedings{florescu-caragea-2017-positionrank,\n    title = \"{P}osition{R}ank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents\",\n    author = \"Florescu, Corina and Caragea, Cornelia\",\n    booktitle = \"Proceedings of ACL 2017\",\n    year = \"2017\",\n}\n</code></pre>"},{"location":"reference/citation/#singlerank","title":"SingleRank","text":"<p>Single Document Keyphrase Extraction Using Neighborhood Knowledge (Wan &amp; Xiao, 2008)</p> <p>Extends TextRank with weighted edges based on co-occurrence frequency and cross-sentence windowing. Used by <code>SingleRank</code>.</p> <pre><code>@inproceedings{wan-xiao-2008-singlerank,\n    title = \"Single Document Keyphrase Extraction Using Neighborhood Knowledge\",\n    author = \"Wan, Xiaojun and Xiao, Jianguo\",\n    booktitle = \"Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI 2008)\",\n    year = \"2008\",\n    pages = \"855--860\",\n}\n</code></pre>"},{"location":"reference/citation/#topicrank","title":"TopicRank","text":"<p>TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction (Bougouin et al., 2013)</p> <p>Clusters candidate phrases into topics using hierarchical agglomerative clustering, then ranks topics as a whole. Used by <code>TopicRank</code>.</p> <pre><code>@inproceedings{bougouin-boudin-daille-2013-topicrank,\n    title = \"{T}opic{R}ank: Graph-Based Topic Ranking for Keyphrase Extraction\",\n    author = \"Bougouin, Adrien and Boudin, Florian and Daille, B{\\'e}atrice\",\n    booktitle = \"Proceedings of the Sixth International Joint Conference on Natural Language Processing\",\n    year = \"2013\",\n    pages = \"543--551\",\n    publisher = \"Asian Federation of Natural Language Processing\",\n}\n</code></pre>"},{"location":"reference/citation/#multipartiterank","title":"MultipartiteRank","text":"<p>Unsupervised Keyphrase Extraction with Multipartite Graphs (Boudin, 2018)</p> <p>Extends TopicRank by keeping individual candidates as graph nodes instead of collapsing topics, removing intra-topic edges to form a k-partite graph. Used by <code>MultipartiteRank</code>.</p> <pre><code>@inproceedings{boudin-2018-multipartiterank,\n    title = \"Unsupervised Keyphrase Extraction with Multipartite Graphs\",\n    author = \"Boudin, Florian\",\n    booktitle = \"Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2018)\",\n    year = \"2018\",\n    pages = \"667--672\",\n}\n</code></pre>"},{"location":"reference/citation/#topical-pagerank","title":"Topical PageRank","text":"<p>Topical Word Importance for Fast Keyphrase Extraction (Sterckx et al., 2015)</p> <p>Biases PageRank toward topically important words using a personalization vector derived from topic models. Used by <code>TopicalPageRank</code>.</p> <pre><code>@inproceedings{sterckx-etal-2015-topical,\n    title = \"Topical Word Importance for Fast Keyphrase Extraction\",\n    author = \"Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris\",\n    booktitle = \"Proceedings of the 24th International Conference on World Wide Web (Companion Volume)\",\n    year = \"2015\",\n    pages = \"121--122\",\n}\n</code></pre>"},{"location":"reference/citation/#biasedtextrank","title":"BiasedTextRank","text":"<p>BiasedTextRank: Unsupervised Graph-Based Content Extraction (Kazemi et al., 2020)</p> <p>Steers extraction toward specific topics using focus terms and a bias weight in the PageRank personalization vector. Used by <code>BiasedTextRank</code>.</p> <pre><code>@inproceedings{kazemi-etal-2020-biasedtextrank,\n    title = \"Biased {T}ext{R}ank: Unsupervised Graph-Based Content Extraction\",\n    author = \"Kazemi, Ashkan and P{\\'e}rez-Rosas, Ver{\\'o}nica and Mihalcea, Rada\",\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020)\",\n    year = \"2020\",\n}\n</code></pre>"},{"location":"reference/faq/","title":"FAQ","text":"<p>Frequently asked questions about rapid_textrank, covering common gotchas and configuration choices.</p> <p>Q: Why is TopicRank JSON-only?</p> <p>A: TopicRank requires pre-tokenized input with POS tags and lemmas, which is best provided by a full NLP pipeline like spaCy. The JSON interface accepts this pre-tokenized data directly. The other variants include a built-in tokenizer that handles tokenization, POS tagging, and lemmatization internally, so they can work with raw text via the native Python classes.</p> <p>Q: Is the Python GIL held during extraction?</p> <p>A: Yes, the GIL is currently held during extraction. For CPU-bound batch workloads, use <code>extract_batch_from_json()</code> to process multiple documents in a single Rust call, which avoids repeated Python-to-Rust boundary crossings. For true parallelism, use Python's <code>multiprocessing</code> module to run extractions across multiple processes.</p> <p>Q: How do stopwords work?</p> <p>A: The <code>stopwords</code> parameter in <code>TextRankConfig</code> adds to the built-in stopword list for the specified language -- it does not replace it. Use <code>get_stopwords(\"en\")</code> to see the built-in list for a given language. If you need to remove a built-in stopword, there is currently no mechanism for that; the parameter is additive only.</p> <p>Q: How are emojis handled?</p> <p>A: Emojis are ignored by the built-in tokenizer. They will not appear as keywords or affect the co-occurrence graph. If you need emoji-aware processing, tokenize with spaCy (or another NLP tool that handles emojis) and use the JSON interface to pass the pre-tokenized data to rapid_textrank.</p> <p>Q: How is this different from pytextrank?</p> <p>A: rapid_textrank is a Rust implementation with Python bindings, while pytextrank is pure Python built on spaCy. rapid_textrank is 10-100x faster and offers a standalone API (no spaCy required for most variants), but pytextrank integrates more deeply into spaCy pipelines. If you are already using spaCy for NER, dependency parsing, or other linguistic features, pytextrank fits naturally into that workflow. If speed is your priority or you do not need spaCy, rapid_textrank is the better choice.</p> <p>Q: How do I tune for short vs long documents?</p> <p>A: For short documents (tweets, titles): use a smaller <code>window_size</code> (2), and consider increasing <code>max_phrase_length</code> to capture the few meaningful phrases. For long documents: use <code>SingleRank</code> (cross-sentence windowing improves recall) or <code>MultipartiteRank</code> (topic clustering promotes diversity). Consider adjusting <code>top_n</code> relative to document length -- a 50-word tweet might only have 3-5 meaningful keyphrases, while a 5,000-word article might justify 20-30.</p> <p>Q: What does <code>use_pos_in_nodes</code> do?</p> <p>A: When <code>True</code> (the default), graph nodes are keyed as <code>\"lemma|POS\"</code> (e.g., <code>\"learning|NOUN\"</code> vs <code>\"learning|VERB\"</code>). This prevents different word senses from sharing a node, which improves precision when the same surface form is used as both a noun and a verb. Set to <code>False</code> to collapse all POS variants of the same lemma into one node, which can improve recall at the cost of conflating different senses.</p> <p>Q: What does <code>phrase_grouping</code> do?</p> <p>A: Controls how phrases are grouped for deduplication. <code>\"scrubbed_text\"</code> (the default) groups by lowercase surface form, so \"Machine Learning\" and \"machine learning\" merge into one entry. <code>\"lemma\"</code> groups by lemmatized form, merging \"machine learning\" and \"machine learns\" into one entry. Use <code>\"lemma\"</code> when you want canonical forms (e.g., for spreadsheets or databases); use <code>\"scrubbed_text\"</code> when you want output that reads naturally.</p>"},{"location":"reference/license/","title":"License","text":"<p>rapid_textrank is released under the MIT License.</p> <pre><code>MIT License\n\nCopyright (c) 2024 TextRanker Contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"reference/release-notes/","title":"Release Notes","text":""},{"location":"reference/release-notes/#v014","title":"v0.1.4","text":""},{"location":"reference/release-notes/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed missing <code>MultipartiteRank</code> Python export -- the class was registered in the Rust PyO3 module but not re-exported from <code>python/rapid_textrank/__init__.py</code>, causing <code>ImportError: cannot import name 'MultipartiteRank'</code> when installing from PyPI.</li> </ul>"},{"location":"reference/release-notes/#v013","title":"v0.1.3","text":""},{"location":"reference/release-notes/#new-algorithm-variants","title":"New Algorithm Variants","text":""},{"location":"reference/release-notes/#singlerank","title":"SingleRank","text":"<ul> <li>New <code>SingleRank</code> variant with weighted edges based on co-occurrence frequency and cross-sentence windowing -- words in adjacent sentences can co-occur within the same sliding window, unlike classic TextRank which treats each sentence independently.</li> <li>Full Python bindings: native class, JSON dispatch, and spaCy pipeline component.</li> <li>Unit tests, integration tests, and documentation.</li> </ul>"},{"location":"reference/release-notes/#topicalpagerank","title":"TopicalPageRank","text":"<ul> <li>New <code>TopicalPageRank</code> variant that biases PageRank toward user-supplied topic weights, enabling domain-focused keyword extraction via a personalization vector.</li> <li>Includes <code>PersonalizedPageRank</code> engine in <code>src/pagerank/personalized.rs</code> with automatic normalization of the personalization vector.</li> <li>7 unit tests and an integration pipeline test.</li> <li>Python <code>topic_weights_from_lda</code> helper (<code>python/rapid_textrank/topic_utils.py</code>) for deriving topic weights from a Gensim LDA model, with an optional Jaccard pre-filter heuristic.</li> <li>Full Python bindings and README examples.</li> </ul>"},{"location":"reference/release-notes/#multipartiterank","title":"MultipartiteRank","text":"<ul> <li>New <code>MultipartiteRank</code> variant that performs Hierarchical Agglomerative Clustering (HAC) on candidate keyphrases using Jaccard distance, then applies a multipartite graph ranking.</li> <li>Shared <code>src/clustering.rs</code> module extracted from the former TopicRank-specific clustering code, now reused by both TopicRank and MultipartiteRank.</li> <li>Disjoint-set fast-path optimization for Jaccard distance computation.</li> <li>Full Python bindings, README documentation, and notebook examples.</li> </ul>"},{"location":"reference/release-notes/#core-engine-improvements","title":"Core Engine Improvements","text":"<ul> <li>Cross-sentence windowing added to <code>GraphBuilder</code> -- configurable window that spans sentence boundaries, improving recall for long documents.</li> <li>Shared clustering module (<code>src/clustering.rs</code>) -- HAC with Jaccard distance, reusable across variants.</li> <li>TopicRank edge weighting aligned with the PKE reference implementation for correctness.</li> </ul>"},{"location":"reference/release-notes/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>Fixed <code>use_pos_in_nodes</code> serde default -- changed from <code>false</code> to <code>true</code>, fixing 2 POS-filtering tests (<code>test_json_include_pos_filtering</code>, <code>test_json_include_pos_multiple_tags</code>).</li> <li>Fixed <code>cargo fmt</code> violations that were failing CI checks across multiple files.</li> </ul>"},{"location":"reference/release-notes/#documentation-examples","title":"Documentation &amp; Examples","text":"<ul> <li>README updated with usage examples for SingleRank, TopicalPageRank, and MultipartiteRank.</li> <li>Notebooks <code>02_algorithm_variants</code> and <code>04_benchmarks</code> updated with examples for all new variants.</li> <li><code>CLAUDE.md</code> and <code>AGENTS.md</code> updated with PyO3 + Python 3.14 build caveats.</li> <li><code>topic_weights_from_lda</code> usage example added to README.</li> </ul>"},{"location":"reference/release-notes/#benchmarks","title":"Benchmarks","text":"<ul> <li>Added SingleRank, TopicalPageRank, and MultipartiteRank to the Criterion benchmark suite.</li> </ul>"},{"location":"reference/release-notes/#stats","title":"Stats","text":"<ul> <li>20 commits since v0.1.2</li> <li>27 files changed, 3,409 insertions, 271 deletions</li> </ul>"},{"location":"reference/release-notes/#v012","title":"v0.1.2","text":""},{"location":"reference/release-notes/#highlights","title":"Highlights","text":"<ul> <li>Added TopicRank support via JSON interface (<code>variant=\"topic_rank\"</code>) with spaCy-token examples.</li> <li>TopicRank behavior aligned more closely with pytextrank.</li> <li>Docs and notebooks updated to include TopicRank usage and comparisons.</li> </ul>"},{"location":"reference/release-notes/#details","title":"Details","text":"<ul> <li>New JSON config fields: <code>topic_similarity_threshold</code>, <code>topic_edge_weight</code>, <code>focus_terms</code>, <code>bias_weight</code>.</li> <li>README updated with TopicRank section + citation.</li> <li>Benchmarks notebook now compares rapid_textrank TopicRank vs pytextrank TopicRank using spaCy tokens.</li> </ul>"},{"location":"reference/release-notes/#v011","title":"v0.1.1","text":""},{"location":"reference/release-notes/#highlights_1","title":"Highlights","text":"<ul> <li>Closer alignment with pytextrank defaults: window size now 3, POS defaults include verbs, and scrubbed-text grouping available by default.</li> <li>Improved phrase quality: stopword-aware chunking reduces noisy phrases.</li> <li>Config parity across APIs: new options surfaced in Python, JSON, and spaCy component interfaces.</li> </ul>"},{"location":"reference/release-notes/#new","title":"New","text":"<ul> <li><code>use_pos_in_nodes</code> to treat nodes as <code>lemma|POS</code>.</li> <li><code>phrase_grouping</code> with <code>lemma</code> or <code>scrubbed_text</code>.</li> <li><code>get_stopwords(language)</code> helper to inspect built-in stopwords.</li> <li>JSON config now supports <code>language</code>, <code>use_pos_in_nodes</code>, <code>phrase_grouping</code>, and additional stopwords (extends built-ins).</li> <li>spaCy component supports <code>include_pos</code>, <code>use_pos_in_nodes</code>, <code>phrase_grouping</code>, <code>language</code>, and <code>stopwords</code>.</li> </ul>"},{"location":"reference/release-notes/#changed-defaults","title":"Changed Defaults","text":"<ul> <li><code>window_size</code>: 4 to 3</li> <li><code>include_pos</code>: NOUN + ADJ + PROPN to NOUN + ADJ + PROPN + VERB</li> <li><code>use_pos_in_nodes</code>: false to true</li> <li><code>phrase_grouping</code>: lemma to scrubbed_text</li> </ul>"},{"location":"reference/release-notes/#notebook-updates","title":"Notebook Updates","text":"<ul> <li>Benchmarks now compare rapid_textrank vs pytextrank with and without spaCy tokens.</li> <li>Config blocks simplified to use new defaults.</li> <li>Stopword list printing added to algorithm explanation notebook.</li> </ul>"},{"location":"reference/release-notes/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>Stopwords now act as chunk boundaries, preventing phrases like \"of NLP is to\".</li> <li>Heuristic POS tagging recognizes common function words to reduce false content tokens.</li> </ul>"},{"location":"reference/release-notes/#compatibility-notes","title":"Compatibility Notes","text":"<p>If you relied on old defaults, set them explicitly to preserve behavior: - <code>window_size=4</code> - <code>include_pos=[\"NOUN\",\"ADJ\",\"PROPN\"]</code> - <code>use_pos_in_nodes=False</code> - <code>phrase_grouping=\"lemma\"</code></p>"},{"location":"reference/release-notes/#v010","title":"v0.1.0","text":"<p>Release Date: February 5, 2026</p> <p>This is the initial public release of <code>rapid_textrank</code>, a high-performance TextRank implementation in Rust with Python bindings.</p>"},{"location":"reference/release-notes/#highlights_2","title":"Highlights","text":"<ul> <li>10-100x faster than pure Python TextRank implementations (depending on document size)</li> <li>Three algorithm variants: BaseTextRank, PositionRank, and BiasedTextRank</li> <li>18 languages supported for stopword filtering</li> <li>Dual API: Native Python classes + JSON interface for batch processing</li> <li>spaCy integration: Drop-in pipeline component</li> </ul>"},{"location":"reference/release-notes/#features","title":"Features","text":""},{"location":"reference/release-notes/#algorithm-variants","title":"Algorithm Variants","text":"Variant Use Case <code>BaseTextRank</code> General keyword extraction <code>PositionRank</code> Documents where key terms appear early (papers, news) <code>BiasedTextRank</code> Topic-focused extraction with customizable focus terms"},{"location":"reference/release-notes/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>CSR (Compressed Sparse Row) graph format for cache-friendly PageRank iteration</li> <li>String interning via <code>StringPool</code> reducing memory 10-100x for typical documents</li> <li>Parallel graph construction with Rayon</li> <li>Link-time optimization (LTO) with single codegen unit</li> <li>FxHash for fast internal hash maps</li> </ul>"},{"location":"reference/release-notes/#supported-platforms","title":"Supported Platforms","text":"<ul> <li>Python 3.9, 3.10, 3.11, 3.12</li> <li>Linux (manylinux)</li> <li>macOS (x86_64, arm64)</li> <li>Windows (x86_64)</li> </ul>"},{"location":"reference/release-notes/#supported-languages","title":"Supported Languages","text":"<p><code>en</code>, <code>de</code>, <code>fr</code>, <code>es</code>, <code>it</code>, <code>pt</code>, <code>nl</code>, <code>ru</code>, <code>sv</code>, <code>no</code>, <code>da</code>, <code>fi</code>, <code>hu</code>, <code>tr</code>, <code>pl</code>, <code>ar</code>, <code>zh</code>, <code>ja</code></p>"}]}