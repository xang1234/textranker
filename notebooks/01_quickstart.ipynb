{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# rapid_textrank Quick Start\n",
    "\n",
    "This notebook demonstrates the basics of `rapid_textrank`, a high-performance TextRank implementation in Rust with Python bindings.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to extract keywords from text\n",
    "- Understanding `Phrase` objects and their attributes\n",
    "- Configuring the algorithm with `TextRankConfig`\n",
    "- Multi-language support\n",
    "- Optional spaCy integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install `rapid_textrank` from PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q rapid_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-header",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "The simplest way to extract keywords is with the `extract_keywords()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "basic-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: 0.2188\n",
      "artificial intelligence that enables: 0.2063\n",
      "and improve from experience: 0.1429\n",
      "networks with many layers: 0.1210\n",
      "is a subset of: 0.0742\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import extract_keywords\n",
    "\n",
    "text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables\n",
    "systems to learn and improve from experience. Deep learning, a type of\n",
    "machine learning, uses neural networks with many layers.\n",
    "\"\"\"\n",
    "\n",
    "# Extract the top 5 keywords\n",
    "keywords = extract_keywords(text, top_n=5, language=\"en\")\n",
    "\n",
    "for phrase in keywords:\n",
    "    print(f\"{phrase.text}: {phrase.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phrase-header",
   "metadata": {},
   "source": [
    "## Understanding Results: The `Phrase` Object\n",
    "\n",
    "Each keyword is returned as a `Phrase` object with several useful attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "phrase-attributes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase attributes:\n",
      "  text:  'Machine'                      # The original phrase text\n",
      "  lemma: 'machine'                      # Lemmatized (base) form\n",
      "  score: 0.2188                         # TextRank importance score\n",
      "  rank:  1                              # 1-indexed ranking position\n",
      "  count: 2                              # Number of occurrences in text\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the first phrase in detail\n",
    "phrase = keywords[0]\n",
    "\n",
    "print(\"Phrase attributes:\")\n",
    "print(f\"  text:  {phrase.text!r:30} # The original phrase text\")\n",
    "print(f\"  lemma: {phrase.lemma!r:30} # Lemmatized (base) form\")\n",
    "print(f\"  score: {phrase.score:<30.4f} # TextRank importance score\")\n",
    "print(f\"  rank:  {phrase.rank:<30} # 1-indexed ranking position\")\n",
    "print(f\"  count: {phrase.count:<30} # Number of occurrences in text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "phrase-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank   Text                                Score      Count \n",
      "------------------------------------------------------------\n",
      "1      Machine                             0.2188     2     \n",
      "2      artificial intelligence that enables 0.2063     1     \n",
      "3      and improve from experience         0.1429     1     \n",
      "4      networks with many layers           0.1210     1     \n",
      "5      is a subset of                      0.0742     1     \n"
     ]
    }
   ],
   "source": [
    "# View all keywords as a table\n",
    "print(f\"{'Rank':<6} {'Text':<35} {'Score':<10} {'Count':<6}\")\n",
    "print(\"-\" * 60)\n",
    "for p in keywords:\n",
    "    print(f\"{p.rank:<6} {p.text:<35} {p.score:<10.4f} {p.count:<6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration with `TextRankConfig`\n",
    "\n",
    "For more control over the algorithm, use `TextRankConfig` with the class-based API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "config-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: True\n",
      "Iterations: 21\n",
      "\n",
      "Top phrases:\n",
      "  1. Machine: 0.2188\n",
      "  2. artificial intelligence that enables: 0.2063\n",
      "  3. and improve from experience: 0.1429\n",
      "  4. networks with many layers: 0.1210\n",
      "  5. is a subset of: 0.0742\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import TextRankConfig, BaseTextRank\n",
    "\n",
    "# Create a custom configuration (only overriding a few defaults)\n",
    "config = TextRankConfig(\n",
    "    top_n=10,\n",
    "    score_aggregation=\"sum\",\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "# Create an extractor with the config\n",
    "extractor = BaseTextRank(config=config)\n",
    "\n",
    "# Extract keywords\n",
    "result = extractor.extract_keywords(text)\n",
    "\n",
    "print(f\"Converged: {result.converged}\")\n",
    "print(f\"Iterations: {result.iterations}\")\n",
    "print(f\"\n",
    "Top phrases:\")\n",
    "for p in result.phrases[:5]:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-params",
   "metadata": {},
   "source": [
    "### Key Configuration Parameters\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `damping` | 0.85 | PageRank damping factor. Higher = more weight to graph structure |\n",
    "| `window_size` | 4 | Co-occurrence window. Larger = more connections between distant words |\n",
    "| `min_phrase_length` | 1 | Allow single words as phrases |\n",
    "| `max_phrase_length` | 4 | Maximum words in a keyphrase |\n",
    "| `score_aggregation` | \"sum\" | How to combine word scores: sum, mean, max, or rms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aggregation-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Aggregation Comparison (top 3 phrases):\n",
      "============================================================\n",
      "\n",
      "SUM:\n",
      "  Machine: 0.2188\n",
      "  artificial intelligence that enables: 0.2063\n",
      "  and improve from experience: 0.1429\n",
      "\n",
      "MEAN:\n",
      "  Machine: 0.1094\n",
      "  is a subset of: 0.0742\n",
      "  and improve from experience: 0.0714\n",
      "\n",
      "MAX:\n",
      "  Machine: 0.1094\n",
      "  artificial intelligence that enables: 0.0742\n",
      "  is a subset of: 0.0742\n",
      "\n",
      "RMS:\n",
      "  Machine: 0.1094\n",
      "  is a subset of: 0.0742\n",
      "  and improve from experience: 0.0714\n"
     ]
    }
   ],
   "source": [
    "# Compare different score aggregation methods\n",
    "aggregation_methods = [\"sum\", \"mean\", \"max\", \"rms\"]\n",
    "\n",
    "print(\"Score Aggregation Comparison (top 3 phrases):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for method in aggregation_methods:\n",
    "    config = TextRankConfig(score_aggregation=method, top_n=3, language=\"en\")\n",
    "    extractor = BaseTextRank(config=config)\n",
    "    result = extractor.extract_keywords(text)\n",
    "    \n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    for p in result.phrases:\n",
    "        print(f\"  {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multilang-header",
   "metadata": {},
   "source": [
    "## Multi-Language Support\n",
    "\n",
    "`rapid_textrank` supports stopword filtering for 18 languages:\n",
    "\n",
    "| Code | Language | Code | Language | Code | Language |\n",
    "|------|----------|------|----------|------|----------|\n",
    "| `en` | English | `de` | German | `fr` | French |\n",
    "| `es` | Spanish | `it` | Italian | `pt` | Portuguese |\n",
    "| `nl` | Dutch | `ru` | Russian | `sv` | Swedish |\n",
    "| `no` | Norwegian | `da` | Danish | `fi` | Finnish |\n",
    "| `hu` | Hungarian | `tr` | Turkish | `pl` | Polish |\n",
    "| `ar` | Arabic | `zh` | Chinese | `ja` | Japanese |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "german-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German keywords:\n",
      "  1. Teilgebiet der k\u00fcnstlichen Intelligenz: 0.1860\n",
      "  2. aus Erfahrung zu lernen: 0.1768\n",
      "  3. Netze mit vielen Schichten: 0.1184\n"
     ]
    }
   ],
   "source": [
    "# German example\n",
    "german_text = \"\"\"\n",
    "Maschinelles Lernen ist ein Teilgebiet der k\u00fcnstlichen Intelligenz.\n",
    "Deep Learning verwendet neuronale Netze mit vielen Schichten.\n",
    "Diese Technologie erm\u00f6glicht es Computern, aus Erfahrung zu lernen.\n",
    "\"\"\"\n",
    "\n",
    "keywords_de = extract_keywords(german_text, top_n=5, language=\"de\")\n",
    "\n",
    "print(\"German keywords:\")\n",
    "for p in keywords_de:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "french-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French keywords:\n",
      "  1. branche de l'intelligence artificielle: 0.1906\n",
      "  2. l'analyse de donn\u00e9es complexes: 0.1764\n",
      "  3. de nombreux secteurs industriels: 0.1250\n"
     ]
    }
   ],
   "source": [
    "# French example\n",
    "french_text = \"\"\"\n",
    "L'apprentissage automatique est une branche de l'intelligence artificielle.\n",
    "Les r\u00e9seaux de neurones profonds permettent l'analyse de donn\u00e9es complexes.\n",
    "Ces technologies transforment de nombreux secteurs industriels.\n",
    "\"\"\"\n",
    "\n",
    "keywords_fr = extract_keywords(french_text, top_n=5, language=\"fr\")\n",
    "\n",
    "print(\"French keywords:\")\n",
    "for p in keywords_fr:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spacy-header",
   "metadata": {},
   "source": [
    "## Optional: spaCy Integration\n",
    "\n",
    "If you use spaCy, `rapid_textrank` can integrate as a pipeline component. This lets you use spaCy's superior tokenization with rapid_textrank's fast extraction.\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spacy-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to install spaCy dependencies\n",
    "%pip install -q spacy\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spacy-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords via spaCy pipeline:\n",
      "  1. Machine learning: 0.6038\n",
      "  2. Deep learning: 0.2218\n",
      "  3. artificial intelligence: 0.1752\n",
      "  4. neural networks: 0.1435\n",
      "  5. subset: 0.0786\n"
     ]
    }
   ],
   "source": [
    "# spaCy integration example\n",
    "try:\n",
    "    import spacy\n",
    "    import rapid_textrank.spacy_component  # Registers the pipeline factory\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"rapid_textrank\")\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    print(\"Keywords via spaCy pipeline:\")\n",
    "    for phrase in doc._.phrases[:5]:\n",
    "        print(f\"  {phrase.rank}. {phrase.text}: {phrase.score:.4f}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"spaCy not installed. This is optional - rapid_textrank works great on its own!\")\n",
    "except OSError:\n",
    "    import sys\n",
    "    print(f\"spaCy model not found. Run: {sys.executable} -m spacy download en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you know the basics, explore more in the other notebooks:\n",
    "\n",
    "1. **[02_algorithm_variants.ipynb](02_algorithm_variants.ipynb)** - Deep dive into BaseTextRank, PositionRank, and BiasedTextRank\n",
    "2. **[03_explain_algorithm.ipynb](03_explain_algorithm.ipynb)** - Visual explanation of how TextRank works\n",
    "3. **[04_benchmarks.ipynb](04_benchmarks.ipynb)** - Performance comparison with pytextrank\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/xang1234/rapid-textrank)\n",
    "- [Original TextRank Paper](https://aclanthology.org/W04-3252/) (Mihalcea & Tarau, 2004)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}