{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Algorithm Variants in rapid_textrank\n",
    "\n",
    "This notebook explores the three TextRank algorithm variants available in `rapid_textrank`:\n",
    "\n",
    "| Variant | Best For | Key Feature |\n",
    "|---------|----------|-------------|\n",
    "| **BaseTextRank** | General text | Standard TextRank implementation |\n",
    "| **PositionRank** | Academic papers, news | Favors words appearing early |\n",
    "| **BiasedTextRank** | Topic-focused extraction | Biases toward specified focus terms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "%pip install -q rapid_textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapid_textrank import BaseTextRank, PositionRank, BiasedTextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basetextrank-header",
   "metadata": {},
   "source": [
    "## 1. BaseTextRank\n",
    "\n",
    "The standard TextRank algorithm, based on [Mihalcea & Tarau (2004)](https://aclanthology.org/W04-3252/).\n",
    "\n",
    "**How it works:**\n",
    "1. Builds a co-occurrence graph from content words\n",
    "2. Runs PageRank to score word importance\n",
    "3. Extracts phrases by grouping high-scoring words\n",
    "\n",
    "**Best for:** General-purpose keyword extraction where word position doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basetextrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextRank Results:\n",
      "==================================================\n",
      " 1. Natural language                    0.1966\n",
      " 2. on many NLP tasks                   0.1388\n",
      " 3. human language in a                 0.1285\n",
      " 4. NLP in recent years                 0.1105\n",
      " 5. of NLP is to                        0.1105\n",
      " 6. computers and humans through        0.1099\n",
      " 7. enable computers to                 0.0820\n",
      " 8. summarization and question          0.0741\n",
      " 9. artificial intelligence             0.0586\n",
      "10. is a field of                       0.0396\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence\n",
    "that focuses on the interaction between computers and humans through\n",
    "natural language. The ultimate goal of NLP is to enable computers to\n",
    "understand, interpret, and generate human language in a valuable way.\n",
    "\n",
    "Machine learning approaches have transformed NLP in recent years.\n",
    "Deep learning models, particularly transformers, have achieved\n",
    "state-of-the-art results on many NLP tasks including translation,\n",
    "summarization, and question answering.\n",
    "\"\"\"\n",
    "\n",
    "base = BaseTextRank(top_n=10, language=\"en\")\n",
    "result = base.extract_keywords(text)\n",
    "\n",
    "print(\"BaseTextRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positionrank-header",
   "metadata": {},
   "source": [
    "## 2. PositionRank\n",
    "\n",
    "Based on [Florescu & Caragea (2017)](https://aclanthology.org/P17-1102/), PositionRank weights words by their position in the document.\n",
    "\n",
    "**Key insight:** In many documents (papers, news articles, reports), important terms appear early\u2014in titles, abstracts, or introductory paragraphs.\n",
    "\n",
    "**How it differs from BaseTextRank:**\n",
    "- Words appearing early get higher initial importance\n",
    "- Position weight decays as you move through the document\n",
    "- The PageRank algorithm then refines these position-biased scores\n",
    "\n",
    "**Best for:** Academic papers, news articles, structured documents with front-loaded information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "positionrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionRank Results:\n",
      "==================================================\n",
      " 1. quantum error correction that       0.4234\n",
      " 2. fault tolerant quantum computation  0.3016\n",
      " 3. Near Term Quantum Computers         0.2913\n",
      " 4. practical quantum                   0.2144\n",
      " 5. predict and correct errors          0.1872\n",
      " 6. logical error rates                 0.1769\n",
      " 7. Our method leverages machine        0.0688\n",
      " 8. reduces the overhead                0.0566\n",
      " 9. reduction in                        0.0224\n",
      "10. applications                        0.0195\n"
     ]
    }
   ],
   "source": [
    "# Academic abstract where key terms appear in the title/first sentence\n",
    "abstract = \"\"\"\n",
    "Quantum Error Correction in Near-Term Quantum Computers\n",
    "\n",
    "We present a novel approach to quantum error correction that significantly\n",
    "reduces the overhead required for fault-tolerant quantum computation.\n",
    "Our method leverages machine learning to predict and correct errors\n",
    "in real-time. Experimental results on superconducting qubits demonstrate\n",
    "a 50% reduction in logical error rates. These advances bring us closer\n",
    "to practical quantum computing applications.\n",
    "\"\"\"\n",
    "\n",
    "pos = PositionRank(top_n=10, language=\"en\")\n",
    "result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(\"PositionRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "### BaseTextRank vs PositionRank: Side-by-Side\n",
    "\n",
    "Let's compare both algorithms on the same text to see how position weighting affects results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextRank                        PositionRank                       \n",
      "======================================================================\n",
      "quantum error correction that       quantum error correction that      \n",
      "fault tolerant quantum computation  fault tolerant quantum computation \n",
      "Near Term Quantum Computers         Near Term Quantum Computers        \n",
      "predict and correct errors          practical quantum                  \n",
      "logical error rates                 predict and correct errors         \n"
     ]
    }
   ],
   "source": [
    "# Same abstract, both algorithms\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "pos = PositionRank(top_n=5, language=\"en\")\n",
    "\n",
    "base_result = base.extract_keywords(abstract)\n",
    "pos_result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(f\"{'BaseTextRank':<35} {'PositionRank':<35}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(5):\n",
    "    base_phrase = base_result.phrases[i]\n",
    "    pos_phrase = pos_result.phrases[i]\n",
    "    print(f\"{base_phrase.text:<35} {pos_phrase.text:<35}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparison-detailed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In both: {'predict and correct errors', 'quantum error correction that', 'fault tolerant quantum computation', 'Near Term Quantum Computers'}\n",
      "Only in BaseTextRank: {'logical error rates'}\n",
      "Only in PositionRank: {'practical quantum'}\n"
     ]
    }
   ],
   "source": [
    "# Let's see which phrases are unique to each algorithm\n",
    "base_texts = {p.text for p in base_result.phrases}\n",
    "pos_texts = {p.text for p in pos_result.phrases}\n",
    "\n",
    "only_base = base_texts - pos_texts\n",
    "only_pos = pos_texts - base_texts\n",
    "both = base_texts & pos_texts\n",
    "\n",
    "print(f\"In both: {both}\")\n",
    "print(f\"Only in BaseTextRank: {only_base}\")\n",
    "print(f\"Only in PositionRank: {only_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biasedtextrank-header",
   "metadata": {},
   "source": [
    "## 3. BiasedTextRank\n",
    "\n",
    "Based on [Kazemi et al. (2020)](https://aclanthology.org/2020.coling-main.144/), BiasedTextRank steers extraction toward specified focus terms.\n",
    "\n",
    "**Key parameters:**\n",
    "- `focus_terms`: List of terms to bias toward\n",
    "- `bias_weight`: How strongly to favor focus terms (higher = stronger bias)\n",
    "\n",
    "**How it works:**\n",
    "- Focus terms get an initial boost in the PageRank algorithm\n",
    "- Words connected to focus terms inherit some of this bias\n",
    "- The result emphasizes the topic you care about\n",
    "\n",
    "**Best for:** Topic-specific extraction, document filtering, aspect-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "biasedtextrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiasedTextRank (focus: security, privacy):\n",
      "==================================================\n",
      " 1. user experience with security       0.1417\n",
      " 2. users on slow networks              0.1075\n",
      " 3. regulations like GDPR require       0.1056\n",
      " 4. but complicate data freshness       0.1021\n",
      " 5. Security vulnerabilities can expose 0.0986\n",
      " 6. sensitive user information          0.0947\n",
      " 7. careful data                        0.0926\n",
      " 8. user                                0.0693\n",
      " 9. Authentication systems must prevent 0.0667\n",
      "10. transit and at rest                 0.0391\n"
     ]
    }
   ],
   "source": [
    "# Text covering multiple topics\n",
    "tech_article = \"\"\"\n",
    "Modern web applications must balance user experience with security.\n",
    "Performance optimizations are crucial for mobile users on slow networks.\n",
    "Privacy regulations like GDPR require careful data handling and consent.\n",
    "Security vulnerabilities can expose sensitive user information.\n",
    "Caching strategies improve response times but complicate data freshness.\n",
    "Authentication systems must prevent unauthorized access while remaining\n",
    "user-friendly. Encryption protects data both in transit and at rest.\n",
    "\"\"\"\n",
    "\n",
    "# Focus on security/privacy topics\n",
    "biased = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=10,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "result = biased.extract_keywords(tech_article)\n",
    "\n",
    "print(\"BiasedTextRank (focus: security, privacy):\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias-weight-header",
   "metadata": {},
   "source": [
    "### Effect of `bias_weight`\n",
    "\n",
    "The `bias_weight` parameter controls how strongly results favor the focus terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bias-weight-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Weight Comparison (focus: security, privacy)\n",
      "================================================================================\n",
      "\n",
      "bias_weight=1.0:\n",
      "  user experience with security: 0.1227\n",
      "  but complicate data freshness: 0.1102\n",
      "  users on slow networks: 0.1087\n",
      "\n",
      "bias_weight=2.0:\n",
      "  user experience with security: 0.1282\n",
      "  users on slow networks: 0.1084\n",
      "  but complicate data freshness: 0.1079\n",
      "\n",
      "bias_weight=5.0:\n",
      "  user experience with security: 0.1417\n",
      "  users on slow networks: 0.1075\n",
      "  regulations like GDPR require: 0.1056\n",
      "\n",
      "bias_weight=10.0:\n",
      "  user experience with security: 0.1576\n",
      "  regulations like GDPR require: 0.1215\n",
      "  Security vulnerabilities can expose: 0.1159\n"
     ]
    }
   ],
   "source": [
    "# Compare different bias weights\n",
    "weights = [1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "print(\"Bias Weight Comparison (focus: security, privacy)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for weight in weights:\n",
    "    biased = BiasedTextRank(\n",
    "        focus_terms=[\"security\", \"privacy\"],\n",
    "        bias_weight=weight,\n",
    "        top_n=3,\n",
    "        language=\"en\"\n",
    "    )\n",
    "    result = biased.extract_keywords(tech_article)\n",
    "    \n",
    "    print(f\"\\nbias_weight={weight}:\")\n",
    "    for p in result.phrases:\n",
    "        print(f\"  {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bias-vs-unbiased",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased                  Security Focus            Performance Focus        \n",
      "===========================================================================\n",
      "user experience with security user experience with security user experience with security\n",
      "but complicate data freshness users on slow networks    users on slow networks   \n",
      "users on slow networks    regulations like GDPR require but complicate data freshness\n",
      "careful data              but complicate data freshness sensitive user information\n",
      "sensitive user information Security vulnerabilities can expose careful data             \n"
     ]
    }
   ],
   "source": [
    "# Compare biased vs unbiased on the same text\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "biased_security = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "biased_perf = BiasedTextRank(\n",
    "    focus_terms=[\"performance\", \"speed\", \"cache\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "base_result = base.extract_keywords(tech_article)\n",
    "security_result = biased_security.extract_keywords(tech_article)\n",
    "perf_result = biased_perf.extract_keywords(tech_article)\n",
    "\n",
    "print(f\"{'Unbiased':<25} {'Security Focus':<25} {'Performance Focus':<25}\")\n",
    "print(\"=\" * 75)\n",
    "for i in range(5):\n",
    "    print(f\"{base_result.phrases[i].text:<25} \"\n",
    "          f\"{security_result.phrases[i].text:<25} \"\n",
    "          f\"{perf_result.phrases[i].text:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focus-per-call",
   "metadata": {},
   "source": [
    "### Dynamic Focus Terms\n",
    "\n",
    "You can also pass `focus_terms` per-call, which is useful when processing multiple documents with different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "per-call-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Focus: ['security', 'encryption']\n",
      "  - user experience with security\n",
      "  - but complicate data freshness\n",
      "  - users on slow networks\n",
      "\n",
      "Focus: ['performance', 'caching']\n",
      "  - user experience with security\n",
      "  - users on slow networks\n",
      "  - but complicate data freshness\n",
      "\n",
      "Focus: ['user', 'experience']\n",
      "  - user experience with security\n",
      "  - users on slow networks\n",
      "  - sensitive user information\n"
     ]
    }
   ],
   "source": [
    "# Create extractor with default focus\n",
    "extractor = BiasedTextRank(\n",
    "    focus_terms=[\"default\"],  # Placeholder\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Override focus_terms per call\n",
    "topics = [\n",
    "    [\"security\", \"encryption\"],\n",
    "    [\"performance\", \"caching\"],\n",
    "    [\"user\", \"experience\"]\n",
    "]\n",
    "\n",
    "for focus in topics:\n",
    "    result = extractor.extract_keywords(tech_article, focus_terms=focus)\n",
    "    print(f\"\\nFocus: {focus}\")\n",
    "    for p in result.phrases[:3]:\n",
    "        print(f\"  - {p.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-header",
   "metadata": {},
   "source": [
    "## JSON Batch API\n",
    "\n",
    "For processing large volumes of pre-tokenized documents, use the JSON interface:\n",
    "\n",
    "- `extract_from_json()` - Single document\n",
    "- `extract_batch_from_json()` - Multiple documents\n",
    "\n",
    "This is particularly useful when:\n",
    "- You've already tokenized with spaCy or another NLP library\n",
    "- You're processing many documents in batch\n",
    "- You need fine-grained control over tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "json-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single document result:\n",
      "  Machine learning: 0.6667\n",
      "  industries: 0.3333\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rapid_textrank import extract_from_json\n",
    "\n",
    "# Single document with pre-tokenized input\n",
    "doc = {\n",
    "    \"tokens\": [\n",
    "        {\"text\": \"Machine\", \"lemma\": \"machine\", \"pos\": \"NOUN\",\n",
    "         \"start\": 0, \"end\": 7, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "        {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "         \"start\": 8, \"end\": 16, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "        {\"text\": \"is\", \"lemma\": \"be\", \"pos\": \"AUX\",\n",
    "         \"start\": 17, \"end\": 19, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": True},\n",
    "        {\"text\": \"transforming\", \"lemma\": \"transform\", \"pos\": \"VERB\",\n",
    "         \"start\": 20, \"end\": 32, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        {\"text\": \"industries\", \"lemma\": \"industry\", \"pos\": \"NOUN\",\n",
    "         \"start\": 33, \"end\": 43, \"sentence_idx\": 0, \"token_idx\": 4, \"is_stopword\": False},\n",
    "    ],\n",
    "    \"config\": {\n",
    "        \"top_n\": 5,\n",
    "        \"window_size\": 3,\n",
    "        \"damping\": 0.85\n",
    "    }\n",
    "}\n",
    "\n",
    "result_json = extract_from_json(json.dumps(doc))\n",
    "result = json.loads(result_json)\n",
    "\n",
    "print(\"Single document result:\")\n",
    "for phrase in result[\"phrases\"]:\n",
    "    print(f\"  {phrase['text']}: {phrase['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "json-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch results:\n",
      "\n",
      "Document 0:\n",
      "  - Deep learning models (1.0000)\n",
      "\n",
      "Document 1:\n",
      "  - Neural networks (0.6667)\n",
      "  - data (0.3333)\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import extract_batch_from_json\n",
    "\n",
    "# Batch processing multiple documents\n",
    "docs = [\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Deep\", \"lemma\": \"deep\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 4, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "             \"start\": 5, \"end\": 13, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"models\", \"lemma\": \"model\", \"pos\": \"NOUN\",\n",
    "             \"start\": 14, \"end\": 20, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Neural\", \"lemma\": \"neural\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 6, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"networks\", \"lemma\": \"network\", \"pos\": \"NOUN\",\n",
    "             \"start\": 7, \"end\": 15, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"process\", \"lemma\": \"process\", \"pos\": \"VERB\",\n",
    "             \"start\": 16, \"end\": 23, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "            {\"text\": \"data\", \"lemma\": \"data\", \"pos\": \"NOUN\",\n",
    "             \"start\": 24, \"end\": 28, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    }\n",
    "]\n",
    "\n",
    "results_json = extract_batch_from_json(json.dumps(docs))\n",
    "results = json.loads(results_json)\n",
    "\n",
    "print(\"Batch results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nDocument {i}:\")\n",
    "    for phrase in result[\"phrases\"]:\n",
    "        print(f\"  - {phrase['text']} ({phrase['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision-guide",
   "metadata": {},
   "source": [
    "## Decision Guide: Which Variant to Use?\n",
    "\n",
    "```\n",
    "                                START\n",
    "                                  \u2502\n",
    "                                  \u25bc\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502 Do you have specific    \u2502\n",
    "                    \u2502 topics to focus on?     \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                         \u2502              \u2502\n",
    "                        YES             NO\n",
    "                         \u2502              \u2502\n",
    "                         \u25bc              \u25bc\n",
    "               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "               \u2502 BiasedTextRank\u2502  \u2502 Is key info at the     \u2502\n",
    "               \u2502              \u2502  \u2502 beginning of the doc?   \u2502\n",
    "               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                       \u2502              \u2502\n",
    "                                      YES             NO\n",
    "                                       \u2502              \u2502\n",
    "                                       \u25bc              \u25bc\n",
    "                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                              \u2502 PositionRank \u2502 \u2502 BaseTextRank \u2502\n",
    "                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Recommendations by Document Type\n",
    "\n",
    "| Document Type | Recommended Variant | Why |\n",
    "|---------------|---------------------|-----|\n",
    "| Blog posts, articles | BaseTextRank | General content, no position bias needed |\n",
    "| Academic papers | PositionRank | Key terms in title/abstract |\n",
    "| News articles | PositionRank | Lead paragraphs contain key info |\n",
    "| Product reviews | BiasedTextRank | Focus on features you care about |\n",
    "| Support tickets | BiasedTextRank | Focus on problem categories |\n",
    "| Legal documents | BaseTextRank | Important terms throughout |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[03_explain_algorithm.ipynb](03_explain_algorithm.ipynb)** - Visual explanation of how TextRank works internally\n",
    "- **[04_benchmarks.ipynb](04_benchmarks.ipynb)** - Performance comparison with pytextrank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}