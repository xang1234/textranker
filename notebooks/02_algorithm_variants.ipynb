{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": "# Algorithm Variants in rapid_textrank\n\nThis notebook explores the TextRank algorithm variants available in `rapid_textrank`:\n\n| Variant | Best For | Key Feature |\n|---------|----------|-------------|\n| **BaseTextRank** | General text | Standard TextRank implementation |\n| **PositionRank** | Academic papers, news | Favors words appearing early |\n| **BiasedTextRank** | Topic-focused extraction | Biases toward specified focus terms |\n| **TopicalPageRank** | Domain-specific extraction | Biases toward topic-weighted terms via personalized PageRank |\n| **MultipartiteRank** | Multi-topic documents | K-partite graph with intra-topic edges removed; boosts first-occurring variants |"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "%pip install -q rapid_textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "from rapid_textrank import BaseTextRank, PositionRank, BiasedTextRank, TopicalPageRank, MultipartiteRank"
  },
  {
   "cell_type": "markdown",
   "id": "basetextrank-header",
   "metadata": {},
   "source": [
    "## 1. BaseTextRank\n",
    "\n",
    "The standard TextRank algorithm, based on [Mihalcea & Tarau (2004)](https://aclanthology.org/W04-3252/).\n",
    "\n",
    "**How it works:**\n",
    "1. Builds a co-occurrence graph from content words\n",
    "2. Runs PageRank to score word importance\n",
    "3. Extracts phrases by grouping high-scoring words\n",
    "\n",
    "**Best for:** General-purpose keyword extraction where word position doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basetextrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextRank Results:\n",
      "==================================================\n",
      " 1. Natural language                    0.1966\n",
      " 2. on many NLP tasks                   0.1388\n",
      " 3. human language in a                 0.1285\n",
      " 4. NLP in recent years                 0.1105\n",
      " 5. of NLP is to                        0.1105\n",
      " 6. computers and humans through        0.1099\n",
      " 7. enable computers to                 0.0820\n",
      " 8. summarization and question          0.0741\n",
      " 9. artificial intelligence             0.0586\n",
      "10. is a field of                       0.0396\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence\n",
    "that focuses on the interaction between computers and humans through\n",
    "natural language. The ultimate goal of NLP is to enable computers to\n",
    "understand, interpret, and generate human language in a valuable way.\n",
    "\n",
    "Machine learning approaches have transformed NLP in recent years.\n",
    "Deep learning models, particularly transformers, have achieved\n",
    "state-of-the-art results on many NLP tasks including translation,\n",
    "summarization, and question answering.\n",
    "\"\"\"\n",
    "\n",
    "base = BaseTextRank(top_n=10, language=\"en\")\n",
    "result = base.extract_keywords(text)\n",
    "\n",
    "print(\"BaseTextRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positionrank-header",
   "metadata": {},
   "source": [
    "## 2. PositionRank\n",
    "\n",
    "Based on [Florescu & Caragea (2017)](https://aclanthology.org/P17-1102/), PositionRank weights words by their position in the document.\n",
    "\n",
    "**Key insight:** In many documents (papers, news articles, reports), important terms appear early—in titles, abstracts, or introductory paragraphs.\n",
    "\n",
    "**How it differs from BaseTextRank:**\n",
    "- Words appearing early get higher initial importance\n",
    "- Position weight decays as you move through the document\n",
    "- The PageRank algorithm then refines these position-biased scores\n",
    "\n",
    "**Best for:** Academic papers, news articles, structured documents with front-loaded information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "positionrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionRank Results:\n",
      "==================================================\n",
      " 1. quantum error correction that       0.4234\n",
      " 2. fault tolerant quantum computation  0.3016\n",
      " 3. Near Term Quantum Computers         0.2913\n",
      " 4. practical quantum                   0.2144\n",
      " 5. predict and correct errors          0.1872\n",
      " 6. logical error rates                 0.1769\n",
      " 7. Our method leverages machine        0.0688\n",
      " 8. reduces the overhead                0.0566\n",
      " 9. reduction in                        0.0224\n",
      "10. applications                        0.0195\n"
     ]
    }
   ],
   "source": [
    "# Academic abstract where key terms appear in the title/first sentence\n",
    "abstract = \"\"\"\n",
    "Quantum Error Correction in Near-Term Quantum Computers\n",
    "\n",
    "We present a novel approach to quantum error correction that significantly\n",
    "reduces the overhead required for fault-tolerant quantum computation.\n",
    "Our method leverages machine learning to predict and correct errors\n",
    "in real-time. Experimental results on superconducting qubits demonstrate\n",
    "a 50% reduction in logical error rates. These advances bring us closer\n",
    "to practical quantum computing applications.\n",
    "\"\"\"\n",
    "\n",
    "pos = PositionRank(top_n=10, language=\"en\")\n",
    "result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(\"PositionRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "### BaseTextRank vs PositionRank: Side-by-Side\n",
    "\n",
    "Let's compare both algorithms on the same text to see how position weighting affects results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextRank                        PositionRank                       \n",
      "======================================================================\n",
      "quantum error correction that       quantum error correction that      \n",
      "fault tolerant quantum computation  fault tolerant quantum computation \n",
      "Near Term Quantum Computers         Near Term Quantum Computers        \n",
      "predict and correct errors          practical quantum                  \n",
      "logical error rates                 predict and correct errors         \n"
     ]
    }
   ],
   "source": [
    "# Same abstract, both algorithms\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "pos = PositionRank(top_n=5, language=\"en\")\n",
    "\n",
    "base_result = base.extract_keywords(abstract)\n",
    "pos_result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(f\"{'BaseTextRank':<35} {'PositionRank':<35}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(5):\n",
    "    base_phrase = base_result.phrases[i]\n",
    "    pos_phrase = pos_result.phrases[i]\n",
    "    print(f\"{base_phrase.text:<35} {pos_phrase.text:<35}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparison-detailed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In both: {'predict and correct errors', 'quantum error correction that', 'fault tolerant quantum computation', 'Near Term Quantum Computers'}\n",
      "Only in BaseTextRank: {'logical error rates'}\n",
      "Only in PositionRank: {'practical quantum'}\n"
     ]
    }
   ],
   "source": [
    "# Let's see which phrases are unique to each algorithm\n",
    "base_texts = {p.text for p in base_result.phrases}\n",
    "pos_texts = {p.text for p in pos_result.phrases}\n",
    "\n",
    "only_base = base_texts - pos_texts\n",
    "only_pos = pos_texts - base_texts\n",
    "both = base_texts & pos_texts\n",
    "\n",
    "print(f\"In both: {both}\")\n",
    "print(f\"Only in BaseTextRank: {only_base}\")\n",
    "print(f\"Only in PositionRank: {only_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biasedtextrank-header",
   "metadata": {},
   "source": [
    "## 3. BiasedTextRank\n",
    "\n",
    "Based on [Kazemi et al. (2020)](https://aclanthology.org/2020.coling-main.144/), BiasedTextRank steers extraction toward specified focus terms.\n",
    "\n",
    "**Key parameters:**\n",
    "- `focus_terms`: List of terms to bias toward\n",
    "- `bias_weight`: How strongly to favor focus terms (higher = stronger bias)\n",
    "\n",
    "**How it works:**\n",
    "- Focus terms get an initial boost in the PageRank algorithm\n",
    "- Words connected to focus terms inherit some of this bias\n",
    "- The result emphasizes the topic you care about\n",
    "\n",
    "**Best for:** Topic-specific extraction, document filtering, aspect-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "biasedtextrank-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiasedTextRank (focus: security, privacy):\n",
      "==================================================\n",
      " 1. user experience with security       0.1417\n",
      " 2. users on slow networks              0.1075\n",
      " 3. regulations like GDPR require       0.1056\n",
      " 4. but complicate data freshness       0.1021\n",
      " 5. Security vulnerabilities can expose 0.0986\n",
      " 6. sensitive user information          0.0947\n",
      " 7. careful data                        0.0926\n",
      " 8. user                                0.0693\n",
      " 9. Authentication systems must prevent 0.0667\n",
      "10. transit and at rest                 0.0391\n"
     ]
    }
   ],
   "source": [
    "# Text covering multiple topics\n",
    "tech_article = \"\"\"\n",
    "Modern web applications must balance user experience with security.\n",
    "Performance optimizations are crucial for mobile users on slow networks.\n",
    "Privacy regulations like GDPR require careful data handling and consent.\n",
    "Security vulnerabilities can expose sensitive user information.\n",
    "Caching strategies improve response times but complicate data freshness.\n",
    "Authentication systems must prevent unauthorized access while remaining\n",
    "user-friendly. Encryption protects data both in transit and at rest.\n",
    "\"\"\"\n",
    "\n",
    "# Focus on security/privacy topics\n",
    "biased = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=10,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "result = biased.extract_keywords(tech_article)\n",
    "\n",
    "print(\"BiasedTextRank (focus: security, privacy):\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias-weight-header",
   "metadata": {},
   "source": [
    "### Effect of `bias_weight`\n",
    "\n",
    "The `bias_weight` parameter controls how strongly results favor the focus terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bias-weight-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Weight Comparison (focus: security, privacy)\n",
      "================================================================================\n",
      "\n",
      "bias_weight=1.0:\n",
      "  user experience with security: 0.1227\n",
      "  but complicate data freshness: 0.1102\n",
      "  users on slow networks: 0.1087\n",
      "\n",
      "bias_weight=2.0:\n",
      "  user experience with security: 0.1282\n",
      "  users on slow networks: 0.1084\n",
      "  but complicate data freshness: 0.1079\n",
      "\n",
      "bias_weight=5.0:\n",
      "  user experience with security: 0.1417\n",
      "  users on slow networks: 0.1075\n",
      "  regulations like GDPR require: 0.1056\n",
      "\n",
      "bias_weight=10.0:\n",
      "  user experience with security: 0.1576\n",
      "  regulations like GDPR require: 0.1215\n",
      "  Security vulnerabilities can expose: 0.1159\n"
     ]
    }
   ],
   "source": [
    "# Compare different bias weights\n",
    "weights = [1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "print(\"Bias Weight Comparison (focus: security, privacy)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for weight in weights:\n",
    "    biased = BiasedTextRank(\n",
    "        focus_terms=[\"security\", \"privacy\"],\n",
    "        bias_weight=weight,\n",
    "        top_n=3,\n",
    "        language=\"en\"\n",
    "    )\n",
    "    result = biased.extract_keywords(tech_article)\n",
    "    \n",
    "    print(f\"\\nbias_weight={weight}:\")\n",
    "    for p in result.phrases:\n",
    "        print(f\"  {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bias-vs-unbiased",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased                  Security Focus            Performance Focus        \n",
      "===========================================================================\n",
      "user experience with security user experience with security user experience with security\n",
      "but complicate data freshness users on slow networks    users on slow networks   \n",
      "users on slow networks    regulations like GDPR require but complicate data freshness\n",
      "careful data              but complicate data freshness sensitive user information\n",
      "sensitive user information Security vulnerabilities can expose careful data             \n"
     ]
    }
   ],
   "source": [
    "# Compare biased vs unbiased on the same text\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "biased_security = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "biased_perf = BiasedTextRank(\n",
    "    focus_terms=[\"performance\", \"speed\", \"cache\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "base_result = base.extract_keywords(tech_article)\n",
    "security_result = biased_security.extract_keywords(tech_article)\n",
    "perf_result = biased_perf.extract_keywords(tech_article)\n",
    "\n",
    "print(f\"{'Unbiased':<25} {'Security Focus':<25} {'Performance Focus':<25}\")\n",
    "print(\"=\" * 75)\n",
    "for i in range(5):\n",
    "    print(f\"{base_result.phrases[i].text:<25} \"\n",
    "          f\"{security_result.phrases[i].text:<25} \"\n",
    "          f\"{perf_result.phrases[i].text:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focus-per-call",
   "metadata": {},
   "source": [
    "### Dynamic Focus Terms\n",
    "\n",
    "You can also pass `focus_terms` per-call, which is useful when processing multiple documents with different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "per-call-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Focus: ['security', 'encryption']\n",
      "  - user experience with security\n",
      "  - but complicate data freshness\n",
      "  - users on slow networks\n",
      "\n",
      "Focus: ['performance', 'caching']\n",
      "  - user experience with security\n",
      "  - users on slow networks\n",
      "  - but complicate data freshness\n",
      "\n",
      "Focus: ['user', 'experience']\n",
      "  - user experience with security\n",
      "  - users on slow networks\n",
      "  - sensitive user information\n"
     ]
    }
   ],
   "source": [
    "# Create extractor with default focus\n",
    "extractor = BiasedTextRank(\n",
    "    focus_terms=[\"default\"],  # Placeholder\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Override focus_terms per call\n",
    "topics = [\n",
    "    [\"security\", \"encryption\"],\n",
    "    [\"performance\", \"caching\"],\n",
    "    [\"user\", \"experience\"]\n",
    "]\n",
    "\n",
    "for focus in topics:\n",
    "    result = extractor.extract_keywords(tech_article, focus_terms=focus)\n",
    "    print(f\"\\nFocus: {focus}\")\n",
    "    for p in result.phrases[:3]:\n",
    "        print(f\"  - {p.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pklx73y7cil",
   "source": "## 4. TopicalPageRank\n\nBased on [Sterckx et al. (2015)](https://aclanthology.org/), TopicalPageRank uses **personalized PageRank** to steer extraction toward topic-relevant terms.\n\n**Key parameters:**\n- `topic_weights`: Dict mapping lemmas to importance weights (e.g. from LDA topics)\n- `min_weight`: Baseline weight for words not in the topic vocabulary (default `0.0`)\n\n**How it differs from BiasedTextRank:**\n- BiasedTextRank boosts *specific focus terms* you provide (e.g. \"security\", \"privacy\")\n- TopicalPageRank uses a *distribution of weights* over many terms, typically derived from topic models like LDA\n- The weights act as the PageRank teleport distribution — when the random surfer restarts, it jumps to nodes proportionally to their topic weight\n- Only relative proportions matter; weights are normalized internally\n\n**Best for:** Domain-specific extraction where you have topic model output or domain vocabularies with graded importance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "bkdza81hrdw",
   "source": "# Text covering multiple topics — same one used for BiasedTextRank above\n# TopicalPageRank lets us weight many terms at once with graded importance\n\ntopic_weights = {\n    \"security\": 0.9,\n    \"privacy\": 0.8,\n    \"encryption\": 0.7,\n    \"authentication\": 0.6,\n    \"data\": 0.4,\n    \"access\": 0.3,\n}\n\ntpr = TopicalPageRank(\n    topic_weights=topic_weights,\n    min_weight=0.0,   # OOV words get zero teleport probability\n    top_n=10,\n    language=\"en\"\n)\n\nresult = tpr.extract_keywords(tech_article)\n\nprint(\"TopicalPageRank (security/privacy topic weights):\")\nprint(\"=\" * 50)\nfor p in result.phrases:\n    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aprveq11sb",
   "source": "### Effect of `min_weight`\n\nThe `min_weight` parameter controls how much \"attention\" out-of-vocabulary words receive during the random walk's teleport step:\n\n- `min_weight=0.0` — Only topic-relevant words get teleport probability (strong focus)\n- `min_weight > 0` — All words get at least this baseline, softening the topic bias",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j2tah087xh",
   "source": "# Compare different min_weight values\nmin_weights = [0.0, 0.01, 0.1, 0.5]\n\nprint(\"min_weight Comparison (same topic_weights)\")\nprint(\"=\" * 80)\n\nfor mw in min_weights:\n    tpr = TopicalPageRank(\n        topic_weights=topic_weights,\n        min_weight=mw,\n        top_n=3,\n        language=\"en\"\n    )\n    result = tpr.extract_keywords(tech_article)\n\n    print(f\"\\nmin_weight={mw}:\")\n    for p in result.phrases:\n        print(f\"  {p.text}: {p.score:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "y4stm10d4is",
   "source": "### TopicalPageRank vs BiasedTextRank: Side-by-Side\n\nBoth variants let you steer extraction toward a topic, but they work differently:\n- **BiasedTextRank** takes a flat list of focus terms with a single `bias_weight` multiplier\n- **TopicalPageRank** takes a *weighted vocabulary* and uses personalized PageRank teleportation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3hwu49xopbm",
   "source": "# Compare BiasedTextRank and TopicalPageRank on the same security focus\nbiased = BiasedTextRank(\n    focus_terms=[\"security\", \"privacy\", \"encryption\", \"authentication\"],\n    bias_weight=5.0,\n    top_n=5,\n    language=\"en\"\n)\ntpr = TopicalPageRank(\n    topic_weights=topic_weights,\n    min_weight=0.0,\n    top_n=5,\n    language=\"en\"\n)\n\nbiased_result = biased.extract_keywords(tech_article)\ntpr_result = tpr.extract_keywords(tech_article)\n\nprint(f\"{'BiasedTextRank':<35} {'TopicalPageRank':<35}\")\nprint(\"=\" * 70)\nfor i in range(5):\n    b = biased_result.phrases[i].text if i < len(biased_result.phrases) else \"\"\n    t = tpr_result.phrases[i].text if i < len(tpr_result.phrases) else \"\"\n    print(f\"{b:<35} {t:<35}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "me563wag5go",
   "source": "## 5. MultipartiteRank\n\nBased on [Boudin (2018)](https://aclanthology.org/N18-2105/), MultipartiteRank extends TopicRank by keeping individual candidates as graph nodes instead of collapsing topics.\n\n**Key parameters:**\n- `similarity_threshold`: Jaccard similarity threshold for clustering candidates into topics (default `0.26`)\n- `alpha`: Position boost strength — higher values give more weight to first-occurring variants (default `1.1`, `0` disables)\n\n**How it works:**\n1. Candidates are clustered into topics (same HAC clustering as TopicRank)\n2. A k-partite graph is built: edges connect candidates from **different** topics only\n3. Edge weights are inversely proportional to the positional gap between candidates\n4. An alpha adjustment **boosts incoming edges** to the first-occurring variant in each topic\n5. PageRank is run on this modified graph\n\n**How it differs from TopicRank:**\n- **TopicRank** collapses each topic into a single node and ranks topics as a whole\n- **MultipartiteRank** keeps every candidate as its own node but removes intra-topic edges, preserving fine-grained distinctions while preventing intra-topic competition\n\n**Best for:** Multi-topic documents where you want topic-aware ranking with positional preference for earlier mentions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "sqeohr48vm",
   "source": "# MultipartiteRank on the same NLP text\nmpr = MultipartiteRank(\n    similarity_threshold=0.26,\n    alpha=1.1,\n    top_n=10,\n    language=\"en\"\n)\n\nresult = mpr.extract_keywords(text)\n\nprint(\"MultipartiteRank Results:\")\nprint(\"=\" * 50)\nfor p in result.phrases:\n    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "t58fv2blua",
   "source": "### Effect of `alpha`\n\nThe `alpha` parameter controls the position boost for first-occurring variants in each topic cluster. Setting `alpha=0` disables the boost entirely:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0tl94094vcf",
   "source": "# Compare different alpha values\nalphas = [0.0, 0.5, 1.1, 2.0]\n\nprint(\"Alpha Comparison (similarity_threshold=0.26)\")\nprint(\"=\" * 80)\n\nfor alpha in alphas:\n    mpr = MultipartiteRank(\n        similarity_threshold=0.26,\n        alpha=alpha,\n        top_n=3,\n        language=\"en\"\n    )\n    result = mpr.extract_keywords(text)\n\n    print(f\"\\nalpha={alpha}:\")\n    for p in result.phrases:\n        print(f\"  {p.text}: {p.score:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "49mx0h2u5j7",
   "source": "### MultipartiteRank vs BaseTextRank: Side-by-Side\n\nLet's compare MultipartiteRank with BaseTextRank to see how topic-aware graph construction affects results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "62npjpi999d",
   "source": "# Compare BaseTextRank and MultipartiteRank on the same text\nbase = BaseTextRank(top_n=5, language=\"en\")\nmpr = MultipartiteRank(similarity_threshold=0.26, alpha=1.1, top_n=5, language=\"en\")\n\nbase_result = base.extract_keywords(text)\nmpr_result = mpr.extract_keywords(text)\n\nprint(f\"{'BaseTextRank':<35} {'MultipartiteRank':<35}\")\nprint(\"=\" * 70)\nfor i in range(5):\n    b = base_result.phrases[i].text if i < len(base_result.phrases) else \"\"\n    m = mpr_result.phrases[i].text if i < len(mpr_result.phrases) else \"\"\n    print(f\"{b:<35} {m:<35}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "json-header",
   "metadata": {},
   "source": [
    "## JSON Batch API\n",
    "\n",
    "For processing large volumes of pre-tokenized documents, use the JSON interface:\n",
    "\n",
    "- `extract_from_json()` - Single document\n",
    "- `extract_batch_from_json()` - Multiple documents\n",
    "\n",
    "This is particularly useful when:\n",
    "- You've already tokenized with spaCy or another NLP library\n",
    "- You're processing many documents in batch\n",
    "- You need fine-grained control over tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "json-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single document result:\n",
      "  Machine learning: 0.6667\n",
      "  industries: 0.3333\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rapid_textrank import extract_from_json\n",
    "\n",
    "# Single document with pre-tokenized input\n",
    "doc = {\n",
    "    \"tokens\": [\n",
    "        {\"text\": \"Machine\", \"lemma\": \"machine\", \"pos\": \"NOUN\",\n",
    "         \"start\": 0, \"end\": 7, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "        {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "         \"start\": 8, \"end\": 16, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "        {\"text\": \"is\", \"lemma\": \"be\", \"pos\": \"AUX\",\n",
    "         \"start\": 17, \"end\": 19, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": True},\n",
    "        {\"text\": \"transforming\", \"lemma\": \"transform\", \"pos\": \"VERB\",\n",
    "         \"start\": 20, \"end\": 32, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        {\"text\": \"industries\", \"lemma\": \"industry\", \"pos\": \"NOUN\",\n",
    "         \"start\": 33, \"end\": 43, \"sentence_idx\": 0, \"token_idx\": 4, \"is_stopword\": False},\n",
    "    ],\n",
    "    \"config\": {\n",
    "        \"top_n\": 5,\n",
    "        \"window_size\": 3,\n",
    "        \"damping\": 0.85\n",
    "    }\n",
    "}\n",
    "\n",
    "result_json = extract_from_json(json.dumps(doc))\n",
    "result = json.loads(result_json)\n",
    "\n",
    "print(\"Single document result:\")\n",
    "for phrase in result[\"phrases\"]:\n",
    "    print(f\"  {phrase['text']}: {phrase['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "json-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch results:\n",
      "\n",
      "Document 0:\n",
      "  - Deep learning models (1.0000)\n",
      "\n",
      "Document 1:\n",
      "  - Neural networks (0.6667)\n",
      "  - data (0.3333)\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import extract_batch_from_json\n",
    "\n",
    "# Batch processing multiple documents\n",
    "docs = [\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Deep\", \"lemma\": \"deep\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 4, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "             \"start\": 5, \"end\": 13, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"models\", \"lemma\": \"model\", \"pos\": \"NOUN\",\n",
    "             \"start\": 14, \"end\": 20, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Neural\", \"lemma\": \"neural\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 6, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"networks\", \"lemma\": \"network\", \"pos\": \"NOUN\",\n",
    "             \"start\": 7, \"end\": 15, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"process\", \"lemma\": \"process\", \"pos\": \"VERB\",\n",
    "             \"start\": 16, \"end\": 23, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "            {\"text\": \"data\", \"lemma\": \"data\", \"pos\": \"NOUN\",\n",
    "             \"start\": 24, \"end\": 28, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    }\n",
    "]\n",
    "\n",
    "results_json = extract_batch_from_json(json.dumps(docs))\n",
    "results = json.loads(results_json)\n",
    "\n",
    "print(\"Batch results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nDocument {i}:\")\n",
    "    for phrase in result[\"phrases\"]:\n",
    "        print(f\"  - {phrase['text']} ({phrase['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision-guide",
   "metadata": {},
   "source": "## Decision Guide: Which Variant to Use?\n\n```\n                                START\n                                  │\n                                  ▼\n                    ┌─────────────────────────┐\n                    │ Do you have specific    │\n                    │ topics to focus on?     │\n                    └─────────────────────────┘\n                         │              │\n                        YES             NO\n                         │              │\n                         ▼              ▼\n              ┌────────────────────┐  ┌─────────────────────────┐\n              │ Do you have graded │  │ Is key info at the     │\n              │ topic weights      │  │ beginning of the doc?   │\n              │ (e.g. from LDA)?   │  └─────────────────────────┘\n              └────────────────────┘       │              │\n                   │            │         YES             NO\n                  YES           NO         │              │\n                   │            │          ▼              ▼\n                   ▼            ▼  ┌──────────────┐ ┌──────────────────────────┐\n          ┌────────────────┐ ┌──────────────┐      │ PositionRank │ │ Multiple topics with     │\n          │TopicalPageRank │ │BiasedTextRank│      └──────────────┘ │ repeated candidates?      │\n          └────────────────┘ └──────────────┘                       └──────────────────────────┘\n                                                                         │              │\n                                                                        YES             NO\n                                                                         │              │\n                                                                         ▼              ▼\n                                                                 ┌──────────────────┐ ┌──────────────┐\n                                                                 │MultipartiteRank  │ │ BaseTextRank │\n                                                                 └──────────────────┘ └──────────────┘\n```\n\n### Recommendations by Document Type\n\n| Document Type | Recommended Variant | Why |\n|---------------|---------------------|-----|\n| Blog posts, articles | BaseTextRank | General content, no position bias needed |\n| Academic papers | PositionRank | Key terms in title/abstract |\n| News articles | PositionRank | Lead paragraphs contain key info |\n| Product reviews | BiasedTextRank | Focus on features you care about |\n| Support tickets | BiasedTextRank | Focus on problem categories |\n| Legal documents | BaseTextRank | Important terms throughout |\n| Domain corpora with LDA | TopicalPageRank | Graded topic weights from topic models |\n| Taxonomy-guided extraction | TopicalPageRank | Weight terms by domain vocabulary importance |\n| Multi-topic documents | MultipartiteRank | Topic-aware with positional preference |\n| Documents with repeated terminology | MultipartiteRank | Deduplicates via topic clustering, boosts first mention |"
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[03_explain_algorithm.ipynb](03_explain_algorithm.ipynb)** - Visual explanation of how TextRank works internally\n",
    "- **[04_benchmarks.ipynb](04_benchmarks.ipynb)** - Performance comparison with pytextrank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}